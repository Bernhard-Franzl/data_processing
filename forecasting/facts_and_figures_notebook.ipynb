{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from _dfguru import DataFrameGuru as DFG\n",
    "from _occupancy_forecasting import MasterTrainer\n",
    "from _occupancy_forecasting import load_data\n",
    "from _occupancy_forecasting import avoid_name_conflicts\n",
    "from _evaluating import ParameterSearch\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "dfg = DFG()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "############ Inputs ############\n",
    "#args = parse_arguments()\n",
    "#args = prompt_for_missing_arguments(args)0\n",
    "#n_run = args.n_run\n",
    "#n_param = args.n_param\n",
    "\n",
    "n_run = 10\n",
    "n_param = 0\n",
    "\n",
    "overwrite = True\n",
    "################################\n",
    "\n",
    "param_dir = \"_occupancy_forecasting/parameters/wrap_up\"\n",
    "tb_log_dir = \"_occupancy_forecasting/training_logs/wrap_up\"\n",
    "cp_log_dir = \"_occupancy_forecasting/checkpoints/wrap_up\"\n",
    "path_to_data = \"data/occupancy_forecasting\"\n",
    "\n",
    "frequency = \"5min\"\n",
    "split_by = \"time\"\n",
    "\n",
    "\n",
    "train_dict, val_dict, test_dict = load_data(\n",
    "    path_to_data_dir=path_to_data, \n",
    "    frequency=frequency, \n",
    "    split_by=split_by,\n",
    "    dfguru=dfg,\n",
    "    with_examweek=False\n",
    ")\n",
    "\n",
    "\n",
    "data = train_dict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "helper_file = os.path.join(\"data/occupancy_forecasting\", \"helpers_occpred.json\")\n",
    "with open(helper_file, \"r\") as f:\n",
    "    helper = json.load(f)       \n",
    "norm_registered = helper[\"columns_to_normalize\"][\"registered\"]\n",
    "norm_temperature = helper[\"columns_to_normalize\"][\"tl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "from _plotting import DataPlotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Some Features on Slide of 17.12 Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-04-09 07:00:00\n",
    "start = datetime.datetime(2024, 4, 16, 7, 0, 0)\n",
    "# 2024-04-09 21:00:00\n",
    "stop = datetime.datetime(2024, 4, 16, 21, 0, 0)\n",
    "\n",
    "plot_data = dfg.filter_by_timestamp(data, \"datetime\", start, stop) \n",
    "\n",
    "plot_data[\"tl\"] = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\n",
    "plot_data[\"registered\"] = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\n",
    "\n",
    "plotter = DataPlotter(\n",
    "    save_path=\"\",\n",
    "    dataframe_guru=dfg\n",
    ")\n",
    "\n",
    "#plotter.plot_some_features(plot_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ranges and size of train/val/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Room 0: 17728 samples from 2024-04-08 00:00:00 to 2024-06-08 13:15:00\n",
      "Val Room 0: 2216 samples from 2024-06-08 13:20:00 to 2024-06-16 05:55:00\n",
      "Test Room 0: 2216 samples from 2024-06-16 06:00:00 to 2024-06-23 22:35:00\n",
      "\n",
      "Train Room 1: 17728 samples from 2024-04-08 00:00:00 to 2024-06-08 13:15:00\n",
      "Val Room 1: 2216 samples from 2024-06-08 13:20:00 to 2024-06-16 05:55:00\n",
      "Test Room 1: 2216 samples from 2024-06-16 06:00:00 to 2024-06-23 22:35:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for room_id in [0,1]:\n",
    "    # print number of samples and range of datetime\n",
    "    print(f\"Train Room {room_id}: {len(train_dict[room_id])} samples from {train_dict[room_id]['datetime'].min()} to {train_dict[room_id]['datetime'].max()}\")\n",
    "    print(f\"Val Room {room_id}: {len(val_dict[room_id])} samples from {val_dict[room_id]['datetime'].min()} to {val_dict[room_id]['datetime'].max()}\")\n",
    "    print(f\"Test Room {room_id}: {len(test_dict[room_id])} samples from {test_dict[room_id]['datetime'].min()} to {test_dict[room_id]['datetime'].max()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show class imbalances -> zero problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Room 0: zero:13653 total:17728 relative:0.7701376353790613\n",
      "Val Room 0: zero:1820 total:2216 relative:0.8212996389891697\n",
      "Test Room 0: zero:1727 total:2216 relative:0.7793321299638989\n",
      "\n",
      "Train Room 1: zero:14132 total:17728 relative:0.7971570397111913\n",
      "Val Room 1: zero:1842 total:2216 relative:0.8312274368231047\n",
      "Test Room 1: zero:1868 total:2216 relative:0.8429602888086642\n",
      "\n",
      "Train: zero:27785 total:35456 relative:0.7836473375451264\n",
      "Val: zero:3662 total:4432 relative:0.8262635379061372\n",
      "Test: zero:3595 total:4432 relative:0.8111462093862816\n"
     ]
    }
   ],
   "source": [
    "# print number of timesteps with occrate = 0\n",
    "\n",
    "for room_id in [0,1]:\n",
    "    train_occrate = train_dict[room_id][\"occrate\"]\n",
    "    print(f\"Train Room {room_id}: zero:{len(train_occrate[train_occrate == 0])} total:{len(train_occrate)} relative:{len(train_occrate[train_occrate == 0]) / len(train_occrate)}\")\n",
    "    val_occrate = val_dict[room_id][\"occrate\"]\n",
    "    print(f\"Val Room {room_id}: zero:{len(val_occrate[val_occrate == 0])} total:{len(val_occrate)} relative:{len(val_occrate[val_occrate == 0]) / len(val_occrate)}\")\n",
    "    test_occrate = test_dict[room_id][\"occrate\"]\n",
    "    print(f\"Test Room {room_id}: zero:{len(test_occrate[test_occrate == 0])} total:{len(test_occrate)} relative:{len(test_occrate[test_occrate == 0]) / len(test_occrate)}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "# sum over all rooms\n",
    "train_occrate = np.concatenate([train_dict[0][\"occrate\"], train_dict[1][\"occrate\"]])\n",
    "val_occrate = np.concatenate([val_dict[0][\"occrate\"], val_dict[1][\"occrate\"]])\n",
    "test_occrate = np.concatenate([test_dict[0][\"occrate\"], test_dict[1][\"occrate\"]])\n",
    "\n",
    "print(f\"Train: zero:{len(train_occrate[train_occrate == 0])} total:{len(train_occrate)} relative:{len(train_occrate[train_occrate == 0]) / len(train_occrate)}\")\n",
    "print(f\"Val: zero:{len(val_occrate[val_occrate == 0])} total:{len(val_occrate)} relative:{len(val_occrate[val_occrate == 0]) / len(val_occrate)}\")\n",
    "print(f\"Test: zero:{len(test_occrate[test_occrate == 0])} total:{len(test_occrate)} relative:{len(test_occrate[test_occrate == 0]) / len(test_occrate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'avgocc', 'occrate', 'occcount', 'occcountdiff',\n",
       "       'occratediff', 'lecturerampafter', 'lecture', 'exam', 'test',\n",
       "       'registered', 'cancelled', 'lecturerampbefore', 'level', 'type',\n",
       "       'maxoccrateestimate', 'maxocccountestimate', 'maxocccount', 'tutorium',\n",
       "       'studyarea', 'maxoccrate', 'offsite', 'coursenumber', 'ects', 'VL',\n",
       "       'UE', 'KS', 'Informatik', 'None_sa', 'Volkswirtschaftslehre', 'Chemie',\n",
       "       'Wirtschaftsinformatik', 'Maschinenbau', 'Betriebswirtschaftslehre',\n",
       "       'Rechtswissenschaften', 'Mathematik', 'Mechatronik',\n",
       "       'Informationselektronik', 'Biologische Chemie', 'Sozialwissenschaften',\n",
       "       'Artificial Intelligence', 'Kunststofftechnik', 'Statistik',\n",
       "       'Pädagogik', 'Medical Engineering', 'B1 - Bachelor 1. Jahr',\n",
       "       'None_level', 'B2 - Bachelor 2. Jahr', 'M1 - Master 1. Jahr',\n",
       "       'B3 - Bachelor 3. Jahr', 'D - Diplom', 'M2 - Master 2. Jahr', 'hod1',\n",
       "       'hod2', 'dow1', 'dow2', 'week1', 'week2', 'holiday', 'zwickltag',\n",
       "       'occrate1week', 'occrate1day', 'occcount1week', 'occcount1day',\n",
       "       'occcountdiff1week', 'occcountdiff1day', 'occratediff1week',\n",
       "       'occratediff1day', 'tl', 'p', 'ff', 'ffx', 'rf', 'rr', 'so'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_features = {\"maxocccount\", \"maxoccrate\" ,\"maxoccrateestimate\", \"maxocccountestimate\",\n",
    "                \"coursenumber\", \"exam\",  \"test\", \"tutorium\", \"cancelled\",\"offsite\", \n",
    "                \"lecture\", \"lecturerampbefore\", \"lecturerampafter\",\n",
    "                \"registered\", \"type\", \"studyarea\", \"ects\", \"level\"}\n",
    "datetime_features = {\"dow\", \"hod\", \"week\", \"holiday\", \"zwickltag\"}\n",
    "general_features = {\"occcount\", \"occrate\", \"avgocc\"}\n",
    "weather_features = {\"weather\"}\n",
    "shift_features = {\"occcount1week\", \"occrate1week\", \"occcount1day\", \"occrate1day\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'avgocc', 'occrate', 'occcount', 'occcountdiff',\n",
       "       'occratediff', 'lecturerampafter', 'lecture', 'exam', 'test',\n",
       "       'registered', 'cancelled', 'lecturerampbefore', 'level', 'type',\n",
       "       'maxoccrateestimate', 'maxocccountestimate', 'maxocccount', 'tutorium',\n",
       "       'studyarea', 'maxoccrate', 'offsite', 'coursenumber', 'ects', 'VL',\n",
       "       'UE', 'KS', 'Informatik', 'None_sa', 'Volkswirtschaftslehre', 'Chemie',\n",
       "       'Wirtschaftsinformatik', 'Maschinenbau', 'Betriebswirtschaftslehre',\n",
       "       'Rechtswissenschaften', 'Mathematik', 'Mechatronik',\n",
       "       'Informationselektronik', 'Biologische Chemie', 'Sozialwissenschaften',\n",
       "       'Artificial Intelligence', 'Kunststofftechnik', 'Statistik',\n",
       "       'Pädagogik', 'Medical Engineering', 'B1 - Bachelor 1. Jahr',\n",
       "       'None_level', 'B2 - Bachelor 2. Jahr', 'M1 - Master 1. Jahr',\n",
       "       'B3 - Bachelor 3. Jahr', 'D - Diplom', 'M2 - Master 2. Jahr', 'hod1',\n",
       "       'hod2', 'dow1', 'dow2', 'week1', 'week2', 'holiday', 'zwickltag',\n",
       "       'occrate1week', 'occrate1day', 'occcount1week', 'occcount1day',\n",
       "       'occcountdiff1week', 'occcountdiff1day', 'occratediff1week',\n",
       "       'occratediff1day', 'tl', 'p', 'ff', 'ffx', 'rf', 'rr', 'so'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Columns\n",
    "\n",
    "Essential Features:\n",
    "* Occupancy information: number of occupancts absolute or relative (divided by room capacity)\n",
    "* Time stamp: Temporal resolution of t minutes\n",
    "\n",
    "Course Features:\n",
    "* Lecture: If a lecture takes place or not\n",
    "* Date Specific Features: Exam, Test, Tutorium, Cancelled\n",
    "* Course Specific Features: Registered students, Type (VL,UE,KS), Study area, Level, Course number\n",
    "\n",
    "Time-related Features:\n",
    "* Time, Weekday, (Calendarweek)\n",
    "* Holiday, Zwickltag\n",
    "\n",
    "Weather Features:\n",
    "* Temperature, Air pressure, Precipation (sum over time interval), Wind speed, Air humidity, Sunshine duration\n",
    "\n",
    "Additional Features:\n",
    "* Average occupancy information of last k weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'VL', 'UE', 'KS', \n",
    "\n",
    "Study area: Maybe try with learnable parameter\n",
    "'Informatik', 'None_sa',\n",
    "'Volkswirtschaftslehre', 'Chemie', 'Wirtschaftsinformatik',\n",
    "'Maschinenbau', 'Betriebswirtschaftslehre', 'Rechtswissenschaften',\n",
    "'Mathematik', 'Mechatronik', 'Informationselektronik',\n",
    "'Biologische Chemie', 'Sozialwissenschaften', 'Artificial Intelligence',\n",
    "'Kunststofftechnik', 'Statistik', 'Pädagogik', 'Medical Engineering',\n",
    "\n",
    "Level: Maybe try with learnable parameter\n",
    "'B1 - Bachelor 1. Jahr', 'None_level', 'B2 - Bachelor 2. Jahr',\n",
    "'M1 - Master 1. Jahr', 'B3 - Bachelor 3. Jahr', 'D - Diplom',\n",
    "'M2 - Master 2. Jahr', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Columns\n",
    "# datetime, occupancy information (occcount, occrate=occcount/room_capacity)\n",
    "# lecture ?\n",
    "\n",
    "# Columns Concerning Specific Course Dates\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read out results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file with training results\n",
    "\n",
    "with open(\"results_wrapup_normal.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    line_str = \"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"################# Run: 0 #################\\nTime: 2024-11-25 12:48:24\\nDataset: train | Loss: MAE\\nCombinations: [[0, 9], [0, 4], [0, 1], [0, 5], [0, 10], [0, 7], [0, 6], [0, 2], [0, 3], [0, 8], [0, 0]]\\nModel Losses: [0.009174, 0.009215, 0.009297, 0.009307, 0.009342, 0.009409, 0.009479, 0.009513, 0.009543, 0.009601, 0.011038]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1)), (np.str_('occrate_type_registered_lecture_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[0, 0], [0, 4], [0, 5], [0, 6], [0, 9], [0, 1], [0, 3], [0, 2], [0, 7], [0, 10], [0, 8]]\\nModel Losses: [-1.271687, -1.556957, -1.624302, -1.873138, -1.884765, -1.897996, -1.941796, -1.957662, -2.071056, -2.220009, -2.245946]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[0, 5], [0, 4], [0, 9], [0, 1], [0, 2], [0, 3], [0, 6], [0, 10], [0, 8], [0, 7], [0, 0]]\\nModel Losses: [0.006804, 0.006821, 0.007258, 0.007267, 0.007291, 0.007312, 0.007422, 0.007476, 0.007774, 0.007785, 0.009546]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[0, 5], [0, 0], [0, 4], [0, 6], [0, 3], [0, 1], [0, 2], [0, 9], [0, 7], [0, 8], [0, 10]]\\nModel Losses: [-0.658495, -0.755675, -0.796193, -0.918626, -0.987752, -1.009844, -1.013806, -1.106653, -1.115457, -1.179837, -1.256963]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[0, 1], [0, 2], [0, 7], [0, 3], [0, 10], [0, 9], [0, 8], [0, 4], [0, 6], [0, 5], [0, 0]]\\nModel Losses: [0.007901, 0.00805 , 0.008058, 0.008071, 0.008272, 0.008278, 0.008304, 0.00834 , 0.008422, 0.00848 , 0.008544]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_lecture_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[0, 4], [0, 1], [0, 9], [0, 6], [0, 0], [0, 3], [0, 7], [0, 10], [0, 2], [0, 8], [0, 5]]\\nModel Losses: [-0.230158, -0.257588, -0.347184, -0.372477, -0.379921, -0.392089, -0.401578, -0.402907, -0.41668 , -0.440488, -0.459776]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 1 #################\\nTime: 2024-11-25 14:21:00\\nDataset: train | Loss: MAE\\nCombinations: [[1, 13], [1, 19], [1, 15], [1, 12], [1, 7], [1, 16], [1, 14], [1, 4], [1, 18], [1, 5], [1, 3], [1, 11], [1, 8], [1, 2], [1, 1], [1, 9], [1, 17], [1, 6], [1, 10], [1, 0]]\\nModel Losses: [0.005365, 0.005464, 0.005661, 0.005747, 0.005833, 0.005853, 0.006014, 0.006079, 0.006143, 0.006166, 0.006189, 0.006234, 0.006281, 0.006321, 0.006533, 0.00666 , 0.006695, 0.007292, 0.007778, 0.009012]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(4)), (np.str_('[64]'), np.int64(1))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[1, 19], [1, 16], [1, 13], [1, 7], [1, 15], [1, 18], [1, 14], [1, 12], [1, 4], [1, 11], [1, 8], [1, 2], [1, 5], [1, 1], [1, 3], [1, 17], [1, 9], [1, 6], [1, 10], [1, 0]]\\nModel Losses: [ 0.193049,  0.078227,  0.067008,  0.047441,  0.007611, -0.051807, -0.052111, -0.058241, -0.094334, -0.105558, -0.109685, -0.113618, -0.12943 , -0.178153, -0.228242, -0.333586, -0.425712, -0.451364, -0.515966, -0.603822]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(4)), (np.str_('[64]'), np.int64(1))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[1, 11], [1, 2], [1, 4], [1, 5], [1, 14], [1, 3], [1, 1], [1, 15], [1, 12], [1, 13], [1, 9], [1, 19], [1, 7], [1, 16], [1, 18], [1, 8], [1, 17], [1, 6], [1, 10], [1, 0]]\\nModel Losses: [0.005578, 0.005615, 0.005643, 0.005658, 0.005674, 0.005765, 0.005828, 0.005851, 0.006005, 0.00604 , 0.00604 , 0.006152, 0.006215, 0.00623 , 0.006381, 0.006392, 0.006484, 0.00672 , 0.007572, 0.00824 ]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(2)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[1, 14], [1, 5], [1, 2], [1, 1], [1, 11], [1, 4], [1, 13], [1, 3], [1, 12], [1, 6], [1, 15], [1, 0], [1, 9], [1, 19], [1, 8], [1, 18], [1, 10], [1, 16], [1, 17], [1, 7]]\\nModel Losses: [-0.600109, -0.617761, -0.703539, -0.728203, -0.74097 , -0.94692 , -0.965587, -1.033466, -1.057283, -1.249861, -1.286699, -1.347372, -1.356661, -1.364595, -1.777167, -1.816296, -1.984959, -2.095326, -2.128897, -2.297296]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(2)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[1, 1], [1, 2], [1, 3], [1, 11], [1, 16], [1, 12], [1, 7], [1, 13], [1, 10], [1, 6], [1, 17], [1, 14], [1, 5], [1, 0], [1, 4], [1, 18], [1, 8], [1, 19], [1, 15], [1, 9]]\\nModel Losses: [0.006296, 0.006531, 0.006542, 0.006658, 0.006936, 0.007133, 0.007158, 0.007328, 0.007382, 0.007402, 0.007413, 0.007438, 0.007457, 0.007743, 0.007834, 0.007956, 0.008018, 0.008085, 0.008222, 0.008387]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(2)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[1, 1], [1, 11], [1, 3], [1, 2], [1, 13], [1, 0], [1, 12], [1, 6], [1, 17], [1, 16], [1, 7], [1, 4], [1, 5], [1, 14], [1, 19], [1, 8], [1, 15], [1, 18], [1, 9], [1, 10]]\\nModel Losses: [ 0.074322,  0.033226, -0.095172, -0.126706, -0.139129, -0.193608, -0.217224, -0.287716, -0.31871 , -0.336765, -0.359967, -0.388613, -0.494078, -0.576274, -0.6339  , -0.669851, -0.79921 , -0.819367, -0.865894, -1.220506]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(2)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 1 #################\\nTime: 2024-11-25 16:41:19\\nDataset: train | Loss: MAE\\nCombinations: [[1, 27], [1, 22], [1, 28], [1, 23], [1, 24], [1, 26], [1, 20], [1, 25], [1, 29], [1, 21], [1, 30]]\\nModel Losses: [0.003739, 0.004822, 0.004867, 0.004951, 0.006118, 0.006558, 0.006774, 0.006924, 0.007001, 0.007033, 0.007324]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[1, 27], [1, 28], [1, 23], [1, 22], [1, 24], [1, 26], [1, 20], [1, 25], [1, 21], [1, 29], [1, 30]]\\nModel Losses: [ 0.580019,  0.27326 ,  0.261062,  0.221271, -0.115581, -0.15577 , -0.211604, -0.340667, -0.449735, -0.49523 , -0.806164]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[1, 24], [1, 21], [1, 25], [1, 27], [1, 28], [1, 22], [1, 23], [1, 26], [1, 29], [1, 30], [1, 20]]\\nModel Losses: [0.005854, 0.005858, 0.005885, 0.005916, 0.00616 , 0.006186, 0.006199, 0.006304, 0.006585, 0.007247, 0.007576]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[1, 22], [1, 24], [1, 25], [1, 21], [1, 23], [1, 26], [1, 27], [1, 29], [1, 28], [1, 30], [1, 20]]\\nModel Losses: [-0.881361, -0.922036, -0.922258, -0.964145, -1.207267, -1.336592, -1.510207, -1.820202, -1.862806, -1.888185, -2.928589]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[1, 21], [1, 26], [1, 23], [1, 22], [1, 20], [1, 27], [1, 28], [1, 24], [1, 25], [1, 29], [1, 30]]\\nModel Losses: [0.006792, 0.007105, 0.007418, 0.0077, 0.007704, 0.008037, 0.008224, 0.008462, 0.00861 , 0.009036, 0.009233]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[1, 21], [1, 26], [1, 23], [1, 22], [1, 28], [1, 25], [1, 30], [1, 29], [1, 24], [1, 20], [1, 27]]\\nModel Losses: [-0.08976 , -0.131046, -0.33059 , -0.538394, -0.818474, -0.821013, -0.871533, -0.892232, -1.085593, -1.175527, -1.189492]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 2 #################\\nTime: 2024-11-25 16:42:42\\nDataset: train | Loss: MAE\\nCombinations: [[2, 7], [2, 3], [2, 8], [2, 9], [2, 6], [2, 4], [2, 2], [2, 1], [2, 10], [2, 5], [2, 0]]\\nModel Losses: [0.005578, 0.005769, 0.005981, 0.005995, 0.006217, 0.006344, 0.006638, 0.006871, 0.007056, 0.007118, 0.008227]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[2, 7], [2, 6], [2, 3], [2, 9], [2, 8], [2, 4], [2, 2], [2, 1], [2, 5], [2, 0], [2, 10]]\\nModel Losses: [ 0.256068,  0.024687, -0.097699, -0.100894, -0.221453, -0.23891 , -0.258536, -0.471042, -0.504981, -0.705008, -1.184513]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[2, 3], [2, 9], [2, 2], [2, 4], [2, 5], [2, 8], [2, 1], [2, 7], [2, 6], [2, 10], [2, 0]]\\nModel Losses: [0.005063, 0.00511 , 0.005153, 0.005216, 0.005338, 0.00534 , 0.005374, 0.00568 , 0.005703, 0.005722, 0.007419]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[2, 3], [2, 2], [2, 1], [2, 4], [2, 9], [2, 8], [2, 5], [2, 6], [2, 7], [2, 10], [2, 0]]\\nModel Losses: [-0.20543 , -0.307817, -0.3122  , -0.66862 , -0.690103, -0.840497, -0.98646 , -1.249429, -1.28819 , -1.35698 , -1.728006]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[2, 7], [2, 2], [2, 3], [2, 6], [2, 9], [2, 1], [2, 4], [2, 5], [2, 8], [2, 0], [2, 10]]\\nModel Losses: [0.005675, 0.005921, 0.005942, 0.006138, 0.006281, 0.006313, 0.006642, 0.007396, 0.007538, 0.007672, 0.007978]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[2, 3], [2, 2], [2, 7], [2, 6], [2, 9], [2, 1], [2, 4], [2, 5], [2, 10], [2, 8], [2, 0]]\\nModel Losses: [ 0.244264,  0.184584,  0.165146,  0.104136,  0.096953, -0.018902, -0.056965, -0.20548 , -0.406115, -0.557998, -1.889594]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 2 #################\\nTime: 2024-11-26 11:04:12\\nDataset: train | Loss: MAE\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.00259 , 0.002844]\\nBL zero Losses: [0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.70743, 0.63676]\\nBL zero Losses: [-46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.00567 , 0.005736]\\nBL zero Losses: [0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [-2.000536, -2.189111]\\nBL zero Losses: [-29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.007281, 0.007356]\\nBL zero Losses: [0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[2, 11], [2, 12]]\\nModel Losses: [-0.705091, -1.517717]\\nBL zero Losses: [-18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\",\n",
       " \"\\n################# Run: 4 #################\\nTime: 2024-11-26 11:49:05\\nDataset: val | Loss: MAE\\nCombinations: [[4, 2], [4, 1], [4, 0]]\\nModel Losses: [0.008509, 0.009223, 0.017107]\\nBL zero Losses: [0.022858, 0.022858, 0.022858]\\nBL naive Losses: [0.015575, 0.015575, 0.015575]\\nBL avg Losses: [0.0141, 0.0141, 0.0141]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[4, 2], [4, 1], [4, 0]]\\nModel Losses: [ 0.349202,  0.113005, -1.065243]\\nBL zero Losses: [-0.088206, -0.088206, -0.088206]\\nBL naive Losses: [-25.300606, -25.300606, -25.300606]\\nBL avg Losses: [-1.20321, -1.20321, -1.20321]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[4, 1], [4, 2], [4, 0]]\\nModel Losses: [0.009723, 0.010195, 0.015032]\\nBL zero Losses: [0.01809, 0.01809, 0.01809]\\nBL naive Losses: [0.016911, 0.016911, 0.016911]\\nBL avg Losses: [0.011491, 0.011491, 0.011491]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[4, 1], [4, 2], [4, 0]]\\nModel Losses: [ 0.422707,  0.231156, -1.89839 ]\\nBL zero Losses: [-0.472649, -0.472649, -0.472649]\\nBL naive Losses: [-21.483574, -21.483574, -21.483574]\\nBL avg Losses: [-0.897995, -0.897995, -0.897995]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\",\n",
       " \"\\n\\n################# Run: 5 #################\\nTime: 2024-11-26 15:47:12\\nDataset: val | Loss: MAE\\nCombinations: [[5, 16], [5, 1], [5, 14], [5, 5], [5, 10], [5, 4], [5, 15], [5, 11], [5, 13], [5, 12], [5, 8], [5, 3], [5, 9], [5, 7], [5, 2], [5, 6], [5, 0]]\\nModel Losses: [0.004702, 0.004728, 0.004769, 0.004769, 0.004776, 0.00478 , 0.004796, 0.004831, 0.004889, 0.004915, 0.00495 , 0.005033, 0.005065, 0.005341, 0.005644, 0.005784, 0.007363]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('5'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(2)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite'), np.int64(3))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[5, 16], [5, 5], [5, 12], [5, 7], [5, 14], [5, 13], [5, 1], [5, 8], [5, 11], [5, 15], [5, 10], [5, 4], [5, 6], [5, 2], [5, 3], [5, 9], [5, 0]]\\nModel Losses: [-0.218303, -0.361199, -0.469523, -0.523856, -0.531198, -0.547082, -0.550233, -0.555581, -0.560754, -0.594154, -0.717199, -0.725033, -1.077306, -1.301381, -1.388305, -1.50122 , -2.879412]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(1)), (np.str_('5'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber_exam'), np.int64(1)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite'), np.int64(2)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite_weather'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[5, 1], [5, 8], [5, 11], [5, 14], [5, 2], [5, 13], [5, 10], [5, 3], [5, 12], [5, 9], [5, 15], [5, 16], [5, 7], [5, 6], [5, 5], [5, 4], [5, 0]]\\nModel Losses: [0.005779, 0.005779, 0.005857, 0.0059  , 0.006063, 0.006221, 0.006232, 0.006278, 0.00629 , 0.006301, 0.006387, 0.006466, 0.006965, 0.007044, 0.007113, 0.007382, 0.00832 ]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(1)), (np.str_('5'), np.int64(1))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(4)), (np.str_('occrate_type_registered_exam'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[5, 11], [5, 10], [5, 2], [5, 1], [5, 16], [5, 8], [5, 15], [5, 13], [5, 3], [5, 5], [5, 12], [5, 7], [5, 14], [5, 9], [5, 6], [5, 4], [5, 0]]\\nModel Losses: [ 0.195995,  0.140819,  0.110799,  0.075032, -0.005665, -0.008376, -0.022353, -0.046668, -0.098944, -0.109979, -0.113518, -0.117702, -0.173238, -0.214145, -0.252696, -0.60466 , -3.004672]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(1)), (np.str_('5'), np.int64(1))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(2)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite'), np.int64(2)), (np.str_('occrate_type_registered_exam'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 6 #################\\nTime: 2024-11-26 21:24:45\\nDataset: val | Loss: MAE\\nCombinations: [[6, 11], [6, 13], [6, 16], [6, 18], [6, 31], [6, 1], [6, 3], [6, 23], [6, 33], [6, 6], [6, 8], [6, 24], [6, 21], [6, 38], [6, 22], [6, 34], [6, 4], [6, 32], [6, 19], [6, 14], [6, 7], [6, 39], [6, 2], [6, 9], [6, 29], [6, 26], [6, 12], [6, 27], [6, 37], [6, 36], [6, 17], [6, 28], [6, 10], [6, 30], [6, 35], [6, 5], [6, 15], [6, 0], [6, 25], [6, 20]]\\nModel Losses: [0.004581, 0.004723, 0.004731, 0.00474 , 0.004768, 0.004816, 0.004843, 0.004904, 0.004904, 0.004969, 0.005045, 0.005146, 0.005156, 0.005188, 0.005203, 0.005327, 0.005517, 0.005554, 0.005685, 0.005718, 0.005739, 0.005778, 0.005784, 0.005792, 0.005948, 0.005957, 0.005979, 0.006083, 0.006235, 0.006385, 0.006639, 0.006748, 0.007438, 0.007452, 0.007492, 0.00754 , 0.007564, 0.00759 , 0.007614, 0.007643]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(3)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(3)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(1)), (np.str_('[64, 128]'), np.int64(4))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[6, 13], [6, 6], [6, 8], [6, 1], [6, 11], [6, 3], [6, 24], [6, 23], [6, 31], [6, 18], [6, 16], [6, 26], [6, 4], [6, 38], [6, 33], [6, 9], [6, 29], [6, 34], [6, 21], [6, 22], [6, 14], [6, 19], [6, 36], [6, 12], [6, 2], [6, 39], [6, 32], [6, 7], [6, 27], [6, 30], [6, 37], [6, 10], [6, 20], [6, 17], [6, 15], [6, 35], [6, 28], [6, 5], [6, 25], [6, 0]]\\nModel Losses: [-0.169109, -0.303833, -0.398899, -0.517575, -0.517724, -0.546941, -0.547492, -0.560447, -0.563973, -0.569382, -0.574677, -0.581566, -0.713319, -0.717757, -0.854848, -0.864661, -0.868608, -0.92575 , -0.932865, -0.986847, -1.003365, -1.097699, -1.25115 , -1.385386, -1.437367, -1.567663, -1.640652, -1.702991, -1.800106, -2.068086, -2.068883, -2.125148, -2.285197, -2.402489, -2.43644 , -2.722001, -2.84985 , -3.168459, -3.263409, -4.13875 ]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(3)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(3)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[64, 128]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[6, 21], [6, 31], [6, 11], [6, 22], [6, 6], [6, 16], [6, 1], [6, 37], [6, 23], [6, 32], [6, 18], [6, 26], [6, 36], [6, 33], [6, 7], [6, 13], [6, 17], [6, 2], [6, 29], [6, 28], [6, 27], [6, 8], [6, 19], [6, 12], [6, 39], [6, 38], [6, 4], [6, 25], [6, 34], [6, 24], [6, 3], [6, 9], [6, 30], [6, 10], [6, 15], [6, 14], [6, 35], [6, 5], [6, 0], [6, 20]]\\nModel Losses: [0.005784, 0.005786, 0.00599 , 0.006034, 0.00605 , 0.006053, 0.006161, 0.006208, 0.006483, 0.006522, 0.006565, 0.006591, 0.00661 , 0.006671, 0.006673, 0.006675, 0.00676 , 0.006765, 0.006771, 0.006845, 0.006862, 0.006914, 0.006941, 0.00702 , 0.007047, 0.007134, 0.007324, 0.00736 , 0.007367, 0.007395, 0.007413, 0.007465, 0.007505, 0.007642, 0.007659, 0.007772, 0.008092, 0.008478, 0.008598, 0.008949]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(4)), (np.str_('0.5'), np.int64(1))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(4)), (np.str_('occrate_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[64, 128]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[6, 36], [6, 21], [6, 16], [6, 31], [6, 22], [6, 6], [6, 13], [6, 11], [6, 37], [6, 8], [6, 26], [6, 4], [6, 9], [6, 2], [6, 23], [6, 18], [6, 1], [6, 24], [6, 14], [6, 7], [6, 32], [6, 33], [6, 19], [6, 12], [6, 34], [6, 38], [6, 27], [6, 3], [6, 25], [6, 29], [6, 28], [6, 17], [6, 39], [6, 15], [6, 30], [6, 35], [6, 10], [6, 5], [6, 0], [6, 20]]\\nModel Losses: [ 1.343760e-01,  1.253210e-01,  1.160560e-01,  9.742900e-02,  5.765900e-02,  3.252100e-02,  1.060100e-02,  6.740000e-03, -2.483000e-03, -2.196100e-02, -3.452200e-02, -4.334300e-02, -4.493800e-02, -4.932400e-02, -6.792700e-02, -7.154700e-02, -7.669400e-02, -8.726900e-02, -1.097070e-01, -1.517460e-01, -1.541560e-01, -1.547600e-01, -1.888410e-01, -2.708050e-01, -2.746570e-01, -2.896750e-01, -3.165870e-01, -3.537920e-01, -3.866040e-01, -5.036790e-01, -5.975380e-01, -6.463040e-01, -8.025740e-01, -1.095634e+00, -1.692345e+00, -1.736348e+00, -2.006605e+00, -2.334082e+00, -2.915198e+00, -2.992799e+00]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(3)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(4)), (np.str_('occrate_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(4)), (np.str_('[64, 128]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 7 #################\\nTime: 2024-11-27 16:42:28\\nDataset: val | Loss: MAE\\nCombinations: [[7, 13], [7, 12], [7, 5], [7, 2], [7, 6], [7, 8], [7, 7], [7, 11], [7, 10], [7, 9], [7, 1], [7, 4], [7, 0], [7, 3]]\\nModel Losses: [0.004604, 0.004819, 0.00499 , 0.005035, 0.005494, 0.005503, 0.005935, 0.005939, 0.005967, 0.006285, 0.00649 , 0.006556, 0.007307, 0.007524]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(4))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[7, 13], [7, 2], [7, 5], [7, 12], [7, 10], [7, 8], [7, 4], [7, 9], [7, 6], [7, 3], [7, 7], [7, 0], [7, 11], [7, 1]]\\nModel Losses: [-0.479118, -0.597712, -0.61198 , -0.705585, -0.876549, -0.963151, -1.120231, -1.333144, -1.646435, -1.995162, -2.044623, -2.3313  , -2.665758, -3.172813]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[7, 5], [7, 13], [7, 6], [7, 4], [7, 12], [7, 2], [7, 11], [7, 8], [7, 7], [7, 9], [7, 3], [7, 10], [7, 0], [7, 1]]\\nModel Losses: [0.005173, 0.006024, 0.006283, 0.006428, 0.006591, 0.006682, 0.006897, 0.007016, 0.007153, 0.00725 , 0.007314, 0.007357, 0.007527, 0.007893]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(4))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[7, 5], [7, 13], [7, 12], [7, 4], [7, 10], [7, 2], [7, 8], [7, 6], [7, 11], [7, 9], [7, 7], [7, 3], [7, 0], [7, 1]]\\nModel Losses: [ 0.327543,  0.14707 ,  0.077327,  0.045528, -0.125984, -0.204842, -0.302932, -0.328158, -0.332158, -0.402251, -0.55292 , -0.676888, -1.119461, -2.586204]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 8 #################\\nTime: 2024-11-27 17:12:19\\nDataset: val | Loss: MAE\\nCombinations: [[8, 2], [8, 4], [8, 1], [8, 5], [8, 0], [8, 3]]\\nModel Losses: [0.00481 , 0.004833, 0.004928, 0.005127, 0.007307, 0.00736 ]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[8, 4], [8, 1], [8, 2], [8, 5], [8, 0], [8, 3]]\\nModel Losses: [-0.320544, -0.706099, -0.862704, -0.880151, -1.982205, -2.68343 ]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[8, 1], [8, 2], [8, 4], [8, 5], [8, 3], [8, 0]]\\nModel Losses: [0.005717, 0.006298, 0.00638 , 0.006584, 0.007216, 0.007426]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[8, 1], [8, 4], [8, 2], [8, 5], [8, 0], [8, 3]]\\nModel Losses: [ 0.183921,  0.024509, -0.072066, -0.16477 , -0.515865, -1.082964]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"################# Run: 9 #################\\nTime: 2024-12-04 16:26:23\\nDataset: val | Loss: MAE\\nCombinations: [[9, 15], [9, 21], [9, 14], [9, 24], [9, 26], [9, 27], [9, 9], [9, 2], [9, 1], [9, 17], [9, 23], [9, 11], [9, 18], [9, 5], [9, 12], [9, 8], [9, 6], [9, 10], [9, 25], [9, 20], [9, 7], [9, 4], [9, 3], [9, 13], [9, 19], [9, 22], [9, 28], [9, 16], [9, 0]]\\nModel Losses: [0.006599, 0.006947, 0.007035, 0.007075, 0.007105, 0.007335, 0.007352, 0.007363, 0.00746 , 0.00754 , 0.007546, 0.007555, 0.007567, 0.007654, 0.007701, 0.007725, 0.007987, 0.008073, 0.00812 , 0.008202, 0.008213, 0.008488, 0.008492, 0.008633, 0.008635, 0.008764, 0.008862, 0.00891 , 0.01491 ]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(3))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(4)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[9, 14], [9, 26], [9, 1], [9, 9], [9, 2], [9, 11], [9, 5], [9, 21], [9, 25], [9, 23], [9, 17], [9, 15], [9, 24], [9, 20], [9, 3], [9, 12], [9, 7], [9, 10], [9, 13], [9, 27], [9, 4], [9, 8], [9, 18], [9, 19], [9, 22], [9, 6], [9, 16], [9, 28], [9, 0]]\\nModel Losses: [ 0.707696,  0.688731,  0.66822 ,  0.656162,  0.638712,  0.635034,  0.620776,  0.613869,  0.6113  ,  0.598549,  0.596165,  0.595943,  0.595683,  0.586445,  0.582081,  0.579067,  0.577318,  0.566439,  0.559768,  0.558818,  0.539176,  0.513359,  0.494332,  0.468378,  0.421734,  0.421308,  0.366727,  0.301313, -1.615332]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[9, 5], [9, 4], [9, 12], [9, 27], [9, 23], [9, 11], [9, 26], [9, 13], [9, 15], [9, 20], [9, 8], [9, 17], [9, 14], [9, 7], [9, 28], [9, 21], [9, 24], [9, 10], [9, 1], [9, 16], [9, 18], [9, 9], [9, 3], [9, 2], [9, 6], [9, 19], [9, 25], [9, 22], [9, 0]]\\nModel Losses: [0.008764, 0.008837, 0.008972, 0.009194, 0.009197, 0.009211, 0.009311, 0.009522, 0.009525, 0.009608, 0.009724, 0.009726, 0.009777, 0.009796, 0.00985 , 0.010023, 0.010026, 0.010034, 0.01005 , 0.010073, 0.010121, 0.010318, 0.010566, 0.010636, 0.010761, 0.010869, 0.011163, 0.011314, 0.013729]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(1)), (np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[9, 5], [9, 12], [9, 4], [9, 26], [9, 20], [9, 23], [9, 10], [9, 27], [9, 24], [9, 17], [9, 8], [9, 7], [9, 3], [9, 9], [9, 2], [9, 11], [9, 14], [9, 25], [9, 15], [9, 6], [9, 21], [9, 1], [9, 18], [9, 19], [9, 13], [9, 22], [9, 0], [9, 16], [9, 28]]\\nModel Losses: [ 4.920100e-01,  4.886260e-01,  4.454480e-01,  4.172440e-01,  3.850360e-01,  3.645490e-01,  3.234280e-01,  3.060620e-01,  2.782660e-01,  2.307400e-01,  2.238560e-01,  2.149940e-01,  2.022450e-01,  1.827370e-01,  1.396270e-01,  1.386380e-01,  1.046240e-01,  2.430300e-02,  8.800000e-04, -2.846800e-02, -7.548600e-02, -1.148560e-01, -1.403400e-01, -2.019100e-01, -2.915040e-01, -4.338170e-01, -6.462810e-01, -7.220930e-01, -1.647431e+00]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(4)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(3))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 8 #################\\nTime: 2024-12-04 16:42:58\\nDataset: val | Loss: MAE\\nCombinations: [[8, 5], [8, 2], [8, 45], [8, 37], [8, 4], [8, 17], [8, 34], [8, 11], [8, 38], [8, 16], [8, 26], [8, 8], [8, 40], [8, 1], [8, 10], [8, 35], [8, 23], [8, 41], [8, 47], [8, 19], [8, 7], [8, 29], [8, 22], [8, 28], [8, 13], [8, 25], [8, 14], [8, 20], [8, 32], [8, 48], [8, 44], [8, 31], [8, 15], [8, 3], [8, 24], [8, 18], [8, 27], [8, 9], [8, 0], [8, 46], [8, 6], [8, 42], [8, 30], [8, 12], [8, 39], [8, 33], [8, 43], [8, 21], [8, 36]]\\nModel Losses: [0.00464 , 0.004676, 0.004698, 0.004709, 0.004717, 0.004728, 0.004744, 0.00476 , 0.004801, 0.004824, 0.004849, 0.004856, 0.004857, 0.004874, 0.00489 , 0.004908, 0.004932, 0.004939, 0.004945, 0.004984, 0.004991, 0.004993, 0.005008, 0.005015, 0.005016, 0.005018, 0.005047, 0.005085, 0.005103, 0.005106, 0.005112, 0.005175, 0.007013, 0.007228, 0.00732 , 0.007373, 0.007428, 0.007454, 0.007456, 0.007465, 0.007482, 0.007492, 0.007594, 0.007605, 0.007615, 0.007638, 0.007687, 0.007716, 0.007913]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(3))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[8, 2], [8, 38], [8, 19], [8, 17], [8, 37], [8, 31], [8, 5], [8, 45], [8, 44], [8, 25], [8, 4], [8, 26], [8, 34], [8, 7], [8, 1], [8, 23], [8, 32], [8, 11], [8, 22], [8, 8], [8, 35], [8, 29], [8, 48], [8, 16], [8, 28], [8, 13], [8, 41], [8, 40], [8, 10], [8, 20], [8, 14], [8, 47], [8, 3], [8, 9], [8, 18], [8, 0], [8, 15], [8, 27], [8, 24], [8, 39], [8, 6], [8, 30], [8, 36], [8, 43], [8, 42], [8, 12], [8, 33], [8, 46], [8, 21]]\\nModel Losses: [-0.252657, -0.371265, -0.371408, -0.388463, -0.439083, -0.440869, -0.444857, -0.508333, -0.534901, -0.539692, -0.579432, -0.604766, -0.610799, -0.620086, -0.628045, -0.64555 , -0.660398, -0.662019, -0.670442, -0.6855  , -0.700202, -0.727114, -0.745157, -0.756098, -0.778219, -0.811358, -0.815596, -0.869563, -0.930014, -0.957052, -0.959312, -0.983513, -1.332442, -1.370787, -1.425347, -1.50101 , -1.812056, -1.890864, -1.964116, -2.000877, -2.396244, -2.408109, -2.423054, -2.563058, -2.729784, -2.79858 , -3.001068, -3.130846, -3.166558]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(3))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(1)), (np.str_('[15, 15]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[8, 16], [8, 4], [8, 34], [8, 40], [8, 22], [8, 5], [8, 25], [8, 19], [8, 44], [8, 1], [8, 47], [8, 37], [8, 10], [8, 32], [8, 2], [8, 8], [8, 14], [8, 35], [8, 7], [8, 28], [8, 13], [8, 48], [8, 26], [8, 31], [8, 38], [8, 11], [8, 17], [8, 29], [8, 41], [8, 45], [8, 6], [8, 23], [8, 9], [8, 36], [8, 39], [8, 15], [8, 27], [8, 46], [8, 20], [8, 18], [8, 42], [8, 33], [8, 3], [8, 21], [8, 12], [8, 24], [8, 0], [8, 43], [8, 30]]\\nModel Losses: [0.005526, 0.00553 , 0.00556 , 0.005561, 0.005736, 0.00585 , 0.005855, 0.005928, 0.005976, 0.005983, 0.006031, 0.006097, 0.006098, 0.006204, 0.006224, 0.006262, 0.006278, 0.006309, 0.006333, 0.006339, 0.006358, 0.006476, 0.006667, 0.006671, 0.00678 , 0.006795, 0.006839, 0.006883, 0.006886, 0.006902, 0.007004, 0.007015, 0.007244, 0.007295, 0.007308, 0.007312, 0.00732 , 0.007425, 0.007433, 0.007444, 0.007599, 0.007667, 0.007673, 0.0077  , 0.007752, 0.007781, 0.007843, 0.007911, 0.008363]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(5))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(1)), (np.str_('[15, 15]'), np.int64(2)), (np.str_('[20, 20]'), np.int64(1)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[8, 40], [8, 1], [8, 26], [8, 4], [8, 32], [8, 22], [8, 34], [8, 16], [8, 47], [8, 8], [8, 25], [8, 19], [8, 38], [8, 2], [8, 45], [8, 5], [8, 44], [8, 29], [8, 37], [8, 28], [8, 13], [8, 36], [8, 7], [8, 35], [8, 48], [8, 20], [8, 23], [8, 10], [8, 31], [8, 17], [8, 11], [8, 41], [8, 14], [8, 27], [8, 18], [8, 39], [8, 33], [8, 15], [8, 6], [8, 42], [8, 3], [8, 12], [8, 0], [8, 24], [8, 9], [8, 43], [8, 30], [8, 21], [8, 46]]\\nModel Losses: [ 0.205036,  0.174756,  0.157687,  0.157285,  0.157016,  0.150714,  0.140038,  0.137736,  0.132087,  0.073776,  0.04815 ,  0.039263,  0.037673,  0.017632,  0.013904, -0.025641, -0.046815, -0.052963, -0.055853, -0.080468, -0.08049 , -0.099261, -0.10383 , -0.122733, -0.124741, -0.132528, -0.13311 , -0.151628, -0.157658, -0.178521, -0.198125, -0.224117, -0.239484, -0.284699, -0.326229, -0.531849, -0.89415 , -0.998195, -1.026945, -1.252284, -1.349038, -1.482114, -1.68949 , -1.69552 , -1.75433 , -1.841906, -1.969648, -2.275099, -2.856373]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(2)), (np.str_('[20, 20]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 9 #################\\nTime: 2024-12-04 17:12:57\\nDataset: val | Loss: MAE\\nCombinations: [[9, 29], [9, 30], [9, 35], [9, 31], [9, 32], [9, 36], [9, 33], [9, 34]]\\nModel Losses: [0.015164, 0.015519, 0.015636, 0.01565 , 0.015732, 0.015751, 0.015887, 0.016075]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(3))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[9, 35], [9, 31], [9, 30], [9, 32], [9, 34], [9, 36], [9, 33], [9, 29]]\\nModel Losses: [-0.445339, -0.596272, -0.716746, -1.022672, -1.127666, -1.17498 , -1.307515, -3.159665]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[9, 30], [9, 33], [9, 35], [9, 34], [9, 36], [9, 32], [9, 31], [9, 29]]\\nModel Losses: [0.014191, 0.014258, 0.014326, 0.014432, 0.014527, 0.014642, 0.014948, 0.014997]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[9, 30], [9, 31], [9, 35], [9, 34], [9, 32], [9, 33], [9, 36], [9, 29]]\\nModel Losses: [-0.610369, -1.597269, -1.658643, -1.942181, -2.068321, -2.357524, -3.120086, -3.145517]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 10 #################\\nTime: 2024-12-04 20:10:18\\nDataset: val | Loss: MAE\\nCombinations: [[10, 6], [10, 2], [10, 4], [10, 0], [10, 3], [10, 7], [10, 1], [10, 5]]\\nModel Losses: [0.007424, 0.007885, 0.008559, 0.008785, 0.009054, 0.009302, 0.015049, 0.015724]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[10, 6], [10, 2], [10, 3], [10, 4], [10, 7], [10, 0], [10, 5], [10, 1]]\\nModel Losses: [ 0.699539,  0.692481,  0.630059,  0.601818,  0.582019,  0.541338, -1.297017, -2.499742]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[10, 2], [10, 6], [10, 7], [10, 3], [10, 4], [10, 0], [10, 5], [10, 1]]\\nModel Losses: [0.008841, 0.00932 , 0.009705, 0.009796, 0.012023, 0.014079, 0.014369, 0.014773]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[10, 6], [10, 2], [10, 7], [10, 4], [10, 3], [10, 0], [10, 1], [10, 5]]\\nModel Losses: [ 0.437432,  0.344327,  0.302479,  0.210006,  0.073559, -0.922822, -2.055568, -2.074318]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 11 #################\\nTime: 2024-12-15 17:18:26\\nDataset: val | Loss: MAE\\nCombinations: [[11, 2], [11, 4], [11, 0], [11, 1], [11, 3]]\\nModel Losses: [0.007291, 0.00773 , 0.007948, 0.008044, 0.008153]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[11, 1], [11, 3], [11, 2], [11, 4], [11, 0]]\\nModel Losses: [0.624272, 0.618771, 0.608902, 0.582323, 0.525961]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[11, 0], [11, 2], [11, 1], [11, 3], [11, 4]]\\nModel Losses: [0.009364, 0.009813, 0.009844, 0.009883, 0.010535]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[11, 0], [11, 3], [11, 1], [11, 2], [11, 4]]\\nModel Losses: [0.476718, 0.43023 , 0.412188, 0.261915, 0.166532]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\"]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_runs = line_str.split(\"\\n\\n\\n\")\n",
    "# remove empty strings\n",
    "list_of_runs = [run for run in list_of_runs if run != \"\"][:-1]\n",
    "list_of_runs\n",
    "\n",
    "runs_of_interest = list_of_runs[:]\n",
    "\n",
    "runs_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_of_dfs = []\n",
    "for run in runs_of_interest:\n",
    "    \n",
    "    splitted_run = run.split(\"\\n\")\n",
    "    # filter out empty strings\n",
    "    splitted_run = [elem for elem in splitted_run if elem != \"\"]\n",
    "\n",
    "    run_id = int(splitted_run[0].split(\" \")[2])\n",
    "    if (run_id < 0) or (run_id > 10):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    comb_lists = []\n",
    "    model_losses = []\n",
    "    zero_baselines = []\n",
    "    naive_baselines = []\n",
    "    avg_baselines = []\n",
    "    dataset_types = []\n",
    "    loss_types = []\n",
    "    \n",
    "    for elem in splitted_run[2:]:\n",
    "\n",
    "        by_bar = elem.split(\"|\")\n",
    "        \n",
    "        if len(by_bar) == 2:\n",
    "            dataset = by_bar[0].split(\":\")[1].strip()\n",
    "            loss_type = by_bar[1].split(\":\")[1].strip()\n",
    "\n",
    "            \n",
    "        elif len(by_bar) == 1:\n",
    "            \n",
    "            if by_bar[0] == \"\":\n",
    "                continue\n",
    "            \n",
    "            array_type, array = by_bar[0].split(\":\")\n",
    "            array_type = array_type.strip()\n",
    "            \n",
    "            if array_type == \"Hyperparameters\":\n",
    "                continue\n",
    "            \n",
    "            array = array.strip()\n",
    "            array = np.array(ast.literal_eval(array))\n",
    "\n",
    "            \n",
    "            if array_type == \"Combinations\":\n",
    "                            \n",
    "                dataset_types.extend(np.repeat(dataset, len(array)))\n",
    "                loss_types.extend(np.repeat(loss_type, len(array)))\n",
    "                \n",
    "                comb_lists.extend(array)\n",
    "                \n",
    "            elif array_type == \"Model Losses\":\n",
    "                model_losses.extend(array)\n",
    "                \n",
    "            elif array_type == \"BL zero Losses\":\n",
    "                zero_baselines.extend(array)\n",
    "                \n",
    "            elif array_type == \"BL naive Losses\":\n",
    "                naive_baselines.extend(array)\n",
    "\n",
    "            elif array_type == \"BL avg Losses\":\n",
    "                avg_baselines.extend(array)\n",
    "\n",
    "            else:\n",
    "                print(array_type, array)\n",
    "                raise\n",
    "      \n",
    "    run_df = pd.DataFrame({\n",
    "        \"run_id\": run_id,\n",
    "        \"dataset\": dataset_types,\n",
    "        \"loss_type\": loss_types,\n",
    "        \"combinations\": comb_lists,\n",
    "        \"model_losses\": model_losses,\n",
    "        \"zero_baselines\": zero_baselines,\n",
    "        \"naive_baselines\": naive_baselines,\n",
    "        \"avg_baselines\": avg_baselines\n",
    "    })\n",
    "    \n",
    "    list_of_dfs.append(run_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(list_of_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate through all combinations and load hyperparameters\n",
    "import json\n",
    "path_to_checkpoints = \"_occupancy_forecasting/checkpoints/wrap_up\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    comb = row[\"combinations\"]\n",
    "    \n",
    "    comb_path = os.path.join(path_to_checkpoints, f\"run_{comb[0]}/comb_{comb[1]}\")\n",
    "    \n",
    "    hyperparameters_path = os.path.join(comb_path, \"hyperparameters.json\")\n",
    "\n",
    "    \n",
    "    hyperparameters = json.load(open(hyperparameters_path, \"r\"))\n",
    "    \n",
    "    # overwrite combinations with tuple of run_id and comb_id\n",
    "    results_df.at[idx, \"combinations\"] = (row[\"run_id\"], comb[1])\n",
    "    \n",
    "    # add all hyperparameters to the dataframe\n",
    "    for key, value in hyperparameters.items():\n",
    "        results_df.at[idx, key] = str(value)\n",
    "\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>combinations</th>\n",
       "      <th>model_losses</th>\n",
       "      <th>zero_baselines</th>\n",
       "      <th>naive_baselines</th>\n",
       "      <th>avg_baselines</th>\n",
       "      <th>info</th>\n",
       "      <th>model_class</th>\n",
       "      <th>...</th>\n",
       "      <th>layer_norm</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>forget_gate</th>\n",
       "      <th>include_x_features</th>\n",
       "      <th>zero_sample_drop_rate</th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_features_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>occcount</th>\n",
       "      <th>feature_store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 7)</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(10, 3)</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 9: weather</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 0)</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(10, 0)</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 9: weather</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset loss_type combinations  model_losses  zero_baselines  \\\n",
       "0       9    test       MAE       (9, 5)      0.008764        0.017787   \n",
       "1       9    test       MAE       (9, 7)      0.009796        0.017787   \n",
       "8      10    test       MAE      (10, 3)      0.009796        0.017787   \n",
       "3       9    test       MAE       (9, 2)      0.010636        0.017787   \n",
       "5       9    test       MAE       (9, 0)      0.013729        0.017787   \n",
       "9      10    test       MAE      (10, 0)      0.014079        0.017787   \n",
       "\n",
       "   naive_baselines  avg_baselines  \\\n",
       "0         0.016627       0.011299   \n",
       "1         0.016627       0.011299   \n",
       "8         0.016627       0.011299   \n",
       "3         0.016627       0.011299   \n",
       "5         0.016627       0.011299   \n",
       "9         0.016627       0.011299   \n",
       "\n",
       "                                          info model_class  ... layer_norm  \\\n",
       "0  Run 8: ed lstm - longer forecasting horizon     ed_lstm  ...      False   \n",
       "1  Run 8: ed lstm - longer forecasting horizon     ed_lstm  ...      False   \n",
       "8                               Run 9: weather     ed_lstm  ...      False   \n",
       "3  Run 8: ed lstm - longer forecasting horizon     ed_lstm  ...      False   \n",
       "5  Run 8: ed lstm - longer forecasting horizon     ed_lstm  ...      False   \n",
       "9                               Run 9: weather     ed_lstm  ...      False   \n",
       "\n",
       "  weight_decay forget_gate include_x_features zero_sample_drop_rate x_size  \\\n",
       "0            0        True               True                   0.1      2   \n",
       "1            0        True               True                   0.1     12   \n",
       "8            0        True               True                   0.1      9   \n",
       "3            0        True               True                   0.1      6   \n",
       "5            0        True               True                   0.1      1   \n",
       "9            0        True               True                   0.1      3   \n",
       "\n",
       "  y_features_size y_size occcount  \\\n",
       "0               1      1    False   \n",
       "1              11      1    False   \n",
       "8               8      1    False   \n",
       "3               5      1    False   \n",
       "5               0      1    False   \n",
       "9               2      1    False   \n",
       "\n",
       "                                       feature_store  \n",
       "0  occrate_coursenumber_exam_test_tutorium_cancel...  \n",
       "1  occrate_coursenumber_exam_test_tutorium_cancel...  \n",
       "8  occrate_coursenumber_exam_test_tutorium_cancel...  \n",
       "3  occrate_coursenumber_exam_test_tutorium_cancel...  \n",
       "5  occrate_coursenumber_exam_test_tutorium_cancel...  \n",
       "9  occrate_coursenumber_exam_test_tutorium_cancel...  \n",
       "\n",
       "[6 rows x 43 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out all runs with a certain loss type\n",
    "\n",
    "def filter_dataframe_by_column_value(df, column, value):\n",
    "    return df[df[column] == value].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# loss type = MAE\n",
    "results_filt = filter_dataframe_by_column_value(results_df, \"loss_type\", \"MAE\")\n",
    "# model class = ed_lstm\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"model_class\", \"ed_lstm\")\n",
    "# split_by = time\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"split_by\", \"time\")\n",
    "# frequency = 5min\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"frequency\", \"5min\")\n",
    "# lr = 0.001\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"lr\", \"0.001\")\n",
    "# batch_size = \"32\"\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"batch_size\", \"32\")\n",
    "# with_examweek = False\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"with_examweek\", \"False\")\n",
    "# course_encoding_dim = 3\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"course_encoding_dim\", \"3\")\n",
    "# room_id = 0\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"room_ids\", \"[0]\")\n",
    "\n",
    "\n",
    "# num_layers = 3\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"num_layers\", \"3\")\n",
    "\n",
    "# hidden_size = \"[32, 32]\"\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"hidden_size\", \"[32, 32]\")\n",
    "\n",
    "## x_horizon = 36\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"y_horizon\", \"36\")\n",
    "\n",
    "# finalize filtering\n",
    "results_out = filter_dataframe_by_column_value(results_filt, \"dataset\", \"test\")\n",
    "results_out = results_out.sort_values(by=\"model_losses\")\n",
    "\n",
    "results_out.drop_duplicates(subset=[\"features\"], keep=\"first\", inplace=True)\n",
    "results_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>model_losses</th>\n",
       "      <th>avg_baselines</th>\n",
       "      <th>naive_baselines</th>\n",
       "      <th>zero_baselines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[occrate, avgocc, coursenumber]</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[occrate, avgocc, coursenumber, exam, tutorium...</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[occrate, avgocc, coursenumber, weather]</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[occrate, avgocc, coursenumber, exam, tutorium...</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[occrate]</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[occrate, avgocc, coursenumber, tl]</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  model_losses  \\\n",
       "0                    [occrate, avgocc, coursenumber]      0.008764   \n",
       "1  [occrate, avgocc, coursenumber, exam, tutorium...      0.009796   \n",
       "8           [occrate, avgocc, coursenumber, weather]      0.009796   \n",
       "3  [occrate, avgocc, coursenumber, exam, tutorium...      0.010636   \n",
       "5                                          [occrate]      0.013729   \n",
       "9                [occrate, avgocc, coursenumber, tl]      0.014079   \n",
       "\n",
       "   avg_baselines  naive_baselines  zero_baselines  \n",
       "0       0.011299         0.016627        0.017787  \n",
       "1       0.011299         0.016627        0.017787  \n",
       "8       0.011299         0.016627        0.017787  \n",
       "3       0.011299         0.016627        0.017787  \n",
       "5       0.011299         0.016627        0.017787  \n",
       "9       0.011299         0.016627        0.017787  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_results = results_out[[\"features\", \"model_losses\", \"avg_baselines\", \"naive_baselines\", \"zero_baselines\"]]\n",
    "\n",
    "# split features by \"_\"\n",
    "pretty_results[\"features\"] = pretty_results[\"features\"].apply(lambda x: x.split(\"_\"))\n",
    "pretty_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 2024-04-09 07:00:00\\nstart = datetime.datetime(2024, 4, 9, 7, 0, 0)\\n# 2024-04-09 21:00:00\\nstop = datetime.datetime(2024, 4, 9, 21, 0, 0)\\n\\nplot_data = dfg.filter_by_timestamp(data, \"datetime\", start, stop) \\n\\n# 3 subplots in 3 rows\\nfig, axs = plt.subplots(3, 1, figsize=(15, 10))\\n# plot occrate\\naxs[0].plot(plot_data[\"datetime\"], plot_data[\"occrate\"], label=\"ocrate\")\\n# plot registered\\nregistered = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\\naxs[1].plot(plot_data[\"datetime\"], registered, label=\"registered\")\\n# temperature\\ntemperature = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\\naxs[2].plot(plot_data[\"datetime\"], temperature, label=\"temperature\")\\nplt.show()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# 2024-04-09 07:00:00\n",
    "start = datetime.datetime(2024, 4, 9, 7, 0, 0)\n",
    "# 2024-04-09 21:00:00\n",
    "stop = datetime.datetime(2024, 4, 9, 21, 0, 0)\n",
    "\n",
    "plot_data = dfg.filter_by_timestamp(data, \"datetime\", start, stop) \n",
    "\n",
    "# 3 subplots in 3 rows\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10))\n",
    "# plot occrate\n",
    "axs[0].plot(plot_data[\"datetime\"], plot_data[\"occrate\"], label=\"ocrate\")\n",
    "# plot registered\n",
    "registered = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\n",
    "axs[1].plot(plot_data[\"datetime\"], registered, label=\"registered\")\n",
    "# temperature\n",
    "temperature = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\n",
    "axs[2].plot(plot_data[\"datetime\"], temperature, label=\"temperature\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig = make_subplots(\n",
    "#    rows=3, \n",
    "#    cols=1, \n",
    "#    subplot_titles=(\"Occupancy Rate\", \"Registered Students\", \"Temperature in Linz\")\n",
    "#    )\n",
    "#x_col = \"datetime\"\n",
    "\n",
    "## occupancy rate\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=plot_data[x_col], \n",
    "#        y=plot_data[\"occrate\"],\n",
    "#        mode='lines', \n",
    "#        name='Occupancy Rate'\n",
    "#        ),\n",
    "#    row=1, col=1\n",
    "#    )\n",
    "## registered students\n",
    "#registered = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=plot_data[x_col], \n",
    "#        y=registered,\n",
    "#        mode='lines', \n",
    "#        name='Registered Students'\n",
    "#        ),\n",
    "#    row=2, col=1\n",
    "#    )\n",
    "\n",
    "## temperature\n",
    "#temperature = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=plot_data[x_col], \n",
    "#        y=temperature,\n",
    "#        mode='lines', \n",
    "#        name='Temperature in Linz'\n",
    "#        ),\n",
    "#    row=3, col=1\n",
    "#    )\n",
    "\n",
    "## set y axis between 0 and 1\n",
    "#fig.update_yaxes(range=[-0.1, 1], row=1, col=1)\n",
    "#fig.update_yaxes(range=[-0.1, 1], row=2, col=1)\n",
    "#fig.update_yaxes(range=[-0.1, 1], row=3, col=1)\n",
    "#fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
