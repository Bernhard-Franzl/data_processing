{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from _dfguru import DataFrameGuru as DFG\n",
    "from _occupancy_forecasting import MasterTrainer\n",
    "from _occupancy_forecasting import load_data\n",
    "from _occupancy_forecasting import avoid_name_conflicts\n",
    "from _evaluating import ParameterSearch\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "dfg = DFG()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "############ Inputs ############\n",
    "#args = parse_arguments()\n",
    "#args = prompt_for_missing_arguments(args)0\n",
    "#n_run = args.n_run\n",
    "#n_param = args.n_param\n",
    "\n",
    "n_run = 10\n",
    "n_param = 0\n",
    "\n",
    "overwrite = True\n",
    "################################\n",
    "\n",
    "param_dir = \"_occupancy_forecasting/parameters/wrap_up\"\n",
    "tb_log_dir = \"_occupancy_forecasting/training_logs/wrap_up\"\n",
    "cp_log_dir = \"_occupancy_forecasting/checkpoints/wrap_up\"\n",
    "path_to_data = \"data/occupancy_forecasting\"\n",
    "\n",
    "frequency = \"5min\"\n",
    "split_by = \"time\"\n",
    "\n",
    "\n",
    "train_dict, val_dict, test_dict = load_data(\n",
    "    path_to_data_dir=path_to_data, \n",
    "    frequency=frequency, \n",
    "    split_by=split_by,\n",
    "    dfguru=dfg,\n",
    "    with_examweek=False\n",
    ")\n",
    "\n",
    "\n",
    "data = train_dict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "helper_file = os.path.join(\"data/occupancy_forecasting\", \"helpers_occpred.json\")\n",
    "with open(helper_file, \"r\") as f:\n",
    "    helper = json.load(f)       \n",
    "norm_registered = helper[\"columns_to_normalize\"][\"registered\"]\n",
    "norm_temperature = helper[\"columns_to_normalize\"][\"tl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "from _plotting import DataPlotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"################# Run: 0 #################\\nTime: 2024-11-25 12:48:24\\nDataset: train | Loss: MAE\\nCombinations: [[0, 9], [0, 4], [0, 1], [0, 5], [0, 10], [0, 7], [0, 6], [0, 2], [0, 3], [0, 8], [0, 0]]\\nModel Losses: [0.009174, 0.009215, 0.009297, 0.009307, 0.009342, 0.009409, 0.009479, 0.009513, 0.009543, 0.009601, 0.011038]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1)), (np.str_('occrate_type_registered_lecture_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[0, 0], [0, 4], [0, 5], [0, 6], [0, 9], [0, 1], [0, 3], [0, 2], [0, 7], [0, 10], [0, 8]]\\nModel Losses: [-1.271687, -1.556957, -1.624302, -1.873138, -1.884765, -1.897996, -1.941796, -1.957662, -2.071056, -2.220009, -2.245946]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[0, 5], [0, 4], [0, 9], [0, 1], [0, 2], [0, 3], [0, 6], [0, 10], [0, 8], [0, 7], [0, 0]]\\nModel Losses: [0.006804, 0.006821, 0.007258, 0.007267, 0.007291, 0.007312, 0.007422, 0.007476, 0.007774, 0.007785, 0.009546]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[0, 5], [0, 0], [0, 4], [0, 6], [0, 3], [0, 1], [0, 2], [0, 9], [0, 7], [0, 8], [0, 10]]\\nModel Losses: [-0.658495, -0.755675, -0.796193, -0.918626, -0.987752, -1.009844, -1.013806, -1.106653, -1.115457, -1.179837, -1.256963]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[0, 1], [0, 2], [0, 7], [0, 3], [0, 10], [0, 9], [0, 8], [0, 4], [0, 6], [0, 5], [0, 0]]\\nModel Losses: [0.007901, 0.00805 , 0.008058, 0.008071, 0.008272, 0.008278, 0.008304, 0.00834 , 0.008422, 0.00848 , 0.008544]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_lecture_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[0, 4], [0, 1], [0, 9], [0, 6], [0, 0], [0, 3], [0, 7], [0, 10], [0, 2], [0, 8], [0, 5]]\\nModel Losses: [-0.230158, -0.257588, -0.347184, -0.372477, -0.379921, -0.392089, -0.401578, -0.402907, -0.41668 , -0.440488, -0.459776]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 1 #################\\nTime: 2024-11-25 14:21:00\\nDataset: train | Loss: MAE\\nCombinations: [[1, 13], [1, 19], [1, 15], [1, 12], [1, 7], [1, 16], [1, 14], [1, 4], [1, 18], [1, 5], [1, 3], [1, 11], [1, 8], [1, 2], [1, 1], [1, 9], [1, 17], [1, 6], [1, 10], [1, 0]]\\nModel Losses: [0.005365, 0.005464, 0.005661, 0.005747, 0.005833, 0.005853, 0.006014, 0.006079, 0.006143, 0.006166, 0.006189, 0.006234, 0.006281, 0.006321, 0.006533, 0.00666 , 0.006695, 0.007292, 0.007778, 0.009012]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(4)), (np.str_('[64]'), np.int64(1))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[1, 19], [1, 16], [1, 13], [1, 7], [1, 15], [1, 18], [1, 14], [1, 12], [1, 4], [1, 11], [1, 8], [1, 2], [1, 5], [1, 1], [1, 3], [1, 17], [1, 9], [1, 6], [1, 10], [1, 0]]\\nModel Losses: [ 0.193049,  0.078227,  0.067008,  0.047441,  0.007611, -0.051807, -0.052111, -0.058241, -0.094334, -0.105558, -0.109685, -0.113618, -0.12943 , -0.178153, -0.228242, -0.333586, -0.425712, -0.451364, -0.515966, -0.603822]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(4)), (np.str_('[64]'), np.int64(1))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[1, 11], [1, 2], [1, 4], [1, 5], [1, 14], [1, 3], [1, 1], [1, 15], [1, 12], [1, 13], [1, 9], [1, 19], [1, 7], [1, 16], [1, 18], [1, 8], [1, 17], [1, 6], [1, 10], [1, 0]]\\nModel Losses: [0.005578, 0.005615, 0.005643, 0.005658, 0.005674, 0.005765, 0.005828, 0.005851, 0.006005, 0.00604 , 0.00604 , 0.006152, 0.006215, 0.00623 , 0.006381, 0.006392, 0.006484, 0.00672 , 0.007572, 0.00824 ]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(2)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[1, 14], [1, 5], [1, 2], [1, 1], [1, 11], [1, 4], [1, 13], [1, 3], [1, 12], [1, 6], [1, 15], [1, 0], [1, 9], [1, 19], [1, 8], [1, 18], [1, 10], [1, 16], [1, 17], [1, 7]]\\nModel Losses: [-0.600109, -0.617761, -0.703539, -0.728203, -0.74097 , -0.94692 , -0.965587, -1.033466, -1.057283, -1.249861, -1.286699, -1.347372, -1.356661, -1.364595, -1.777167, -1.816296, -1.984959, -2.095326, -2.128897, -2.297296]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(2)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[1, 1], [1, 2], [1, 3], [1, 11], [1, 16], [1, 12], [1, 7], [1, 13], [1, 10], [1, 6], [1, 17], [1, 14], [1, 5], [1, 0], [1, 4], [1, 18], [1, 8], [1, 19], [1, 15], [1, 9]]\\nModel Losses: [0.006296, 0.006531, 0.006542, 0.006658, 0.006936, 0.007133, 0.007158, 0.007328, 0.007382, 0.007402, 0.007413, 0.007438, 0.007457, 0.007743, 0.007834, 0.007956, 0.008018, 0.008085, 0.008222, 0.008387]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(2)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[1, 1], [1, 11], [1, 3], [1, 2], [1, 13], [1, 0], [1, 12], [1, 6], [1, 17], [1, 16], [1, 7], [1, 4], [1, 5], [1, 14], [1, 19], [1, 8], [1, 15], [1, 18], [1, 9], [1, 10]]\\nModel Losses: [ 0.074322,  0.033226, -0.095172, -0.126706, -0.139129, -0.193608, -0.217224, -0.287716, -0.31871 , -0.336765, -0.359967, -0.388613, -0.494078, -0.576274, -0.6339  , -0.669851, -0.79921 , -0.819367, -0.865894, -1.220506]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(2)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[64, 32]'), np.int64(2)), (np.str_('[64]'), np.int64(3))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 1 #################\\nTime: 2024-11-25 16:41:19\\nDataset: train | Loss: MAE\\nCombinations: [[1, 27], [1, 22], [1, 28], [1, 23], [1, 24], [1, 26], [1, 20], [1, 25], [1, 29], [1, 21], [1, 30]]\\nModel Losses: [0.003739, 0.004822, 0.004867, 0.004951, 0.006118, 0.006558, 0.006774, 0.006924, 0.007001, 0.007033, 0.007324]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[1, 27], [1, 28], [1, 23], [1, 22], [1, 24], [1, 26], [1, 20], [1, 25], [1, 21], [1, 29], [1, 30]]\\nModel Losses: [ 0.580019,  0.27326 ,  0.261062,  0.221271, -0.115581, -0.15577 , -0.211604, -0.340667, -0.449735, -0.49523 , -0.806164]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[1, 24], [1, 21], [1, 25], [1, 27], [1, 28], [1, 22], [1, 23], [1, 26], [1, 29], [1, 30], [1, 20]]\\nModel Losses: [0.005854, 0.005858, 0.005885, 0.005916, 0.00616 , 0.006186, 0.006199, 0.006304, 0.006585, 0.007247, 0.007576]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[1, 22], [1, 24], [1, 25], [1, 21], [1, 23], [1, 26], [1, 27], [1, 29], [1, 28], [1, 30], [1, 20]]\\nModel Losses: [-0.881361, -0.922036, -0.922258, -0.964145, -1.207267, -1.336592, -1.510207, -1.820202, -1.862806, -1.888185, -2.928589]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[1, 21], [1, 26], [1, 23], [1, 22], [1, 20], [1, 27], [1, 28], [1, 24], [1, 25], [1, 29], [1, 30]]\\nModel Losses: [0.006792, 0.007105, 0.007418, 0.0077, 0.007704, 0.008037, 0.008224, 0.008462, 0.00861 , 0.009036, 0.009233]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[1, 21], [1, 26], [1, 23], [1, 22], [1, 28], [1, 25], [1, 30], [1, 29], [1, 24], [1, 20], [1, 27]]\\nModel Losses: [-0.08976 , -0.131046, -0.33059 , -0.538394, -0.818474, -0.821013, -0.871533, -0.892232, -1.085593, -1.175527, -1.189492]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[128, 64, 32]'), np.int64(5))]), ('num_layers', [(np.str_('0'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 2 #################\\nTime: 2024-11-25 16:42:42\\nDataset: train | Loss: MAE\\nCombinations: [[2, 7], [2, 3], [2, 8], [2, 9], [2, 6], [2, 4], [2, 2], [2, 1], [2, 10], [2, 5], [2, 0]]\\nModel Losses: [0.005578, 0.005769, 0.005981, 0.005995, 0.006217, 0.006344, 0.006638, 0.006871, 0.007056, 0.007118, 0.008227]\\nBL zero Losses: [0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[2, 7], [2, 6], [2, 3], [2, 9], [2, 8], [2, 4], [2, 2], [2, 1], [2, 5], [2, 0], [2, 10]]\\nModel Losses: [ 0.256068,  0.024687, -0.097699, -0.100894, -0.221453, -0.23891 , -0.258536, -0.471042, -0.504981, -0.705008, -1.184513]\\nBL zero Losses: [-46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[2, 3], [2, 9], [2, 2], [2, 4], [2, 5], [2, 8], [2, 1], [2, 7], [2, 6], [2, 10], [2, 0]]\\nModel Losses: [0.005063, 0.00511 , 0.005153, 0.005216, 0.005338, 0.00534 , 0.005374, 0.00568 , 0.005703, 0.005722, 0.007419]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test_offsite'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[2, 3], [2, 2], [2, 1], [2, 4], [2, 9], [2, 8], [2, 5], [2, 6], [2, 7], [2, 10], [2, 0]]\\nModel Losses: [-0.20543 , -0.307817, -0.3122  , -0.66862 , -0.690103, -0.840497, -0.98646 , -1.249429, -1.28819 , -1.35698 , -1.728006]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture'), np.int64(1)), (np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled_tutorium_test'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[2, 7], [2, 2], [2, 3], [2, 6], [2, 9], [2, 1], [2, 4], [2, 5], [2, 8], [2, 0], [2, 10]]\\nModel Losses: [0.005675, 0.005921, 0.005942, 0.006138, 0.006281, 0.006313, 0.006642, 0.007396, 0.007538, 0.007672, 0.007978]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[2, 3], [2, 2], [2, 7], [2, 6], [2, 9], [2, 1], [2, 4], [2, 5], [2, 10], [2, 8], [2, 0]]\\nModel Losses: [ 0.244264,  0.184584,  0.165146,  0.104136,  0.096953, -0.018902, -0.056965, -0.20548 , -0.406115, -0.557998, -1.889594]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_exam'), np.int64(1)), (np.str_('occrate_lecture_exam_cancelled'), np.int64(1)), (np.str_('occrate_type_registered'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite_lecture'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 2 #################\\nTime: 2024-11-26 11:04:12\\nDataset: train | Loss: MAE\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.00259 , 0.002844]\\nBL zero Losses: [0.025558, 0.025558]\\nBL naive Losses: [0.023304, 0.023304]\\nBL avg Losses: [0.023492, 0.023492]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: train | Loss: R2\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.70743, 0.63676]\\nBL zero Losses: [-46.051517, -46.051517]\\nBL naive Losses: [-29.56692, -29.56692]\\nBL avg Losses: [-24.358385, -24.358385]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: val | Loss: MAE\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.00567 , 0.005736]\\nBL zero Losses: [0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [-2.000536, -2.189111]\\nBL zero Losses: [-29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[2, 12], [2, 11]]\\nModel Losses: [0.007281, 0.007356]\\nBL zero Losses: [0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[2, 11], [2, 12]]\\nModel Losses: [-0.705091, -1.517717]\\nBL zero Losses: [-18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(2))]), ('dropout', [(np.str_('0'), np.int64(2))]), ('features', [(np.str_('occrate_type_registered_exam_lecture'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2))]), ('x_horizon', [(np.str_('24'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2))])]\",\n",
       " \"\\n################# Run: 4 #################\\nTime: 2024-11-26 11:49:05\\nDataset: val | Loss: MAE\\nCombinations: [[4, 2], [4, 1], [4, 0]]\\nModel Losses: [0.008509, 0.009223, 0.017107]\\nBL zero Losses: [0.022858, 0.022858, 0.022858]\\nBL naive Losses: [0.015575, 0.015575, 0.015575]\\nBL avg Losses: [0.0141, 0.0141, 0.0141]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[4, 2], [4, 1], [4, 0]]\\nModel Losses: [ 0.349202,  0.113005, -1.065243]\\nBL zero Losses: [-0.088206, -0.088206, -0.088206]\\nBL naive Losses: [-25.300606, -25.300606, -25.300606]\\nBL avg Losses: [-1.20321, -1.20321, -1.20321]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[4, 1], [4, 2], [4, 0]]\\nModel Losses: [0.009723, 0.010195, 0.015032]\\nBL zero Losses: [0.01809, 0.01809, 0.01809]\\nBL naive Losses: [0.016911, 0.016911, 0.016911]\\nBL avg Losses: [0.011491, 0.011491, 0.011491]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[4, 1], [4, 2], [4, 0]]\\nModel Losses: [ 0.422707,  0.231156, -1.89839 ]\\nBL zero Losses: [-0.472649, -0.472649, -0.472649]\\nBL naive Losses: [-21.483574, -21.483574, -21.483574]\\nBL avg Losses: [-0.897995, -0.897995, -0.897995]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(3))]), ('dropout', [(np.str_('0'), np.int64(3))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_type_registered_exam'), np.int64(1)), (np.str_('occrate_type_registered_exam_test_tutorium_cancelled_offsite'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3))]), ('num_layers', [(np.str_('2'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3))]), ('x_horizon', [(np.str_('72'), np.int64(3))]), ('y_horizon', [(np.str_('36'), np.int64(3))])]\",\n",
       " \"\\n\\n################# Run: 5 #################\\nTime: 2024-11-26 15:47:12\\nDataset: val | Loss: MAE\\nCombinations: [[5, 16], [5, 1], [5, 14], [5, 5], [5, 10], [5, 4], [5, 15], [5, 11], [5, 13], [5, 12], [5, 8], [5, 3], [5, 9], [5, 7], [5, 2], [5, 6], [5, 0]]\\nModel Losses: [0.004702, 0.004728, 0.004769, 0.004769, 0.004776, 0.00478 , 0.004796, 0.004831, 0.004889, 0.004915, 0.00495 , 0.005033, 0.005065, 0.005341, 0.005644, 0.005784, 0.007363]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('5'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(2)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite'), np.int64(3))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[5, 16], [5, 5], [5, 12], [5, 7], [5, 14], [5, 13], [5, 1], [5, 8], [5, 11], [5, 15], [5, 10], [5, 4], [5, 6], [5, 2], [5, 3], [5, 9], [5, 0]]\\nModel Losses: [-0.218303, -0.361199, -0.469523, -0.523856, -0.531198, -0.547082, -0.550233, -0.555581, -0.560754, -0.594154, -0.717199, -0.725033, -1.077306, -1.301381, -1.388305, -1.50122 , -2.879412]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(1)), (np.str_('5'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber_exam'), np.int64(1)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite'), np.int64(2)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite_weather'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[5, 1], [5, 8], [5, 11], [5, 14], [5, 2], [5, 13], [5, 10], [5, 3], [5, 12], [5, 9], [5, 15], [5, 16], [5, 7], [5, 6], [5, 5], [5, 4], [5, 0]]\\nModel Losses: [0.005779, 0.005779, 0.005857, 0.0059  , 0.006063, 0.006221, 0.006232, 0.006278, 0.00629 , 0.006301, 0.006387, 0.006466, 0.006965, 0.007044, 0.007113, 0.007382, 0.00832 ]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(1)), (np.str_('5'), np.int64(1))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(4)), (np.str_('occrate_type_registered_exam'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[5, 11], [5, 10], [5, 2], [5, 1], [5, 16], [5, 8], [5, 15], [5, 13], [5, 3], [5, 5], [5, 12], [5, 7], [5, 14], [5, 9], [5, 6], [5, 4], [5, 0]]\\nModel Losses: [ 0.195995,  0.140819,  0.110799,  0.075032, -0.005665, -0.008376, -0.022353, -0.046668, -0.098944, -0.109979, -0.113518, -0.117702, -0.173238, -0.214145, -0.252696, -0.60466 , -3.004672]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(1)), (np.str_('5'), np.int64(1))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(2)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled_offsite'), np.int64(2)), (np.str_('occrate_type_registered_exam'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 6 #################\\nTime: 2024-11-26 21:24:45\\nDataset: val | Loss: MAE\\nCombinations: [[6, 11], [6, 13], [6, 16], [6, 18], [6, 31], [6, 1], [6, 3], [6, 23], [6, 33], [6, 6], [6, 8], [6, 24], [6, 21], [6, 38], [6, 22], [6, 34], [6, 4], [6, 32], [6, 19], [6, 14], [6, 7], [6, 39], [6, 2], [6, 9], [6, 29], [6, 26], [6, 12], [6, 27], [6, 37], [6, 36], [6, 17], [6, 28], [6, 10], [6, 30], [6, 35], [6, 5], [6, 15], [6, 0], [6, 25], [6, 20]]\\nModel Losses: [0.004581, 0.004723, 0.004731, 0.00474 , 0.004768, 0.004816, 0.004843, 0.004904, 0.004904, 0.004969, 0.005045, 0.005146, 0.005156, 0.005188, 0.005203, 0.005327, 0.005517, 0.005554, 0.005685, 0.005718, 0.005739, 0.005778, 0.005784, 0.005792, 0.005948, 0.005957, 0.005979, 0.006083, 0.006235, 0.006385, 0.006639, 0.006748, 0.007438, 0.007452, 0.007492, 0.00754 , 0.007564, 0.00759 , 0.007614, 0.007643]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(3)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(3)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(1)), (np.str_('[64, 128]'), np.int64(4))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[6, 13], [6, 6], [6, 8], [6, 1], [6, 11], [6, 3], [6, 24], [6, 23], [6, 31], [6, 18], [6, 16], [6, 26], [6, 4], [6, 38], [6, 33], [6, 9], [6, 29], [6, 34], [6, 21], [6, 22], [6, 14], [6, 19], [6, 36], [6, 12], [6, 2], [6, 39], [6, 32], [6, 7], [6, 27], [6, 30], [6, 37], [6, 10], [6, 20], [6, 17], [6, 15], [6, 35], [6, 28], [6, 5], [6, 25], [6, 0]]\\nModel Losses: [-0.169109, -0.303833, -0.398899, -0.517575, -0.517724, -0.546941, -0.547492, -0.560447, -0.563973, -0.569382, -0.574677, -0.581566, -0.713319, -0.717757, -0.854848, -0.864661, -0.868608, -0.92575 , -0.932865, -0.986847, -1.003365, -1.097699, -1.25115 , -1.385386, -1.437367, -1.567663, -1.640652, -1.702991, -1.800106, -2.068086, -2.068883, -2.125148, -2.285197, -2.402489, -2.43644 , -2.722001, -2.84985 , -3.168459, -3.263409, -4.13875 ]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(3)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(3)), (np.str_('occrate_coursenumber_exam_test_tutorium_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[64, 128]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[6, 21], [6, 31], [6, 11], [6, 22], [6, 6], [6, 16], [6, 1], [6, 37], [6, 23], [6, 32], [6, 18], [6, 26], [6, 36], [6, 33], [6, 7], [6, 13], [6, 17], [6, 2], [6, 29], [6, 28], [6, 27], [6, 8], [6, 19], [6, 12], [6, 39], [6, 38], [6, 4], [6, 25], [6, 34], [6, 24], [6, 3], [6, 9], [6, 30], [6, 10], [6, 15], [6, 14], [6, 35], [6, 5], [6, 0], [6, 20]]\\nModel Losses: [0.005784, 0.005786, 0.00599 , 0.006034, 0.00605 , 0.006053, 0.006161, 0.006208, 0.006483, 0.006522, 0.006565, 0.006591, 0.00661 , 0.006671, 0.006673, 0.006675, 0.00676 , 0.006765, 0.006771, 0.006845, 0.006862, 0.006914, 0.006941, 0.00702 , 0.007047, 0.007134, 0.007324, 0.00736 , 0.007367, 0.007395, 0.007413, 0.007465, 0.007505, 0.007642, 0.007659, 0.007772, 0.008092, 0.008478, 0.008598, 0.008949]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(4)), (np.str_('0.5'), np.int64(1))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(4)), (np.str_('occrate_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[64, 128]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[6, 36], [6, 21], [6, 16], [6, 31], [6, 22], [6, 6], [6, 13], [6, 11], [6, 37], [6, 8], [6, 26], [6, 4], [6, 9], [6, 2], [6, 23], [6, 18], [6, 1], [6, 24], [6, 14], [6, 7], [6, 32], [6, 33], [6, 19], [6, 12], [6, 34], [6, 38], [6, 27], [6, 3], [6, 25], [6, 29], [6, 28], [6, 17], [6, 39], [6, 15], [6, 30], [6, 35], [6, 10], [6, 5], [6, 0], [6, 20]]\\nModel Losses: [ 1.343760e-01,  1.253210e-01,  1.160560e-01,  9.742900e-02,  5.765900e-02,  3.252100e-02,  1.060100e-02,  6.740000e-03, -2.483000e-03, -2.196100e-02, -3.452200e-02, -4.334300e-02, -4.493800e-02, -4.932400e-02, -6.792700e-02, -7.154700e-02, -7.669400e-02, -8.726900e-02, -1.097070e-01, -1.517460e-01, -1.541560e-01, -1.547600e-01, -1.888410e-01, -2.708050e-01, -2.746570e-01, -2.896750e-01, -3.165870e-01, -3.537920e-01, -3.866040e-01, -5.036790e-01, -5.975380e-01, -6.463040e-01, -8.025740e-01, -1.095634e+00, -1.692345e+00, -1.736348e+00, -2.006605e+00, -2.334082e+00, -2.915198e+00, -2.992799e+00]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(3)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_coursenumber'), np.int64(4)), (np.str_('occrate_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(4)), (np.str_('[64, 128]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 7 #################\\nTime: 2024-11-27 16:42:28\\nDataset: val | Loss: MAE\\nCombinations: [[7, 13], [7, 12], [7, 5], [7, 2], [7, 6], [7, 8], [7, 7], [7, 11], [7, 10], [7, 9], [7, 1], [7, 4], [7, 0], [7, 3]]\\nModel Losses: [0.004604, 0.004819, 0.00499 , 0.005035, 0.005494, 0.005503, 0.005935, 0.005939, 0.005967, 0.006285, 0.00649 , 0.006556, 0.007307, 0.007524]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(4))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[7, 13], [7, 2], [7, 5], [7, 12], [7, 10], [7, 8], [7, 4], [7, 9], [7, 6], [7, 3], [7, 7], [7, 0], [7, 11], [7, 1]]\\nModel Losses: [-0.479118, -0.597712, -0.61198 , -0.705585, -0.876549, -0.963151, -1.120231, -1.333144, -1.646435, -1.995162, -2.044623, -2.3313  , -2.665758, -3.172813]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[7, 5], [7, 13], [7, 6], [7, 4], [7, 12], [7, 2], [7, 11], [7, 8], [7, 7], [7, 9], [7, 3], [7, 10], [7, 0], [7, 1]]\\nModel Losses: [0.005173, 0.006024, 0.006283, 0.006428, 0.006591, 0.006682, 0.006897, 0.007016, 0.007153, 0.00725 , 0.007314, 0.007357, 0.007527, 0.007893]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(4))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[7, 5], [7, 13], [7, 12], [7, 4], [7, 10], [7, 2], [7, 8], [7, 6], [7, 11], [7, 9], [7, 7], [7, 3], [7, 0], [7, 1]]\\nModel Losses: [ 0.327543,  0.14707 ,  0.077327,  0.045528, -0.125984, -0.204842, -0.302932, -0.328158, -0.332158, -0.402251, -0.55292 , -0.676888, -1.119461, -2.586204]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod_dow_week'), np.int64(1))]), ('hidden_size', [(np.str_('[12, 12]'), np.int64(1)), (np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 8 #################\\nTime: 2024-11-27 17:12:19\\nDataset: val | Loss: MAE\\nCombinations: [[8, 2], [8, 4], [8, 1], [8, 5], [8, 0], [8, 3]]\\nModel Losses: [0.00481 , 0.004833, 0.004928, 0.005127, 0.007307, 0.00736 ]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[8, 4], [8, 1], [8, 2], [8, 5], [8, 0], [8, 3]]\\nModel Losses: [-0.320544, -0.706099, -0.862704, -0.880151, -1.982205, -2.68343 ]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[8, 1], [8, 2], [8, 4], [8, 5], [8, 3], [8, 0]]\\nModel Losses: [0.005717, 0.006298, 0.00638 , 0.006584, 0.007216, 0.007426]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[8, 1], [8, 4], [8, 2], [8, 5], [8, 0], [8, 3]]\\nModel Losses: [ 0.183921,  0.024509, -0.072066, -0.16477 , -0.515865, -1.082964]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[8, 8]'), np.int64(5))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"################# Run: 9 #################\\nTime: 2024-12-04 16:26:23\\nDataset: val | Loss: MAE\\nCombinations: [[9, 15], [9, 21], [9, 14], [9, 24], [9, 26], [9, 27], [9, 9], [9, 2], [9, 1], [9, 17], [9, 23], [9, 11], [9, 18], [9, 5], [9, 12], [9, 8], [9, 6], [9, 10], [9, 25], [9, 20], [9, 7], [9, 4], [9, 3], [9, 13], [9, 19], [9, 22], [9, 28], [9, 16], [9, 0]]\\nModel Losses: [0.006599, 0.006947, 0.007035, 0.007075, 0.007105, 0.007335, 0.007352, 0.007363, 0.00746 , 0.00754 , 0.007546, 0.007555, 0.007567, 0.007654, 0.007701, 0.007725, 0.007987, 0.008073, 0.00812 , 0.008202, 0.008213, 0.008488, 0.008492, 0.008633, 0.008635, 0.008764, 0.008862, 0.00891 , 0.01491 ]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(3))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(4)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[9, 14], [9, 26], [9, 1], [9, 9], [9, 2], [9, 11], [9, 5], [9, 21], [9, 25], [9, 23], [9, 17], [9, 15], [9, 24], [9, 20], [9, 3], [9, 12], [9, 7], [9, 10], [9, 13], [9, 27], [9, 4], [9, 8], [9, 18], [9, 19], [9, 22], [9, 6], [9, 16], [9, 28], [9, 0]]\\nModel Losses: [ 0.707696,  0.688731,  0.66822 ,  0.656162,  0.638712,  0.635034,  0.620776,  0.613869,  0.6113  ,  0.598549,  0.596165,  0.595943,  0.595683,  0.586445,  0.582081,  0.579067,  0.577318,  0.566439,  0.559768,  0.558818,  0.539176,  0.513359,  0.494332,  0.468378,  0.421734,  0.421308,  0.366727,  0.301313, -1.615332]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[9, 5], [9, 4], [9, 12], [9, 27], [9, 23], [9, 11], [9, 26], [9, 13], [9, 15], [9, 20], [9, 8], [9, 17], [9, 14], [9, 7], [9, 28], [9, 21], [9, 24], [9, 10], [9, 1], [9, 16], [9, 18], [9, 9], [9, 3], [9, 2], [9, 6], [9, 19], [9, 25], [9, 22], [9, 0]]\\nModel Losses: [0.008764, 0.008837, 0.008972, 0.009194, 0.009197, 0.009211, 0.009311, 0.009522, 0.009525, 0.009608, 0.009724, 0.009726, 0.009777, 0.009796, 0.00985 , 0.010023, 0.010026, 0.010034, 0.01005 , 0.010073, 0.010121, 0.010318, 0.010566, 0.010636, 0.010761, 0.010869, 0.011163, 0.011314, 0.013729]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(1)), (np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[9, 5], [9, 12], [9, 4], [9, 26], [9, 20], [9, 23], [9, 10], [9, 27], [9, 24], [9, 17], [9, 8], [9, 7], [9, 3], [9, 9], [9, 2], [9, 11], [9, 14], [9, 25], [9, 15], [9, 6], [9, 21], [9, 1], [9, 18], [9, 19], [9, 13], [9, 22], [9, 0], [9, 16], [9, 28]]\\nModel Losses: [ 4.920100e-01,  4.886260e-01,  4.454480e-01,  4.172440e-01,  3.850360e-01,  3.645490e-01,  3.234280e-01,  3.060620e-01,  2.782660e-01,  2.307400e-01,  2.238560e-01,  2.149940e-01,  2.022450e-01,  1.827370e-01,  1.396270e-01,  1.386380e-01,  1.046240e-01,  2.430300e-02,  8.800000e-04, -2.846800e-02, -7.548600e-02, -1.148560e-01, -1.403400e-01, -2.019100e-01, -2.915040e-01, -4.338170e-01, -6.462810e-01, -7.220930e-01, -1.647431e+00]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(4)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(1))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(3))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 8 #################\\nTime: 2024-12-04 16:42:58\\nDataset: val | Loss: MAE\\nCombinations: [[8, 5], [8, 2], [8, 45], [8, 37], [8, 4], [8, 17], [8, 34], [8, 11], [8, 38], [8, 16], [8, 26], [8, 8], [8, 40], [8, 1], [8, 10], [8, 35], [8, 23], [8, 41], [8, 47], [8, 19], [8, 7], [8, 29], [8, 22], [8, 28], [8, 13], [8, 25], [8, 14], [8, 20], [8, 32], [8, 48], [8, 44], [8, 31], [8, 15], [8, 3], [8, 24], [8, 18], [8, 27], [8, 9], [8, 0], [8, 46], [8, 6], [8, 42], [8, 30], [8, 12], [8, 39], [8, 33], [8, 43], [8, 21], [8, 36]]\\nModel Losses: [0.00464 , 0.004676, 0.004698, 0.004709, 0.004717, 0.004728, 0.004744, 0.00476 , 0.004801, 0.004824, 0.004849, 0.004856, 0.004857, 0.004874, 0.00489 , 0.004908, 0.004932, 0.004939, 0.004945, 0.004984, 0.004991, 0.004993, 0.005008, 0.005015, 0.005016, 0.005018, 0.005047, 0.005085, 0.005103, 0.005106, 0.005112, 0.005175, 0.007013, 0.007228, 0.00732 , 0.007373, 0.007428, 0.007454, 0.007456, 0.007465, 0.007482, 0.007492, 0.007594, 0.007605, 0.007615, 0.007638, 0.007687, 0.007716, 0.007913]\\nBL zero Losses: [0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103, 0.022103]\\nBL naive Losses: [0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061, 0.015061]\\nBL avg Losses: [0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634, 0.013634]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(3))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[8, 2], [8, 38], [8, 19], [8, 17], [8, 37], [8, 31], [8, 5], [8, 45], [8, 44], [8, 25], [8, 4], [8, 26], [8, 34], [8, 7], [8, 1], [8, 23], [8, 32], [8, 11], [8, 22], [8, 8], [8, 35], [8, 29], [8, 48], [8, 16], [8, 28], [8, 13], [8, 41], [8, 40], [8, 10], [8, 20], [8, 14], [8, 47], [8, 3], [8, 9], [8, 18], [8, 0], [8, 15], [8, 27], [8, 24], [8, 39], [8, 6], [8, 30], [8, 36], [8, 43], [8, 42], [8, 12], [8, 33], [8, 46], [8, 21]]\\nModel Losses: [-0.252657, -0.371265, -0.371408, -0.388463, -0.439083, -0.440869, -0.444857, -0.508333, -0.534901, -0.539692, -0.579432, -0.604766, -0.610799, -0.620086, -0.628045, -0.64555 , -0.660398, -0.662019, -0.670442, -0.6855  , -0.700202, -0.727114, -0.745157, -0.756098, -0.778219, -0.811358, -0.815596, -0.869563, -0.930014, -0.957052, -0.959312, -0.983513, -1.332442, -1.370787, -1.425347, -1.50101 , -1.812056, -1.890864, -1.964116, -2.000877, -2.396244, -2.408109, -2.423054, -2.563058, -2.729784, -2.79858 , -3.001068, -3.130846, -3.166558]\\nBL zero Losses: [-29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622, -29.052622]\\nBL naive Losses: [-20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732, -20.696732]\\nBL avg Losses: [-9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975, -9.551975]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(3))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(1)), (np.str_('[15, 15]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[8, 16], [8, 4], [8, 34], [8, 40], [8, 22], [8, 5], [8, 25], [8, 19], [8, 44], [8, 1], [8, 47], [8, 37], [8, 10], [8, 32], [8, 2], [8, 8], [8, 14], [8, 35], [8, 7], [8, 28], [8, 13], [8, 48], [8, 26], [8, 31], [8, 38], [8, 11], [8, 17], [8, 29], [8, 41], [8, 45], [8, 6], [8, 23], [8, 9], [8, 36], [8, 39], [8, 15], [8, 27], [8, 46], [8, 20], [8, 18], [8, 42], [8, 33], [8, 3], [8, 21], [8, 12], [8, 24], [8, 0], [8, 43], [8, 30]]\\nModel Losses: [0.005526, 0.00553 , 0.00556 , 0.005561, 0.005736, 0.00585 , 0.005855, 0.005928, 0.005976, 0.005983, 0.006031, 0.006097, 0.006098, 0.006204, 0.006224, 0.006262, 0.006278, 0.006309, 0.006333, 0.006339, 0.006358, 0.006476, 0.006667, 0.006671, 0.00678 , 0.006795, 0.006839, 0.006883, 0.006886, 0.006902, 0.007004, 0.007015, 0.007244, 0.007295, 0.007308, 0.007312, 0.00732 , 0.007425, 0.007433, 0.007444, 0.007599, 0.007667, 0.007673, 0.0077  , 0.007752, 0.007781, 0.007843, 0.007911, 0.008363]\\nBL zero Losses: [0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493, 0.017493]\\nBL naive Losses: [0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352, 0.016352]\\nBL avg Losses: [0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112, 0.011112]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(5))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(1)), (np.str_('[15, 15]'), np.int64(2)), (np.str_('[20, 20]'), np.int64(1)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[8, 40], [8, 1], [8, 26], [8, 4], [8, 32], [8, 22], [8, 34], [8, 16], [8, 47], [8, 8], [8, 25], [8, 19], [8, 38], [8, 2], [8, 45], [8, 5], [8, 44], [8, 29], [8, 37], [8, 28], [8, 13], [8, 36], [8, 7], [8, 35], [8, 48], [8, 20], [8, 23], [8, 10], [8, 31], [8, 17], [8, 11], [8, 41], [8, 14], [8, 27], [8, 18], [8, 39], [8, 33], [8, 15], [8, 6], [8, 42], [8, 3], [8, 12], [8, 0], [8, 24], [8, 9], [8, 43], [8, 30], [8, 21], [8, 46]]\\nModel Losses: [ 0.205036,  0.174756,  0.157687,  0.157285,  0.157016,  0.150714,  0.140038,  0.137736,  0.132087,  0.073776,  0.04815 ,  0.039263,  0.037673,  0.017632,  0.013904, -0.025641, -0.046815, -0.052963, -0.055853, -0.080468, -0.08049 , -0.099261, -0.10383 , -0.122733, -0.124741, -0.132528, -0.13311 , -0.151628, -0.157658, -0.178521, -0.198125, -0.224117, -0.239484, -0.284699, -0.326229, -0.531849, -0.89415 , -0.998195, -1.026945, -1.252284, -1.349038, -1.482114, -1.68949 , -1.69552 , -1.75433 , -1.841906, -1.969648, -2.275099, -2.856373]\\nBL zero Losses: [-18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164, -18.732164]\\nBL naive Losses: [-9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227, -9.35227]\\nBL avg Losses: [-3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878, -3.73878]\\nHyperparameters: [('course_encoding_dim', [(np.str_('2'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_exam_tutorium_test_cancelled'), np.int64(2))]), ('hidden_size', [(np.str_('[10, 10]'), np.int64(2)), (np.str_('[20, 20]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(1))]), ('num_layers', [(np.str_('2'), np.int64(4)), (np.str_('3'), np.int64(1))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 9 #################\\nTime: 2024-12-04 17:12:57\\nDataset: val | Loss: MAE\\nCombinations: [[9, 29], [9, 30], [9, 35], [9, 31], [9, 32], [9, 36], [9, 33], [9, 34]]\\nModel Losses: [0.015164, 0.015519, 0.015636, 0.01565 , 0.015732, 0.015751, 0.015887, 0.016075]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(3))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[9, 35], [9, 31], [9, 30], [9, 32], [9, 34], [9, 36], [9, 33], [9, 29]]\\nModel Losses: [-0.445339, -0.596272, -0.716746, -1.022672, -1.127666, -1.17498 , -1.307515, -3.159665]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[9, 30], [9, 33], [9, 35], [9, 34], [9, 36], [9, 32], [9, 31], [9, 29]]\\nModel Losses: [0.014191, 0.014258, 0.014326, 0.014432, 0.014527, 0.014642, 0.014948, 0.014997]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[9, 30], [9, 31], [9, 35], [9, 34], [9, 32], [9, 33], [9, 36], [9, 29]]\\nModel Losses: [-0.610369, -1.597269, -1.658643, -1.942181, -2.068321, -2.357524, -3.120086, -3.145517]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(5))]), ('hidden_size', [(np.str_('[16, 16]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 10 #################\\nTime: 2024-12-04 20:10:18\\nDataset: val | Loss: MAE\\nCombinations: [[10, 6], [10, 2], [10, 4], [10, 0], [10, 3], [10, 7], [10, 1], [10, 5]]\\nModel Losses: [0.007424, 0.007885, 0.008559, 0.008785, 0.009054, 0.009302, 0.015049, 0.015724]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[10, 6], [10, 2], [10, 3], [10, 4], [10, 7], [10, 0], [10, 5], [10, 1]]\\nModel Losses: [ 0.699539,  0.692481,  0.630059,  0.601818,  0.582019,  0.541338, -1.297017, -2.499742]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[10, 2], [10, 6], [10, 7], [10, 3], [10, 4], [10, 0], [10, 5], [10, 1]]\\nModel Losses: [0.008841, 0.00932 , 0.009705, 0.009796, 0.012023, 0.014079, 0.014369, 0.014773]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[10, 6], [10, 2], [10, 7], [10, 4], [10, 3], [10, 0], [10, 1], [10, 5]]\\nModel Losses: [ 0.437432,  0.344327,  0.302479,  0.210006,  0.073559, -0.922822, -2.055568, -2.074318]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_tl'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_weather'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"################# Run: 11 #################\\nTime: 2024-12-16 20:36:42\\nDataset: val | Loss: MAE\\nCombinations: [[11, 2], [11, 1], [11, 3], [11, 0]]\\nModel Losses: [0.00762 , 0.008128, 0.008248, 0.008541]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('False'), np.int64(4))]), ('x_horizon', [(np.str_('36'), np.int64(4))]), ('y_horizon', [(np.str_('36'), np.int64(4))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[11, 3], [11, 2], [11, 1], [11, 0]]\\nModel Losses: [0.641767, 0.639651, 0.610826, 0.604311]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('False'), np.int64(4))]), ('x_horizon', [(np.str_('36'), np.int64(4))]), ('y_horizon', [(np.str_('36'), np.int64(4))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[11, 2], [11, 0], [11, 1], [11, 3]]\\nModel Losses: [0.009765, 0.010129, 0.010192, 0.010507]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('False'), np.int64(4))]), ('x_horizon', [(np.str_('36'), np.int64(4))]), ('y_horizon', [(np.str_('36'), np.int64(4))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[11, 0], [11, 2], [11, 1], [11, 3]]\\nModel Losses: [ 0.449613,  0.154474, -0.703272, -0.742051]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('False'), np.int64(4))]), ('x_horizon', [(np.str_('36'), np.int64(4))]), ('y_horizon', [(np.str_('36'), np.int64(4))])]\",\n",
       " \"\\n################# Run: 11 #################\\nTime: 2024-12-16 21:11:00\\nDataset: val | Loss: MAE\\nCombinations: [[11, 4], [11, 7], [11, 2], [11, 5], [11, 6], [11, 1], [11, 3], [11, 0]]\\nModel Losses: [0.007372, 0.007473, 0.00762 , 0.007826, 0.007827, 0.008128, 0.008248, 0.008541]\\nBL zero Losses: [0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474, 0.022474]\\nBL naive Losses: [0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314, 0.015314]\\nBL avg Losses: [0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863, 0.013863]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber_dow'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_dow_hod_exam_test_tutorium_registered'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[11, 4], [11, 3], [11, 2], [11, 1], [11, 0], [11, 5], [11, 6], [11, 7]]\\nModel Losses: [0.651463, 0.641767, 0.639651, 0.610826, 0.604311, 0.574051, 0.474853, 0.435377]\\nBL zero Losses: [-0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942, -0.069942]\\nBL naive Losses: [-24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194, -24.859194]\\nBL avg Losses: [-1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233, -1.166233]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[11, 6], [11, 7], [11, 5], [11, 2], [11, 0], [11, 1], [11, 3], [11, 4]]\\nModel Losses: [0.009253, 0.009334, 0.009434, 0.009765, 0.010129, 0.010192, 0.010507, 0.010559]\\nBL zero Losses: [0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787, 0.017787]\\nBL naive Losses: [0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627, 0.016627]\\nBL avg Losses: [0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299, 0.011299]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber_dow'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_dow_hod_exam_test_tutorium_registered'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_coursenumber_type_studyarea_level_registered'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[11, 5], [11, 0], [11, 6], [11, 4], [11, 7], [11, 2], [11, 1], [11, 3]]\\nModel Losses: [ 0.454924,  0.449613,  0.425372,  0.40445 ,  0.394774,  0.154474, -0.703272, -0.742051]\\nBL zero Losses: [-0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933, -0.447933]\\nBL naive Losses: [-21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226, -21.106226]\\nBL avg Losses: [-0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614, -0.86614]\\nHyperparameters: [('course_encoding_dim', [(np.str_('3'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_avgocc_coursenumber_dow'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_dow_hod_exam_test_tutorium_registered'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 12 #################\\nTime: 2024-12-22 16:20:29\\nDataset: val | Loss: MAE\\nCombinations: [[12, 3], [12, 4], [12, 9], [12, 0], [12, 5], [12, 10], [12, 11], [12, 6], [12, 1], [12, 2], [12, 7], [12, 8]]\\nModel Losses: [0.006192, 0.008054, 0.00831 , 0.008884, 0.009067, 0.010995, 0.013329, 0.014448, 0.015501, 0.018781, 0.036227, 0.040218]\\nBL zero Losses: [0.020519, 0.018247, 0.018612, 0.020519, 0.018247, 0.018612, 0.020519, 0.018247, 0.018612, 0.020519, 0.018247, 0.018612]\\nBL naive Losses: [0.015809, 0.014358, 0.014663, 0.015809, 0.014358, 0.014663, 0.015809, 0.014358, 0.014663, 0.015809, 0.014358, 0.014663]\\nBL avg Losses: [0.013431, 0.012195, 0.012207, 0.013431, 0.012195, 0.012207, 0.013431, 0.012195, 0.012207, 0.013431, 0.012195, 0.012207]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(4))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('True'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[12, 5], [12, 4], [12, 11], [12, 10], [12, 1], [12, 2], [12, 8], [12, 3], [12, 0], [12, 7], [12, 9], [12, 6]]\\nModel Losses: [ 0.712765,  0.52137 ,  0.305434,  0.095344,  0.015795, -0.00538 , -0.70123 , -0.86736 , -1.501677, -1.675928, -1.698227, -3.031904]\\nBL zero Losses: [-27.330751,  -0.441705,   0.085425, -27.330751,  -0.441705,   0.085425, -27.330751,  -0.441705,   0.085425, -27.330751,  -0.441705,   0.085425]\\nBL naive Losses: [-18.013397,  -2.803663,  -0.152335, -18.013397,  -2.803663,  -0.152335, -18.013397,  -2.803663,  -0.152335, -18.013397,  -2.803663,  -0.152335]\\nBL avg Losses: [-11.710587,   0.123909,   0.46484 , -11.710587,   0.123909,   0.46484 , -11.710587,   0.123909,   0.46484 , -11.710587,   0.123909,   0.46484 ]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(4))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('True'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[12, 0], [12, 3], [12, 9], [12, 4], [12, 6], [12, 10], [12, 5], [12, 11], [12, 1], [12, 2], [12, 7], [12, 8]]\\nModel Losses: [0.011464, 0.011954, 0.013062, 0.016119, 0.016209, 0.01676 , 0.017908, 0.020414, 0.021094, 0.024009, 0.038312, 0.042709]\\nBL zero Losses: [0.025621, 0.026335, 0.026437, 0.025621, 0.026335, 0.026437, 0.025621, 0.026335, 0.026437, 0.025621, 0.026335, 0.026437]\\nBL naive Losses: [0.022586, 0.022605, 0.022297, 0.022586, 0.022605, 0.022297, 0.022586, 0.022605, 0.022297, 0.022586, 0.022605, 0.022297]\\nBL avg Losses: [0.020453, 0.020618, 0.020486, 0.020453, 0.020618, 0.020486, 0.020453, 0.020618, 0.020486, 0.020453, 0.020618, 0.020486]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(2)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(3))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('True'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[12, 1], [12, 2], [12, 0], [12, 10], [12, 11], [12, 5], [12, 9], [12, 4], [12, 8], [12, 6], [12, 3], [12, 7]]\\nModel Losses: [-0.345438, -0.573679, -0.926171, -1.020708, -1.272773, -1.51287 , -2.090469, -2.313196, -2.389688, -2.390769, -2.984782, -3.021099]\\nBL zero Losses: [-20.696457,  -0.523346,   0.07378 , -20.696457,  -0.523346,   0.07378 , -20.696457,  -0.523346,   0.07378 , -20.696457,  -0.523346,   0.07378 ]\\nBL naive Losses: [-14.390378,  -4.60688 ,  -3.270787, -14.390378,  -4.60688 ,  -3.270787, -14.390378,  -4.60688 ,  -3.270787, -14.390378,  -4.60688 ,  -3.270787]\\nBL avg Losses: [-9.621417, -1.702704, -0.566013, -9.621417, -1.702704, -0.566013, -9.621417, -1.702704, -0.566013, -9.621417, -1.702704, -0.566013]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(5))]), ('dataset_mode', [(np.str_('normal'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate'), np.int64(3)), (np.str_('occrate_avgocc_coursenumber_hod'), np.int64(2))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('True'), np.int64(5))]), ('x_horizon', [(np.str_('24'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]\",\n",
       " \"\\n################# Run: 13 #################\\nTime: 2024-12-23 15:11:49\\nDataset: val | Loss: MAE\\nCombinations: [[13, 3], [13, 1], [13, 2], [13, 0]]\\nModel Losses: [0.008218, 0.008601, 0.011386, 0.01501 ]\\nBL zero Losses: [0.018247, 0.018247, 0.018247, 0.018247]\\nBL naive Losses: [0.014358, 0.014358, 0.014358, 0.014358]\\nBL avg Losses: [0.012195, 0.012195, 0.012195, 0.012195]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[13, 3], [13, 1], [13, 2], [13, 0]]\\nModel Losses: [ 0.569246,  0.417125,  0.338269, -0.049801]\\nBL zero Losses: [-0.441705, -0.441705, -0.441705, -0.441705]\\nBL naive Losses: [-2.803663, -2.803663, -2.803663, -2.803663]\\nBL avg Losses: [0.123909, 0.123909, 0.123909, 0.123909]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[13, 1], [13, 3], [13, 2], [13, 0]]\\nModel Losses: [0.016267, 0.016713, 0.01907 , 0.020217]\\nBL zero Losses: [0.026335, 0.026335, 0.026335, 0.026335]\\nBL naive Losses: [0.022605, 0.022605, 0.022605, 0.022605]\\nBL avg Losses: [0.020618, 0.020618, 0.020618, 0.020618]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[13, 3], [13, 0], [13, 2], [13, 1]]\\nModel Losses: [-0.351239, -0.526043, -1.154288, -1.2511  ]\\nBL zero Losses: [-0.523346, -0.523346, -0.523346, -0.523346]\\nBL naive Losses: [-4.60688, -4.60688, -4.60688, -4.60688]\\nBL avg Losses: [-1.702704, -1.702704, -1.702704, -1.702704]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\",\n",
       " \"\\n################# Run: 14 #################\\nTime: 2024-12-23 15:14:34\\nDataset: val | Loss: MAE\\nCombinations: [[14, 1], [14, 3], [14, 2], [14, 0]]\\nModel Losses: [0.00804 , 0.008247, 0.01136 , 0.015677]\\nBL zero Losses: [0.018247, 0.018247, 0.018247, 0.018247]\\nBL naive Losses: [0.014358, 0.014358, 0.014358, 0.014358]\\nBL avg Losses: [0.012195, 0.012195, 0.012195, 0.012195]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[14, 1], [14, 3], [14, 2], [14, 0]]\\nModel Losses: [ 0.632874,  0.564222,  0.168236, -0.634094]\\nBL zero Losses: [-0.441705, -0.441705, -0.441705, -0.441705]\\nBL naive Losses: [-2.803663, -2.803663, -2.803663, -2.803663]\\nBL avg Losses: [0.123909, 0.123909, 0.123909, 0.123909]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[14, 1], [14, 3], [14, 2], [14, 0]]\\nModel Losses: [0.016066, 0.016968, 0.018379, 0.020431]\\nBL zero Losses: [0.026335, 0.026335, 0.026335, 0.026335]\\nBL naive Losses: [0.022605, 0.022605, 0.022605, 0.022605]\\nBL avg Losses: [0.020618, 0.020618, 0.020618, 0.020618]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[14, 1], [14, 3], [14, 0], [14, 2]]\\nModel Losses: [-0.448516, -0.688057, -0.87719 , -1.338619]\\nBL zero Losses: [-0.523346, -0.523346, -0.523346, -0.523346]\\nBL naive Losses: [-4.60688, -4.60688, -4.60688, -4.60688]\\nBL avg Losses: [-1.702704, -1.702704, -1.702704, -1.702704]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\",\n",
       " \"\\n################# Run: 15 #################\\nTime: 2024-12-23 15:17:16\\nDataset: val | Loss: MAE\\nCombinations: [[15, 1], [15, 3], [15, 2], [15, 0]]\\nModel Losses: [0.008257, 0.008608, 0.010919, 0.015186]\\nBL zero Losses: [0.018247, 0.018247, 0.018247, 0.018247]\\nBL naive Losses: [0.014358, 0.014358, 0.014358, 0.014358]\\nBL avg Losses: [0.012195, 0.012195, 0.012195, 0.012195]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: val | Loss: R2\\nCombinations: [[15, 3], [15, 1], [15, 2], [15, 0]]\\nModel Losses: [0.629832, 0.582551, 0.373923, 0.076452]\\nBL zero Losses: [-0.441705, -0.441705, -0.441705, -0.441705]\\nBL naive Losses: [-2.803663, -2.803663, -2.803663, -2.803663]\\nBL avg Losses: [0.123909, 0.123909, 0.123909, 0.123909]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: test | Loss: MAE\\nCombinations: [[15, 3], [15, 1], [15, 2], [15, 0]]\\nModel Losses: [0.016157, 0.016479, 0.018512, 0.020667]\\nBL zero Losses: [0.026335, 0.026335, 0.026335, 0.026335]\\nBL naive Losses: [0.022605, 0.022605, 0.022605, 0.022605]\\nBL avg Losses: [0.020618, 0.020618, 0.020618, 0.020618]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\\n\\nDataset: test | Loss: R2\\nCombinations: [[15, 3], [15, 0], [15, 1], [15, 2]]\\nModel Losses: [-0.387595, -0.662434, -0.725742, -1.405641]\\nBL zero Losses: [-0.523346, -0.523346, -0.523346, -0.523346]\\nBL naive Losses: [-4.60688, -4.60688, -4.60688, -4.60688]\\nBL avg Losses: [-1.702704, -1.702704, -1.702704, -1.702704]\\nHyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(4))]), ('dataset_mode', [(np.str_('normal'), np.int64(4))]), ('dropout', [(np.str_('0'), np.int64(4))]), ('features', [(np.str_('occrate'), np.int64(1)), (np.str_('occrate_avgocc'), np.int64(1)), (np.str_('occrate_avgocc_coursenumber'), np.int64(1)), (np.str_('occrate_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32, 32]'), np.int64(4))]), ('num_layers', [(np.str_('3'), np.int64(4))]), ('split_by', [(np.str_('time'), np.int64(4))]), ('with_examweek', [(np.str_('True'), np.int64(4))]), ('x_horizon', [(np.str_('24'), np.int64(4))]), ('y_horizon', [(np.str_('12'), np.int64(4))])]\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read txt file with training results\n",
    "\n",
    "with open(\"results_wrapup_normal.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    line_str = \"\".join(lines)\n",
    "    \n",
    "    \n",
    "list_of_runs = line_str.split(\"\\n\\n\\n\")\n",
    "# remove empty strings\n",
    "list_of_runs = [run for run in list_of_runs if run != \"\"][:-1]\n",
    "list_of_runs\n",
    "\n",
    "runs_of_interest = list_of_runs[:]\n",
    "\n",
    "runs_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "class StatsLogger():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.comb_lists = []\n",
    "        self.model_losses = []\n",
    "        self.zero_baselines = []\n",
    "        self.naive_baselines = []\n",
    "        self.avg_baselines = []\n",
    "        self.dataset_types = []\n",
    "        self.loss_types = []\n",
    "        \n",
    "    def return_dataframe(self, run_id):\n",
    "        return pd.DataFrame({\n",
    "            \"run_id\": run_id,\n",
    "            \"dataset\": self.dataset_types,\n",
    "            \"loss_type\": self.loss_types,\n",
    "            \"combinations\": self.comb_lists,\n",
    "            \"model_losses\": self.model_losses,\n",
    "            \"zero_baselines\": self.zero_baselines,\n",
    "            \"naive_baselines\": self.naive_baselines,\n",
    "            \"avg_baselines\": self.avg_baselines\n",
    "        })\n",
    "    \n",
    "def handle_array_types(array_type, array, dataset, loss_type, logger):\n",
    "    \n",
    "    if array_type == \"Combinations\":\n",
    "                    \n",
    "        logger.dataset_types.extend(np.repeat(dataset, len(array)))\n",
    "        logger.loss_types.extend(np.repeat(loss_type, len(array)))\n",
    "        \n",
    "        logger.comb_lists.extend(array)\n",
    "        \n",
    "    elif array_type == \"Model Losses\":\n",
    "        logger.model_losses.extend(array)\n",
    "        \n",
    "    elif array_type == \"BL zero Losses\":\n",
    "        logger.zero_baselines.extend(array)\n",
    "        \n",
    "    elif array_type == \"BL naive Losses\":\n",
    "        logger.naive_baselines.extend(array)\n",
    "\n",
    "    elif array_type == \"BL avg Losses\":\n",
    "        logger.avg_baselines.extend(array)\n",
    "\n",
    "    else:\n",
    "        print(array_type, array)\n",
    "        raise ValueError(\"array_type not recognized\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "for run in runs_of_interest:\n",
    "    \n",
    "    splitted_run = run.split(\"\\n\")\n",
    "    # filter out empty strings\n",
    "    splitted_run = [elem for elem in splitted_run if elem != \"\"]\n",
    "\n",
    "    run_id = int(splitted_run[0].split(\" \")[2])\n",
    "    if (run_id < 13) or (run_id > 16):\n",
    "        continue\n",
    "    \n",
    "    logger = StatsLogger()\n",
    "    \n",
    "    for elem in splitted_run[2:]:\n",
    "\n",
    "        by_bar = elem.split(\"|\")\n",
    "        \n",
    "        if len(by_bar) == 2:\n",
    "            dataset = by_bar[0].split(\":\")[1].strip()\n",
    "            loss_type = by_bar[1].split(\":\")[1].strip()\n",
    " \n",
    "        elif len(by_bar) == 1:\n",
    "            \n",
    "            if by_bar[0] == \"\":\n",
    "                continue\n",
    "            \n",
    "            array_type, array = by_bar[0].split(\":\")\n",
    "            array_type = array_type.strip()\n",
    "            \n",
    "            if array_type == \"Hyperparameters\":\n",
    "                continue\n",
    "            \n",
    "            array = array.strip()\n",
    "            array = np.array(ast.literal_eval(array))\n",
    "\n",
    "            handle_array_types(array_type, array, dataset, loss_type, logger)\n",
    "      \n",
    "    run_df = logger.return_dataframe(run_id)\n",
    "    \n",
    "    list_of_dfs.append(run_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>combinations</th>\n",
       "      <th>model_losses</th>\n",
       "      <th>zero_baselines</th>\n",
       "      <th>naive_baselines</th>\n",
       "      <th>avg_baselines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 3]</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 1]</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 2]</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 0]</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 3]</td>\n",
       "      <td>0.569246</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 1]</td>\n",
       "      <td>0.417125</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 2]</td>\n",
       "      <td>0.338269</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 0]</td>\n",
       "      <td>-0.049801</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 1]</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 3]</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 2]</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[13, 0]</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 3]</td>\n",
       "      <td>-0.351239</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 0]</td>\n",
       "      <td>-0.526043</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 2]</td>\n",
       "      <td>-1.154288</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[13, 1]</td>\n",
       "      <td>-1.251100</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 1]</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 3]</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 2]</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 0]</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 1]</td>\n",
       "      <td>0.632874</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 3]</td>\n",
       "      <td>0.564222</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 2]</td>\n",
       "      <td>0.168236</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 0]</td>\n",
       "      <td>-0.634094</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 1]</td>\n",
       "      <td>0.016066</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 3]</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 2]</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[14, 0]</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 1]</td>\n",
       "      <td>-0.448516</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 3]</td>\n",
       "      <td>-0.688057</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 0]</td>\n",
       "      <td>-0.877190</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[14, 2]</td>\n",
       "      <td>-1.338619</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 1]</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 3]</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 2]</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 0]</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 3]</td>\n",
       "      <td>0.629832</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 1]</td>\n",
       "      <td>0.582551</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 2]</td>\n",
       "      <td>0.373923</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 0]</td>\n",
       "      <td>0.076452</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 3]</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 1]</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 2]</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>[15, 0]</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 3]</td>\n",
       "      <td>-0.387595</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 0]</td>\n",
       "      <td>-0.662434</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 1]</td>\n",
       "      <td>-0.725742</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>R2</td>\n",
       "      <td>[15, 2]</td>\n",
       "      <td>-1.405641</td>\n",
       "      <td>-0.523346</td>\n",
       "      <td>-4.606880</td>\n",
       "      <td>-1.702704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id dataset loss_type combinations  model_losses  zero_baselines  \\\n",
       "0       13     val       MAE      [13, 3]      0.008218        0.018247   \n",
       "1       13     val       MAE      [13, 1]      0.008601        0.018247   \n",
       "2       13     val       MAE      [13, 2]      0.011386        0.018247   \n",
       "3       13     val       MAE      [13, 0]      0.015010        0.018247   \n",
       "4       13     val        R2      [13, 3]      0.569246       -0.441705   \n",
       "5       13     val        R2      [13, 1]      0.417125       -0.441705   \n",
       "6       13     val        R2      [13, 2]      0.338269       -0.441705   \n",
       "7       13     val        R2      [13, 0]     -0.049801       -0.441705   \n",
       "8       13    test       MAE      [13, 1]      0.016267        0.026335   \n",
       "9       13    test       MAE      [13, 3]      0.016713        0.026335   \n",
       "10      13    test       MAE      [13, 2]      0.019070        0.026335   \n",
       "11      13    test       MAE      [13, 0]      0.020217        0.026335   \n",
       "12      13    test        R2      [13, 3]     -0.351239       -0.523346   \n",
       "13      13    test        R2      [13, 0]     -0.526043       -0.523346   \n",
       "14      13    test        R2      [13, 2]     -1.154288       -0.523346   \n",
       "15      13    test        R2      [13, 1]     -1.251100       -0.523346   \n",
       "16      14     val       MAE      [14, 1]      0.008040        0.018247   \n",
       "17      14     val       MAE      [14, 3]      0.008247        0.018247   \n",
       "18      14     val       MAE      [14, 2]      0.011360        0.018247   \n",
       "19      14     val       MAE      [14, 0]      0.015677        0.018247   \n",
       "20      14     val        R2      [14, 1]      0.632874       -0.441705   \n",
       "21      14     val        R2      [14, 3]      0.564222       -0.441705   \n",
       "22      14     val        R2      [14, 2]      0.168236       -0.441705   \n",
       "23      14     val        R2      [14, 0]     -0.634094       -0.441705   \n",
       "24      14    test       MAE      [14, 1]      0.016066        0.026335   \n",
       "25      14    test       MAE      [14, 3]      0.016968        0.026335   \n",
       "26      14    test       MAE      [14, 2]      0.018379        0.026335   \n",
       "27      14    test       MAE      [14, 0]      0.020431        0.026335   \n",
       "28      14    test        R2      [14, 1]     -0.448516       -0.523346   \n",
       "29      14    test        R2      [14, 3]     -0.688057       -0.523346   \n",
       "30      14    test        R2      [14, 0]     -0.877190       -0.523346   \n",
       "31      14    test        R2      [14, 2]     -1.338619       -0.523346   \n",
       "32      15     val       MAE      [15, 1]      0.008257        0.018247   \n",
       "33      15     val       MAE      [15, 3]      0.008608        0.018247   \n",
       "34      15     val       MAE      [15, 2]      0.010919        0.018247   \n",
       "35      15     val       MAE      [15, 0]      0.015186        0.018247   \n",
       "36      15     val        R2      [15, 3]      0.629832       -0.441705   \n",
       "37      15     val        R2      [15, 1]      0.582551       -0.441705   \n",
       "38      15     val        R2      [15, 2]      0.373923       -0.441705   \n",
       "39      15     val        R2      [15, 0]      0.076452       -0.441705   \n",
       "40      15    test       MAE      [15, 3]      0.016157        0.026335   \n",
       "41      15    test       MAE      [15, 1]      0.016479        0.026335   \n",
       "42      15    test       MAE      [15, 2]      0.018512        0.026335   \n",
       "43      15    test       MAE      [15, 0]      0.020667        0.026335   \n",
       "44      15    test        R2      [15, 3]     -0.387595       -0.523346   \n",
       "45      15    test        R2      [15, 0]     -0.662434       -0.523346   \n",
       "46      15    test        R2      [15, 1]     -0.725742       -0.523346   \n",
       "47      15    test        R2      [15, 2]     -1.405641       -0.523346   \n",
       "\n",
       "    naive_baselines  avg_baselines  \n",
       "0          0.014358       0.012195  \n",
       "1          0.014358       0.012195  \n",
       "2          0.014358       0.012195  \n",
       "3          0.014358       0.012195  \n",
       "4         -2.803663       0.123909  \n",
       "5         -2.803663       0.123909  \n",
       "6         -2.803663       0.123909  \n",
       "7         -2.803663       0.123909  \n",
       "8          0.022605       0.020618  \n",
       "9          0.022605       0.020618  \n",
       "10         0.022605       0.020618  \n",
       "11         0.022605       0.020618  \n",
       "12        -4.606880      -1.702704  \n",
       "13        -4.606880      -1.702704  \n",
       "14        -4.606880      -1.702704  \n",
       "15        -4.606880      -1.702704  \n",
       "16         0.014358       0.012195  \n",
       "17         0.014358       0.012195  \n",
       "18         0.014358       0.012195  \n",
       "19         0.014358       0.012195  \n",
       "20        -2.803663       0.123909  \n",
       "21        -2.803663       0.123909  \n",
       "22        -2.803663       0.123909  \n",
       "23        -2.803663       0.123909  \n",
       "24         0.022605       0.020618  \n",
       "25         0.022605       0.020618  \n",
       "26         0.022605       0.020618  \n",
       "27         0.022605       0.020618  \n",
       "28        -4.606880      -1.702704  \n",
       "29        -4.606880      -1.702704  \n",
       "30        -4.606880      -1.702704  \n",
       "31        -4.606880      -1.702704  \n",
       "32         0.014358       0.012195  \n",
       "33         0.014358       0.012195  \n",
       "34         0.014358       0.012195  \n",
       "35         0.014358       0.012195  \n",
       "36        -2.803663       0.123909  \n",
       "37        -2.803663       0.123909  \n",
       "38        -2.803663       0.123909  \n",
       "39        -2.803663       0.123909  \n",
       "40         0.022605       0.020618  \n",
       "41         0.022605       0.020618  \n",
       "42         0.022605       0.020618  \n",
       "43         0.022605       0.020618  \n",
       "44        -4.606880      -1.702704  \n",
       "45        -4.606880      -1.702704  \n",
       "46        -4.606880      -1.702704  \n",
       "47        -4.606880      -1.702704  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>combinations</th>\n",
       "      <th>model_losses</th>\n",
       "      <th>zero_baselines</th>\n",
       "      <th>naive_baselines</th>\n",
       "      <th>avg_baselines</th>\n",
       "      <th>info</th>\n",
       "      <th>model_class</th>\n",
       "      <th>...</th>\n",
       "      <th>differencing</th>\n",
       "      <th>layer_norm</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>forget_gate</th>\n",
       "      <th>include_x_features</th>\n",
       "      <th>zero_sample_drop_rate</th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_features_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>occcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 3)</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 1)</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 2)</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 0)</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>R2</td>\n",
       "      <td>(13, 3)</td>\n",
       "      <td>0.569246</td>\n",
       "      <td>-0.441705</td>\n",
       "      <td>-2.803663</td>\n",
       "      <td>0.123909</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset loss_type combinations  model_losses  zero_baselines  \\\n",
       "0      13     val       MAE      (13, 3)      0.008218        0.018247   \n",
       "1      13     val       MAE      (13, 1)      0.008601        0.018247   \n",
       "2      13     val       MAE      (13, 2)      0.011386        0.018247   \n",
       "3      13     val       MAE      (13, 0)      0.015010        0.018247   \n",
       "4      13     val        R2      (13, 3)      0.569246       -0.441705   \n",
       "\n",
       "   naive_baselines  avg_baselines                info model_class  ...  \\\n",
       "0         0.014358       0.012195  Run 13: same as 12     ed_lstm  ...   \n",
       "1         0.014358       0.012195  Run 13: same as 12     ed_lstm  ...   \n",
       "2         0.014358       0.012195  Run 13: same as 12     ed_lstm  ...   \n",
       "3         0.014358       0.012195  Run 13: same as 12     ed_lstm  ...   \n",
       "4        -2.803663       0.123909  Run 13: same as 12     ed_lstm  ...   \n",
       "\n",
       "  differencing layer_norm weight_decay forget_gate include_x_features  \\\n",
       "0         none      False            0        True               True   \n",
       "1         none      False            0        True               True   \n",
       "2         none      False            0        True               True   \n",
       "3         none      False            0        True               True   \n",
       "4         none      False            0        True               True   \n",
       "\n",
       "  zero_sample_drop_rate x_size y_features_size y_size occcount  \n",
       "0                   0.1      1               0      1    False  \n",
       "1                   0.1      2               1      1    False  \n",
       "2                   0.1      2               1      1    False  \n",
       "3                   0.1      1               0      1    False  \n",
       "4                   0.1      1               0      1    False  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through all combinations and load hyperparameters\n",
    "import json\n",
    "path_to_checkpoints = \"_occupancy_forecasting/checkpoints/wrap_up\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    comb = row[\"combinations\"]\n",
    "    \n",
    "    comb_path = os.path.join(path_to_checkpoints, f\"run_{comb[0]}/comb_{comb[1]}\")\n",
    "    \n",
    "    hyperparameters_path = os.path.join(comb_path, \"hyperparameters.json\")\n",
    "\n",
    "    \n",
    "    hyperparameters = json.load(open(hyperparameters_path, \"r\"))\n",
    "    \n",
    "    # overwrite combinations with tuple of run_id and comb_id\n",
    "    results_df.at[idx, \"combinations\"] = (row[\"run_id\"], comb[1])\n",
    "    \n",
    "    # add all hyperparameters to the dataframe\n",
    "    for key, value in hyperparameters.items():\n",
    "        results_df.at[idx, key] = str(value)\n",
    "\n",
    "print(len(results_df))\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>combinations</th>\n",
       "      <th>model_losses</th>\n",
       "      <th>zero_baselines</th>\n",
       "      <th>naive_baselines</th>\n",
       "      <th>avg_baselines</th>\n",
       "      <th>info</th>\n",
       "      <th>model_class</th>\n",
       "      <th>...</th>\n",
       "      <th>differencing</th>\n",
       "      <th>layer_norm</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>forget_gate</th>\n",
       "      <th>include_x_features</th>\n",
       "      <th>zero_sample_drop_rate</th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_features_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>occcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 1)</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 3)</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 2)</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(13, 0)</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 13: same as 12</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(14, 1)</td>\n",
       "      <td>0.016066</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 14: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(14, 3)</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 14: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(14, 2)</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 14: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(14, 0)</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 14: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(15, 3)</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 15: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(15, 1)</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 15: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(15, 2)</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 15: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(15, 0)</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>Run 15: same as 13</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id dataset loss_type combinations  model_losses  zero_baselines  \\\n",
       "0       13    test       MAE      (13, 1)      0.016267        0.026335   \n",
       "1       13    test       MAE      (13, 3)      0.016713        0.026335   \n",
       "2       13    test       MAE      (13, 2)      0.019070        0.026335   \n",
       "3       13    test       MAE      (13, 0)      0.020217        0.026335   \n",
       "4       14    test       MAE      (14, 1)      0.016066        0.026335   \n",
       "5       14    test       MAE      (14, 3)      0.016968        0.026335   \n",
       "6       14    test       MAE      (14, 2)      0.018379        0.026335   \n",
       "7       14    test       MAE      (14, 0)      0.020431        0.026335   \n",
       "8       15    test       MAE      (15, 3)      0.016157        0.026335   \n",
       "9       15    test       MAE      (15, 1)      0.016479        0.026335   \n",
       "10      15    test       MAE      (15, 2)      0.018512        0.026335   \n",
       "11      15    test       MAE      (15, 0)      0.020667        0.026335   \n",
       "\n",
       "    naive_baselines  avg_baselines                info model_class  ...  \\\n",
       "0          0.022605       0.020618  Run 13: same as 12     ed_lstm  ...   \n",
       "1          0.022605       0.020618  Run 13: same as 12     ed_lstm  ...   \n",
       "2          0.022605       0.020618  Run 13: same as 12     ed_lstm  ...   \n",
       "3          0.022605       0.020618  Run 13: same as 12     ed_lstm  ...   \n",
       "4          0.022605       0.020618  Run 14: same as 13     ed_lstm  ...   \n",
       "5          0.022605       0.020618  Run 14: same as 13     ed_lstm  ...   \n",
       "6          0.022605       0.020618  Run 14: same as 13     ed_lstm  ...   \n",
       "7          0.022605       0.020618  Run 14: same as 13     ed_lstm  ...   \n",
       "8          0.022605       0.020618  Run 15: same as 13     ed_lstm  ...   \n",
       "9          0.022605       0.020618  Run 15: same as 13     ed_lstm  ...   \n",
       "10         0.022605       0.020618  Run 15: same as 13     ed_lstm  ...   \n",
       "11         0.022605       0.020618  Run 15: same as 13     ed_lstm  ...   \n",
       "\n",
       "   differencing layer_norm weight_decay forget_gate include_x_features  \\\n",
       "0          none      False            0        True               True   \n",
       "1          none      False            0        True               True   \n",
       "2          none      False            0        True               True   \n",
       "3          none      False            0        True               True   \n",
       "4          none      False            0        True               True   \n",
       "5          none      False            0        True               True   \n",
       "6          none      False            0        True               True   \n",
       "7          none      False            0        True               True   \n",
       "8          none      False            0        True               True   \n",
       "9          none      False            0        True               True   \n",
       "10         none      False            0        True               True   \n",
       "11         none      False            0        True               True   \n",
       "\n",
       "   zero_sample_drop_rate x_size y_features_size y_size occcount  \n",
       "0                    0.1      2               1      1    False  \n",
       "1                    0.1      1               0      1    False  \n",
       "2                    0.1      2               1      1    False  \n",
       "3                    0.1      1               0      1    False  \n",
       "4                    0.1      2               1      1    False  \n",
       "5                    0.1      1               0      1    False  \n",
       "6                    0.1      2               1      1    False  \n",
       "7                    0.1      1               0      1    False  \n",
       "8                    0.1      1               0      1    False  \n",
       "9                    0.1      2               1      1    False  \n",
       "10                   0.1      2               1      1    False  \n",
       "11                   0.1      1               0      1    False  \n",
       "\n",
       "[12 rows x 44 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def filter_dataframe_by_column_value(df, column, value):\n",
    "    return df[df[column] == value].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def filter_dataframe_by_dict(df, dict_filter):\n",
    "    for key, value in dict_filter.items():\n",
    "        df = filter_dataframe_by_column_value(df, key, value)\n",
    "    return df\n",
    "\n",
    "\n",
    "results_out = filter_dataframe_by_dict(\n",
    "    results_df,\n",
    "    {\n",
    "        \"loss_type\": \"MAE\",\n",
    "        \"dataset\": \"test\"\n",
    "        #\"frequency\": \"15min\",\n",
    "        #\"lr\": \"0.001\",\n",
    "        #\"batch_size\": \"32\",\n",
    "       # \"with_examweek\": \"False\",\n",
    "        #\"course_encoding_dim\": \"3\",\n",
    "        #\"room_ids\": \"[0]\",\n",
    "        #\"num_layers\": \"3\",\n",
    "        #\"hidden_size\": \"[32, 32]\",\n",
    "        #\"y_horizon\": \"36\",\n",
    "        #\"dataset\": \"test\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "results_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('occrate',)\n",
      "0.020438333333333336\n",
      "0.0002250896117845821\n",
      "\n",
      "('occrate_avgocc',)\n",
      "0.018653666666666666\n",
      "0.0003666365139117126\n",
      "\n",
      "('occrate_avgocc_coursenumber',)\n",
      "0.016270666666666666\n",
      "0.00020652441340755182\n",
      "\n",
      "('occrate_coursenumber',)\n",
      "0.016612666666666668\n",
      "0.0004147051161166604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill dataframe with group means and stds\n",
    "\n",
    "\n",
    "\n",
    "group_list = []\n",
    "\n",
    "for group, df in results_out.groupby([\"features\"]):\n",
    "    print(group)\n",
    "    print(df[\"model_losses\"].mean())\n",
    "    print(df[\"model_losses\"].std())\n",
    "    print()\n",
    "    # add data to new dataframe\n",
    "    \n",
    "    group_list.append(\n",
    "        (group[0], df[\"model_losses\"].mean(), df[\"model_losses\"].std())\n",
    "    )\n",
    "    \n",
    "df_plot = pd.DataFrame(group_list, columns=[\"features\", \"mean\", \"std\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAH5CAYAAAAmxkCDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6dUlEQVR4nO3deXhV1d3+//uQOSQnMkgGGzKIUBAHSB4QMMW2zK2FluI8UAsVrNKQpxXRFtCqOGChVgEVFJXWoo+1ikUGW6FRomAgtJBIRAKhmBgjmqQiCUk+vz/45vw4JIEkAgs479d15bqy115rr7XPWSfc2ay94zEzEwAAAABn2rkeAAAAABDoCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwLdj2Ak6m+vl4ff/yxoqOj5fF4XA8HAAAARzAzVVVVKSEhQe3aBc7144AK5R9//LESExNdDwMAAADHsGfPHn3jG99wPYyTJqBCeXR0tKRDb7LX63U8GgAAABypsrJSiYmJvtwWKAIqlDcsWfF6vYRyAACAU1igLTUOnIU6AAAAwCmKUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcCzY9QDOBIuyd2pRdlGr203ISNGEjNQTMCIAAACcTgjlx0HVgVqVVh5oUzsAAACAUH4cRIcHK84b7ldmMn1SWS1JivWGySNPk+0AAAAAj5mZ60GcLJWVlYqJiVFFRYW8Xu8J7Wt/Ta16zVglScq/Z7giQwngAAAAx3Iy89qphBs9AQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFB+gtTVm+/7DUX7/LYBAACAwxHKT4CVW0s05HfrfNvjn9moSx/8h1ZuLXE4KgAAAJyqCOXH2cqtJZq8dJM+qaz2Ky+tOKDJSzcRzAEAANAIofw4qqs33b08X00tVGkou3t5PktZAAAA4IdQfhxtKNqnkooDze43SSUVB7ShaN/JGxQAAABOeYTy46isqvlA3pZ6AAAACAyE8uOoS3T4ca0HAACAwEAoP476pXRUfEy4PM3s90iKjwlXv5SOJ3NYAAAAOMURyo+joHYezby8lyQ1CuYN2zMv76Wgds3FdgAAAAQiQvlxNqJ3vBZc11ddvGF+5XEx4VpwXV+N6B3vaGQAAAA4VQW7HsCZaETveA3q1lkXzFotSVryk/9Rxnlnc4UcAAAATeJK+QlyeADvl9KRQA4AAIBmEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4Fiw6wGcCRZl79Si7CK/MpP5vv/2nLXyyNOo3YSMFE3ISD3h4wMAAMCpjVB+HFQdqFVp5YFm939SWd1sOwAAAIBQfhxEhwcrzhvepnYAAACAx8zs2NXODJWVlYqJiVFFRYW8Xq/r4QAAAOAIgZrXuNETAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADH2hTK58+fr5SUFIWHhystLU3Z2dlHrb9u3TqlpaUpPDxcqampWrhwod/+p556ShkZGerQoYM6dOigIUOGaMOGDV+7XwAAAOB00OpQvmzZMmVmZuquu+7S5s2blZGRoZEjR6q4uLjJ+kVFRRo1apQyMjK0efNm3XnnnZoyZYpefvllX521a9fq6quv1ltvvaWcnBx17dpVw4YN0969e9vcLwAAAHC68JiZtaZB//791bdvXy1YsMBX1rNnT40ZM0azZ89uVH/atGl67bXXVFBQ4CubNGmStmzZopycnCb7qKurU4cOHfTYY4/phhtuaFO/TamsrFRMTIwqKirk9Xpb1AYAAAAnT6DmtVZdKa+pqVFubq6GDRvmVz5s2DCtX7++yTY5OTmN6g8fPlzvv/++Dh482GSb/fv36+DBg+rYsWOb+5Wk6upqVVZW+n0BAAAAp5pWhfLy8nLV1dUpNjbWrzw2NlalpaVNtiktLW2yfm1trcrLy5tsc8cdd+icc87RkCFD2tyvJM2ePVsxMTG+r8TExGOeIwAAAHCytelGT4/H47dtZo3KjlW/qXJJeuihh/TCCy/oL3/5i8LDw79Wv9OnT1dFRYXva8+ePc3WBQAAAFwJbk3lzp07KygoqNHV6bKyskZXsRvExcU1WT84OFidOnXyK58zZ47uv/9+vfnmm7rwwgu/Vr+SFBYWprCwsBadGwAAAOBKq66Uh4aGKi0tTWvWrPErX7NmjQYOHNhkmwEDBjSqv3r1aqWnpyskJMRX9vDDD+u3v/2tVq5cqfT09K/dLwAAAHC6aNWVcknKysrS9ddfr/T0dA0YMEBPPvmkiouLNWnSJEmHlozs3btXzz33nKRDT1p57LHHlJWVpYkTJyonJ0eLFy/WCy+84DvmQw89pN/85jf605/+pOTkZN8V8aioKEVFRbWoXwAAAOB01epQfuWVV+qzzz7TPffco5KSEvXu3VsrVqxQUlKSJKmkpMTv2eEpKSlasWKFpk6dqscff1wJCQl69NFHNXbsWF+d+fPnq6amRj/+8Y/9+po5c6ZmzZrVon4BAACA01Wrn1N+OgvU514CAACcLgI1r7Xp6SsAAAAAjh9COQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGNtCuXz589XSkqKwsPDlZaWpuzs7KPWX7dundLS0hQeHq7U1FQtXLjQb/+2bds0duxYJScny+PxaN68eY2OUVVVpczMTCUlJSkiIkIDBw7Uxo0b2zJ8AAAA4JQS3NoGy5YtU2ZmpubPn69BgwbpiSee0MiRI5Wfn6+uXbs2ql9UVKRRo0Zp4sSJWrp0qd555x3dcsstOvvsszV27FhJ0v79+5Wamqpx48Zp6tSpTfY7YcIEbd26Vc8//7wSEhK0dOlSDRkyRPn5+TrnnHNaexoA2mhR9k4tyi5qdbsJGSmakJF6AkYEAMDpz2Nm1poG/fv3V9++fbVgwQJfWc+ePTVmzBjNnj27Uf1p06bptddeU0FBga9s0qRJ2rJli3JychrVT05OVmZmpjIzM31lX331laKjo/Xqq6/qe9/7nq/84osv1ve//33de++9LRp7ZWWlYmJiVFFRIa/X26I2APzNXVOo3//9w1a3+8V3z9PUod1PwIgAAGeSQM1rrbpSXlNTo9zcXN1xxx1+5cOGDdP69eubbJOTk6Nhw4b5lQ0fPlyLFy/WwYMHFRIScsx+a2trVVdXp/DwcL/yiIgIvf322822q66uVnV1tW+7srLymH0BOLro8GDFef0/iybTJ5WHPmux3jB55GmyHQAAaFqr/pUsLy9XXV2dYmNj/cpjY2NVWlraZJvS0tIm69fW1qq8vFzx8fHH7Dc6OloDBgzQb3/7W/Xs2VOxsbF64YUX9N577+m8885rtt3s2bN19913t+DMALTUhIzURstQ9tfUqteMVZKkt355mSJDCeAAALRGm2709Hj8r4KZWaOyY9Vvqvxonn/+eZmZzjnnHIWFhenRRx/VNddco6CgoGbbTJ8+XRUVFb6vPXv2tLg/AAAA4GRp1eWszp07KygoqNFV8bKyskZXwxvExcU1WT84OFidOnVqcd/nnnuu1q1bpy+//FKVlZWKj4/XlVdeqZSUlGbbhIWFKSwsrMV9AAAAAC606kp5aGio0tLStGbNGr/yNWvWaODAgU22GTBgQKP6q1evVnp6eovWkx+pffv2io+P1+eff65Vq1Zp9OjRrT4GAAAAcCpp9cLPrKwsXX/99UpPT9eAAQP05JNPqri4WJMmTZJ0aMnI3r179dxzz0k69KSVxx57TFlZWZo4caJycnK0ePFivfDCC75j1tTUKD8/3/f93r17lZeXp6ioKHXr1k2StGrVKpmZevTooR07duhXv/qVevTooZ/85Cdf+0UAAAAAXGp1KL/yyiv12Wef6Z577lFJSYl69+6tFStWKCkpSZJUUlKi4uJiX/2UlBStWLFCU6dO1eOPP66EhAQ9+uijvmeUS9LHH3+sPn36+LbnzJmjOXPmaPDgwVq7dq0kqaKiQtOnT9d//vMfdezYUWPHjtV9993XpqvtAAAAwKmk1c8pP50F6nMvgRPt8Kev5N8znKevAADaLFDzWpuevgIAAADg+CGUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAX1tdvfm+31C0z28bAAAcG6EcwNeycmuJhvxunW97/DMbdemD/9DKrSUORwUAwOmFUA6gzVZuLdHkpZv0SWW1X3lpxQFNXrqJYA4AQAsRygG0SV296e7l+WpqoUpD2d3L81nKAgBACxDKAbTJhqJ9Kqk40Ox+k1RScUAbivadvEEBAHCaIpQDaJOyquYDeVvqAQAQyAjlANqkS3T4ca0HAEAgI5QDaJN+KR0VHxMuTzP7PZLiY8LVL6XjyRwWAACnJUI5gDYJaufRzMt7SVKjYN6wPfPyXgpq11xsBwAADQjlANpsRO94Lbiur7p4w/zK42LCteC6vhrRO97RyAAAOL0Eux4AgNPbiN7xGtStsy6YtVqStOQn/6OM887mCjkAAK3AlXIAX9vhAbxfSkcCOQAArUQoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwLdj0AAKeXRdk7tSi7yK/MZL7vvz1nrTzyNGo3ISNFEzJST/j4AAA4HRHKAbRK1YFalVYeaHb/J5XVzbYDAABNI5QDaJXo8GDFecPb1A4AADTNY2Z27GpnhsrKSsXExKiiokJer9f1cAAAAHCEQM1r3OgJAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADH2hTK58+fr5SUFIWHhystLU3Z2dlHrb9u3TqlpaUpPDxcqampWrhwod/+bdu2aezYsUpOTpbH49G8efMaHaO2tla//vWvlZKSooiICKWmpuqee+5RfX19W04BAAAAOGW0OpQvW7ZMmZmZuuuuu7R582ZlZGRo5MiRKi4ubrJ+UVGRRo0apYyMDG3evFl33nmnpkyZopdfftlXZ//+/UpNTdUDDzyguLi4Jo/z4IMPauHChXrsscdUUFCghx56SA8//LD+8Ic/tPYUAAAAgFOKx8ysNQ369++vvn37asGCBb6ynj17asyYMZo9e3aj+tOmTdNrr72mgoICX9mkSZO0ZcsW5eTkNKqfnJyszMxMZWZm+pV///vfV2xsrBYvXuwrGzt2rCIjI/X88883Odbq6mpVV1f7tisrK5WYmKiKigp5vd4WnzMAAABOjsrKSsXExARcXmvVlfKamhrl5uZq2LBhfuXDhg3T+vXrm2yTk5PTqP7w4cP1/vvv6+DBgy3u+9JLL9Xf//53FRYWSpK2bNmit99+W6NGjWq2zezZsxUTE+P7SkxMbHF/AAAAwMkS3JrK5eXlqqurU2xsrF95bGysSktLm2xTWlraZP3a2lqVl5crPj6+RX1PmzZNFRUV+uY3v6mgoCDV1dXpvvvu09VXX91sm+nTpysrK8u33XClHAAAADiVtCqUN/B4PH7bZtao7Fj1myo/mmXLlmnp0qX605/+pPPPP195eXnKzMxUQkKCbrzxxibbhIWFKSwsrMV9AAAAAC60KpR37txZQUFBja6Kl5WVNboa3iAuLq7J+sHBwerUqVOL+/7Vr36lO+64Q1dddZUk6YILLtDu3bs1e/bsZkM5AAAAcDpo1Zry0NBQpaWlac2aNX7la9as0cCBA5tsM2DAgEb1V69erfT0dIWEhLS47/3796tdO//hBgUF8UhEAAAAnPZavXwlKytL119/vdLT0zVgwAA9+eSTKi4u1qRJkyQdWse9d+9ePffcc5IOPWnlscceU1ZWliZOnKicnBwtXrxYL7zwgu+YNTU1ys/P932/d+9e5eXlKSoqSt26dZMkXX755brvvvvUtWtXnX/++dq8ebN+97vf6aabbvraLwIAAADgUqsfiSgd+uNBDz30kEpKStS7d2/NnTtX3/rWtyRJ48eP165du7R27Vpf/XXr1mnq1Knatm2bEhISNG3aNF+Il6Rdu3YpJSWlUT+DBw/2Haeqqkq/+c1v9Morr6isrEwJCQm6+uqrNWPGDIWGhrZo3IH6iB0AAIDTRaDmtTaF8tNVoL7JAAAAp4tAzWut/oueAAAAAI4vQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjwW1pNH/+fD388MMqKSnR+eefr3nz5ikjI6PZ+uvWrVNWVpa2bdumhIQE3X777Zo0aZJv/7Zt2zRjxgzl5uZq9+7dmjt3rjIzM/2OkZycrN27dzc69i233KLHH3+8LacBAAAASYuyd2pRdlGr203ISNGEjNQTMKLA0+pQvmzZMmVmZmr+/PkaNGiQnnjiCY0cOVL5+fnq2rVro/pFRUUaNWqUJk6cqKVLl+qdd97RLbfcorPPPltjx46VJO3fv1+pqakaN26cpk6d2mS/GzduVF1dnW9769atGjp0qMaNG9faUwAAAMBhqg7UqrTyQJva4fjwmJm1pkH//v3Vt29fLViwwFfWs2dPjRkzRrNnz25Uf9q0aXrttddUUFDgK5s0aZK2bNminJycRvWTk5OVmZnZ6Er5kTIzM/X666/rww8/lMfjadHYKysrFRMTo4qKCnm93ha1AQAAONM1daXcZPqkslqSFOsNk0eN89aJuFIeqHmtVVfKa2pqlJubqzvuuMOvfNiwYVq/fn2TbXJycjRs2DC/suHDh2vx4sU6ePCgQkJCWjnkQ+NYunSpsrKyjhrIq6urVV1d7duurKxsdV8AAABnugkZqY3C9f6aWvWasUqS9NYvL1NkaJtWPaOFWnWjZ3l5uerq6hQbG+tXHhsbq9LS0ibblJaWNlm/trZW5eXlrRzuIX/961/1xRdfaPz48UetN3v2bMXExPi+EhMT29QfAAAAcCK16ekrR16dNrOjXrFuqn5T5S21ePFijRw5UgkJCUetN336dFVUVPi+9uzZ06b+AAAAgBOpVf8P0blzZwUFBTW6Kl5WVtboaniDuLi4JusHBwerU6dOrRyutHv3br355pv6y1/+csy6YWFhCgsLa3UfAAAAwMnUqivloaGhSktL05o1a/zK16xZo4EDBzbZZsCAAY3qr169Wunp6W1aT/7MM8+oS5cu+t73vtfqtgAAAMCpqNXLV7KysrRo0SI9/fTTKigo0NSpU1VcXOx77vj06dN1ww03+OpPmjRJu3fvVlZWlgoKCvT0009r8eLF+uUvf+mrU1NTo7y8POXl5ammpkZ79+5VXl6eduzY4dd3fX29nnnmGd14440KDuZmAwAAAJwZWp1sr7zySn322We65557VFJSot69e2vFihVKSkqSJJWUlKi4uNhXPyUlRStWrNDUqVP1+OOPKyEhQY8++qjvGeWS9PHHH6tPnz6+7Tlz5mjOnDkaPHiw1q5d6yt/8803VVxcrJtuuqkt5woAAACcklr9nPLTWaA+9xIAAKC1Dn8kYv49w0/aIxEDNa+16ekrAAAAAI4fQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACOEcoBAAAAxwjlAAAAaKSu3nzfbyja57eN449QDgAAAD8rt5ZoyO/W+bbHP7NRlz74D63cWuJwVGc2QjkAAAB8Vm4t0eSlm/RJZbVfeWnFAU1euolgfoIQygEAACDp0JKVu5fnq6mFKg1ldy/PZynLCUAoBwAAgKRDa8dLKg40u98klVQc0IaifSdvUAGCUA4AAABJUllV84G8LfXQcoRyAAAASJK6RIcf13poOUI5AAAAJEn9UjoqPiZcnmb2eyTFx4SrX0rHkzmsgEAoBwAAgCQpqJ1HMy/vJUmNgnnD9szLeymoXXOxHW1FKAcAAIDPiN7xWnBdX3XxhvmVx8WEa8F1fTWid7yjkZ3Zgl0PAAAAAKeWEb3jNahbZ10wa7UkaclP/kcZ553NFfITiCvlAAAAaOTwAN4vpSOB/AQjlAMAAACOEcoBAAAAxwjlAAAAgGOEcgAAAMAxnr4CAEAzFmXv1KLsola3m5CRogkZqSdgRADOVIRyAACaUXWgVqWVB9rUDgBag1AOAEAzosODFecN9yszmT6prJYkxXrD5GniD5JHh/PPK4DW4acGAADNmJCR2mgZyv6aWvWasUqS9NYvL1NkKP+UAvj6uNETAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4RigHAAAAHCOUAwDQCnX15vt+Q9E+v20AaCtCOQAALbRya4mG/G6db3v8Mxt16YP/0MqtJQ5HBeBMQCgHAKAFVm4t0eSlm/RJZbVfeWnFAU1euolgDuBrIZQDAHAMdfWmu5fnq6mFKg1ldy/PZykLgDYjlAMAcAwbivappOJAs/tNUknFAW0o2nfyBgXgjEIoBwDgGMqqmg/kbakHAEcilAMAcAxdosOPaz0AOBKhHACAY+iX0lHxMeHyNLPfIyk+Jlz9UjqezGEBOIMQygEAOIagdh7NvLyXJDUK5g3bMy/vpaB2zcV2ADg6QjkAAC0wone8FlzXV128YX7lcTHhWnBdX43oHe9oZADOBMGuBwAAwOliRO94DerWWRfMWi1JWvKT/1HGeWdzhRzA10YoBwCgFQ4P4P1SOhLIcUZYlL1Ti7KL/MrssCfzf3vOWnmauKtiQkaKJmSknvDxBQJCOQAAQICrOlCr0srmH+l55F+yPbwdjg9COQAAQICLDg9WnLf1j/SMDidKHi+8kgAAAAFuQkYqy1Ac4+krAAAAgGOEcgAAAMAxQjkAAADgGKEcAAAAcIxQDgAAADhGKAcAAAAcI5QDAAAAjhHKAQAAAMf440EAADRjUfZOLcou8iszme/7b89ZK488jdpNyEjhD7EAaBVCOQAAzag6UKvSygPN7v+ksrrZdgDQGoRyAACaER0erDhveJvaAUBreMzMjl3N3/z58/Xwww+rpKRE559/vubNm6eMjIxm669bt05ZWVnatm2bEhISdPvtt2vSpEm+/du2bdOMGTOUm5ur3bt3a+7cucrMzGx0nL1792ratGl644039NVXX6l79+5avHix0tLSWjTuyspKxcTEqKKiQl6vt7WnDQAAgBMsUPNaq2/0XLZsmTIzM3XXXXdp8+bNysjI0MiRI1VcXNxk/aKiIo0aNUoZGRnavHmz7rzzTk2ZMkUvv/yyr87+/fuVmpqqBx54QHFxcU0e5/PPP9egQYMUEhKiN954Q/n5+XrkkUd01llntfYUAAAAgFNKq6+U9+/fX3379tWCBQt8ZT179tSYMWM0e/bsRvWnTZum1157TQUFBb6ySZMmacuWLcrJyWlUPzk5WZmZmY2ulN9xxx165513lJ2d3Zrh+gnU37wAAABOF4Ga11p1pbympka5ubkaNmyYX/mwYcO0fv36Jtvk5OQ0qj98+HC9//77OnjwYIv7fu2115Senq5x48apS5cu6tOnj5566qmjtqmurlZlZaXfFwAAAHCqaVUoLy8vV11dnWJjY/3KY2NjVVpa2mSb0tLSJuvX1taqvLy8xX3v3LlTCxYs0HnnnadVq1Zp0qRJmjJlip577rlm28yePVsxMTG+r8TExBb3BwAAAJwsbfrjQR6P/zNZzaxR2bHqN1V+NPX19erbt6/uv/9+9enTRzfffLMmTpzot4zmSNOnT1dFRYXva8+ePS3uDwAAADhZWhXKO3furKCgoEZXxcvKyhpdDW8QFxfXZP3g4GB16tSpxX3Hx8erV69efmU9e/Zs9gZTSQoLC5PX6/X7AgAAAE41rQrloaGhSktL05o1a/zK16xZo4EDBzbZZsCAAY3qr169Wunp6QoJCWlx34MGDdL27dv9ygoLC5WUlNTiYwAAAACnolYvX8nKytKiRYv09NNPq6CgQFOnTlVxcbHvuePTp0/XDTfc4Ks/adIk7d69W1lZWSooKNDTTz+txYsX65e//KWvTk1NjfLy8pSXl6eamhrt3btXeXl52rFjh6/O1KlT9e677+r+++/Xjh079Kc//UlPPvmkfv7zn3+d8wcAAACca/MfD3rooYdUUlKi3r17a+7cufrWt74lSRo/frx27dqltWvX+uqvW7dOU6dO9f3xoGnTpvn98aBdu3YpJSWlUT+DBw/2O87rr7+u6dOn68MPP1RKSoqysrI0ceLEFo87UB+xAwAAcLoI1LzWplB+ugrUNxkAAOB0Eah5rU1PXwEAAABw/BDKAQAAAMcI5QAAAIBjhHIAAADAMUI5AAAA4BihHAAAAHCMUA4AAAA4Fux6ACdTwyPZKysrHY8EAAAATWnIaQH0p3QkBVgor6qqkiQlJiY6HgkAAACOpqqqSjExMa6HcdIE1F/0rK+v18cff6zo6Gh5PJ4T3l9lZaUSExO1Z8+egPqLVAhMzHcEEuY7AoWLuW5mqqqqUkJCgtq1C5yV1gF1pbxdu3b6xje+cdL79Xq9/NBGwGC+I5Aw3xEoTvZcD6Qr5A0C59cPAAAA4BRFKAcAAAAcI5SfQGFhYZo5c6bCwsJcDwU44ZjvCCTMdwQK5vrJE1A3egIAAACnIq6UAwAAAI4RygEAAADHCOUAAACAY4RyAAAAwDFCOQAAOCUkJydr3rx5roeBALRkyRKdddZZTsdAKD/FjB8/XmPGjHE9DAQo5h+awrwAThw+X2hAKD9JDh486HoICGDMPzSFeXFmMTPV1ta6HsYpx9U8D7TPV01NjeshnJJaMw8COpRXV1drypQp6tKli8LDw3XppZdq48aNvv3btm3T9773PXm9XkVHRysjI0MfffSRb//TTz+t888/X2FhYYqPj9ett97q2+fxeLRw4UKNHj1a7du317333qu6ujr99Kc/VUpKiiIiItSjRw/9/ve/97WZNWuWnn32Wb366qvyeDzyeDxau3atJGnv3r268sor1aFDB3Xq1EmjR4/Wrl27TvhrhBMnUObfxo0bNXToUHXu3FkxMTEaPHiwNm3a5Nt/9dVX66qrrvJrc/DgQXXu3FnPPPOMJKmqqkrXXnut2rdvr/j4eM2dO1eXXXaZMjMzfW0+//xz3XDDDerQoYMiIyM1cuRIffjhh37HfeeddzR48GBFRkaqQ4cOGj58uD7//HNJUn19vR588EF169ZNYWFh6tq1q+67774WnePxxLw45EyYF//5z3901VVXqWPHjmrfvr3S09P13nvv+fYvWLBA5557rkJDQ9WjRw89//zzvn27du2Sx+NRXl6er+yLL77we/3Xrl0rj8ejVatWKT09XWFhYcrOztaWLVv07W9/W9HR0fJ6vUpLS9P777/vO8769ev1rW99SxEREUpMTNSUKVP05Zdf+vYnJyfr/vvv10033aTo6Gh17dpVTz75pG9/Q79ffPGFrywvL08ej8f3/jcsBXj99dfVo0cPRUZG6sc//rG+/PJLPfvss0pOTlaHDh102223qa6uzu91q6qq0jXXXKOoqCglJCToD3/4g9/+iooK/exnP1OXLl3k9Xr1ne98R1u2bPHtnzVrli6++GI9/fTTSk1NVVhYmBr+JEugfL6ONdbi4mKNHj1aUVFR8nq9uuKKK/TJJ5/49jd19T4zM1OXXXaZb/uyyy7TrbfeqqysLHXu3FlDhw71nVPXrl0VFhamhIQETZkyxdempqZGt99+u8455xy1b99e/fv3952v9P/Pm1WrVqlnz56KiorSiBEjVFJS4tfv4Z9xSRozZozGjx/v205OTta9996rG264QVFRUUpKStKrr76qTz/91HfeF1xwgd/nosFf//pXde/eXeHh4Ro6dKj27Nnjt3/58uVKS0tTeHi4UlNTdffdd/v9MtzUPGgxC2BTpkyxhIQEW7FihW3bts1uvPFG69Chg3322Wf2n//8xzp27Gg/+tGPbOPGjbZ9+3Z7+umn7YMPPjAzs/nz51t4eLjNmzfPtm/fbhs2bLC5c+f6ji3JunTpYosXL7aPPvrIdu3aZTU1NTZjxgzbsGGD7dy505YuXWqRkZG2bNkyMzOrqqqyK664wkaMGGElJSVWUlJi1dXV9uWXX9p5551nN910k/3rX/+y/Px8u+aaa6xHjx5WXV3t4qXDcRAo8+/vf/+7Pf/885afn2/5+fn205/+1GJjY62ystLMzJYvX24RERFWVVXla7N8+XILDw+3iooKMzObMGGCJSUl2Ztvvmn//ve/7Yc//KFFR0fbL37xC1+bH/zgB9azZ0/75z//aXl5eTZ8+HDr1q2b1dTUmJnZ5s2bLSwszCZPnmx5eXm2detW+8Mf/mCffvqpmZndfvvt1qFDB1uyZInt2LHDsrOz7amnnmr7G9xGzIszY15UVVVZamqqZWRkWHZ2tn344Ye2bNkyW79+vZmZ/eUvf7GQkBB7/PHHbfv27fbII49YUFCQ/eMf/zAzs6KiIpNkmzdv9h3z888/N0n21ltvmZnZW2+9ZZLswgsvtNWrV9uOHTusvLzczj//fLvuuuusoKDACgsL7cUXX7S8vDwzM/vXv/5lUVFRNnfuXCssLLR33nnH+vTpY+PHj/f1k5SUZB07drTHH3/cPvzwQ5s9e7a1a9fOCgoK/Pr9/PPPfW02b95skqyoqMjMzJ555hkLCQmxoUOH2qZNm2zdunXWqVMnGzZsmF1xxRW2bds2W758uYWGhtqf//xnv76jo6Nt9uzZtn37dnv00UctKCjIVq9ebWZm9fX1NmjQILv88stt48aNVlhYaP/7v/9rnTp1ss8++8zMzGbOnGnt27e34cOH26ZNm2zLli1WX19vZoHz+TraWOvr661Pnz526aWX2vvvv2/vvvuu9e3b1wYPHuxrf+ONN9ro0aP9jvmLX/zCr87gwYMtKirKfvWrX9kHH3xgBQUF9tJLL5nX67UVK1bY7t277b333rMnn3zS1+aaa66xgQMH2j//+U/bsWOHPfzwwxYWFmaFhYV+82bIkCG2ceNGy83NtZ49e9o111zj1+/hn3Ezs9GjR9uNN97oN486duxoCxcutMLCQps8ebJFR0fbiBEj7MUXX7Tt27fbmDFjrGfPnr650dB3enq6rV+/3t5//33r16+fDRw40HfclStXmtfrtSVLlthHH31kq1evtuTkZJs1a9ZR50FLBWwo/+9//2shISH2xz/+0VdWU1NjCQkJ9tBDD9n06dMtJSXF94P7SAkJCXbXXXc1e3xJlpmZecxx3HLLLTZ27FjfdlMfhMWLF1uPHj18E8fMrLq62iIiImzVqlXH7AOnnkCef7W1tRYdHW3Lly83s0Pn3blzZ3vuued8da6++mobN26cmZlVVlZaSEiIvfTSS779X3zxhUVGRvp+MBcWFpoke+edd3x1ysvLLSIiwl588UXfMQcNGtTkmCorKy0sLMxJCD8c8+LMmRdPPPGERUdH+4LikQYOHGgTJ070Kxs3bpyNGjXKzFoXyv/617/6HSc6OtqWLFnSZL/XX3+9/exnP/Mry87Otnbt2tlXX31lZocCzXXXXefbX19fb126dLEFCxb49XusUC7JduzY4atz8803W2RkpN8vWsOHD7ebb77Zt52UlGQjRozwG9+VV15pI0eONLNDv8x5vV47cOCAX51zzz3XnnjiCTM7FMpDQkKsrKzMr04gfb6ONtbVq1dbUFCQFRcX+8q2bdtmkmzDhg3NjqmpUH7xxRf71XnkkUese/fuTb6GO3bsMI/HY3v37vUr/+53v2vTp083s6bnzeOPP26xsbF+/bYklB8+h0tKSkyS/eY3v/GV5eTkmCQrKSnx6/vdd9/11SkoKDBJ9t5775mZWUZGht1///1+fT///PMWHx/v227pPGhKwC5f+eijj3Tw4EENGjTIVxYSEqJ+/fqpoKBAeXl5ysjIUEhISKO2ZWVl+vjjj/Xd7373qH2kp6c3Klu4cKHS09N19tlnKyoqSk899ZSKi4uPepzc3Fzt2LFD0dHRioqKUlRUlDp27KgDBw74/bcaTh+BNP/Kyso0adIkde/eXTExMYqJidF///tfX78hISEaN26c/vjHP0qSvvzyS7366qu69tprJUk7d+7UwYMH1a9fP98xY2Ji1KNHD992QUGBgoOD1b9/f19Zp06d1KNHDxUUFEg69N/rzb1mBQUFqq6uPuZreqIxL86ceZGXl6c+ffqoY8eOzR778PdZkgYNGuQbV2sc+Z5mZWVpwoQJGjJkiB544AG/9yM3N1dLlizxvWdRUVEaPny46uvrVVRU5Kt34YUX+r73eDyKi4tTWVlZq8YVGRmpc88917cdGxur5ORkRUVF+ZUdedwBAwY02m54XXJzc/Xf//5XnTp18juHoqIiv/NMSkrS2Wef7XecQPl8HWusBQUFSkxMVGJioq+sV69eOuuss1o9/44833Hjxumrr75SamqqJk6cqFdeecW3tGPTpk0yM3Xv3t3vvVu3bp3fOR05b+Lj41s99yT/ORwbGytJuuCCCxqVHX7s4OBgv3P65je/6fe65Obm6p577vEb/8SJE1VSUqL9+/c3+7q0VHCbWp0B7P+tL/N4PI3KPR6PIiIimm17tH2Ha9++vd/2iy++qKlTp+qRRx7RgAEDFB0drYcffthvjWFT6uvrlZaW5vvH6XBH/tDB6SGQ5t/48eP16aefat68eUpKSlJYWJgGDBjgd1PQtddeq8GDB6usrExr1qxReHi4Ro4cKenor1VT3x9Zp6Hd8XhNTzTmxZkzL1rStrn3WZLatWvnK2vQ3A1jR76ns2bN0jXXXKO//e1veuONNzRz5kz9+c9/1g9/+EPV19fr5ptv9lvn26Br166+748Mph6PR/X19a0aW1PHONpxj6bhdamvr1d8fLzfOuQGhz/O7sjX5PDxnumfr2ON9fB51lx5u3btGn1+mnqPjzzfxMREbd++XWvWrNGbb76pW265RQ8//LDWrVun+vp6BQUFKTc3V0FBQX7tDv9Frak5cvhYWjq2w4/TcF5NlR05/5p6bQ6ve/fdd+tHP/pRozrh4eG+75uafy0RsFfKu3XrptDQUL399tu+soMHD+r9999Xz549deGFFyo7O7vJNzo6OlrJycn6+9//3qo+s7OzNXDgQN1yyy3q06ePunXr1ug33tDQ0EY3vfTt21cffvihunTpom7duvl9xcTEtGoMODUE0vzLzs7WlClTNGrUKN9NR+Xl5X51Bg4cqMTERC1btkx//OMfNW7cOIWGhkqSzj33XIWEhGjDhg2++pWVlX436/Xq1Uu1tbV+/9B99tlnKiwsVM+ePSUdumrS3Gt23nnnKSIiotWv6fHGvDhz5sWFF16ovLw87du3r8n9PXv29HufpUM3YDaMqyF4HX6D2+E3fR5L9+7dNXXqVK1evVo/+tGPfDfH9u3bV9u2bWv0njXMvZb4umM7lnfffbfR9je/+U1Jh8ZfWlqq4ODgRuPv3LnzUY8bKJ+vY421V69eKi4u9ruBMT8/XxUVFX7z7/D3V2r5exwREaEf/OAHevTRR7V27Vrl5OTo3//+t/r06aO6ujqVlZU1Oqe4uLgWHbupsdXV1Wnr1q0tbn80tbW1fjd/bt++XV988YXf/Nu+fXuTn5+GX1a/ljYtejlD/OIXv7CEhAR74403/G742Ldvn5WXl1unTp18N3wUFhbac88957vhY8mSJRYeHm6///3vrbCw0HJzc+3RRx/1HVuSvfLKK379zZs3z7xer61cudK2b99uv/71r83r9dpFF13kq3PfffdZ165d7YMPPrBPP/3UampqfDd8XHbZZfbPf/7Tdu7caWvXrrUpU6bYnj17TsZLhRMgUObfxRdfbEOHDrX8/Hx79913LSMjwyIiIvxukDIzu/POO61Xr14WHBxs2dnZfvsmTJhgKSkp9o9//MO2bt1qY8eOtejoaL91e6NHj7ZevXpZdna25eXl2YgRI/xu6Nu+fbuFhoba5MmTbcuWLVZQUGDz58/33dA3a9Ys69Chgz377LO2Y8cOy8nJsUWLFh3z/I435sVcv3qn67yorq627t27W0ZGhr399tv20Ucf2f/93//5bvR85ZVXLCQkxBYsWGCFhYW+Gz0b1oubmV1yySWWkZFh27Zts3Xr1lm/fv2aXFN++Nru/fv3289//nN76623bNeuXfb222/bueeea7fffruZmW3ZssUiIiLslltusc2bN1thYaG9+uqrduutt/qOkZSU1Oh9uOiii2zmzJlmdmgddmJioo0bN862b99ur7/+uvXo0aPRmvKYmBi/Y8ycOdNvXpk1XruclJRkXq/XHnzwQdu+fbs99thjFhQUZCtXrjSzQ+vbL730Urvooots5cqVVlRUZO+8847dddddtnHjxmb7aRAon6+jjbXhRs+MjAzLzc219957z9LS0vzWi69cudI8Ho89++yzVlhYaDNmzDCv19toTfmRa7ufeeYZW7Rokf373/+2jz76yO666y6LiIiw8vJyMzO79tprLTk52V5++WXbuXOnbdiwwR544AH729/+5mt/5Lx55ZVX7PC4unDhQouMjLTXX3/dCgoK7Gc/+5l5vd5Ga8qPnMNHvj9H3rfRcKNnv3797N1337Xc3FwbMGCAXXLJJX6vS3BwsM2cOdO2bt1q+fn59uc//9lv/X5T86ClAjqUf/XVV3bbbbdZ586dLSwszAYNGuS7ycHs0A+vYcOGWWRkpEVHR1tGRoZ99NFHvv0LFy60Hj16WEhIiMXHx9ttt93m29fUm3LgwAEbP368xcTE2FlnnWWTJ0+2O+64w+/DWVZWZkOHDrWoqCi/H74lJSV2ww03+MaamppqEydO9D2FAKefQJl/mzZtsvT0dAsLC7PzzjvPXnrppSZ/YDbcaJSUlOR3c5PZoRvurrnmGouMjLS4uDj73e9+Z/369bM77rjDV2ffvn12/fXXW0xMjEVERNjw4cN9d/Q3WLt2rQ0cONDCwsLsrLPOsuHDh/sCTV1dnd17772WlJRkISEh1rVr10Y39JwMzIu5fvVO53mxa9cuGzt2rHm9XouMjLT09HTfDWNmh56QkZqaaiEhIda9e3e/m1rNzPLz8+2SSy6xiIgIu/jii2316tXHDOXV1dV21VVXWWJiooWGhlpCQoLdeuutvps4zcw2bNjgez/bt29vF154od13332+/ccK5WZmb7/9tl1wwQUWHh5uGRkZ9tJLLx23UH733XfbFVdcYZGRkRYbG2vz5s3za1NZWWm33XabJSQkWEhIiCUmJtq1117ru3HxaKE8UD5fxxrr7t277Qc/+IG1b9/eoqOjbdy4cVZaWurXfsaMGRYbG2sxMTE2depUu/XWW48Zyl955RXr37+/eb1ea9++vV1yySX25ptv+vY3PI0mOTnZQkJCLC4uzn74wx/av/71LzNrWSivqamxyZMnW8eOHa1Lly42e/bsJm/0bEsoj4mJsZdfftlSU1MtNDTUvvOd7zR6esrKlStt4MCBFhERYV6v1/r16+f3hJmvE8o9/+8AAHDa+PLLL3XOOefokUce0U9/+lPXw8EpgnkB4HQWsDd6Ajh9bN68WR988IH69euniooK3XPPPZKk0aNHOx4ZXGJeADiTBOyNngCOj8MfDXXkV3Z29nHrZ86cObrooos0ZMgQffnll8rOzj7mjV1w50yfF/fff3+z59fwhBjgRDlZny+cXCxfAfC17Nixo9l955xzzinzuEGcXGf6vNi3b1+zT1aJiIjQOeecc5JHhEBypn++AhWhHAAAAHCM5SsAAACAY4RyAAAAwDFCOQAAAOAYoRwAAABwjFAOAAAAOEYoBwAAABwjlAMAAACO/X+chxRTiq2cJgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot mean with error bars (standard deviation)\n",
    "ax.errorbar(\n",
    "    df_plot[\"features\"],\n",
    "    df_plot[\"mean\"],\n",
    "    yerr=df_plot[\"std\"],\n",
    "    fmt=\"o\",\n",
    "    capsize=5,\n",
    "    capthick=2,\n",
    "    label=\"Mean MAE with Std Dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_results = results_out[[\"features\", \"model_losses\", \"avg_baselines\", \"naive_baselines\", \"zero_baselines\"]]\n",
    "\n",
    "# split features by \"_\"\n",
    "pretty_results[\"features\"] = pretty_results[\"features\"].apply(lambda x: x.split(\"_\"))\n",
    "\n",
    "# do not cut off columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pretty_results.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretty_results.to_csv(\"pretty_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "list_of_dfs = []\n",
    "for run in runs_of_interest:\n",
    "    \n",
    "    splitted_run = run.split(\"\\n\")\n",
    "    # filter out empty strings\n",
    "    splitted_run = [elem for elem in splitted_run if elem != \"\"]\n",
    "\n",
    "    run_id = int(splitted_run[0].split(\" \")[2])\n",
    "    if (run_id < 13) or (run_id > 15):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    comb_lists = []\n",
    "    model_losses = []\n",
    "    zero_baselines = []\n",
    "    naive_baselines = []\n",
    "    avg_baselines = []\n",
    "    dataset_types = []\n",
    "    loss_types = []\n",
    "    \n",
    "    for elem in splitted_run[2:]:\n",
    "\n",
    "        by_bar = elem.split(\"|\")\n",
    "        \n",
    "        if len(by_bar) == 2:\n",
    "            dataset = by_bar[0].split(\":\")[1].strip()\n",
    "            loss_type = by_bar[1].split(\":\")[1].strip()\n",
    " \n",
    "        elif len(by_bar) == 1:\n",
    "            \n",
    "            if by_bar[0] == \"\":\n",
    "                continue\n",
    "            \n",
    "            array_type, array = by_bar[0].split(\":\")\n",
    "            array_type = array_type.strip()\n",
    "            \n",
    "            if array_type == \"Hyperparameters\":\n",
    "                continue\n",
    "            \n",
    "            array = array.strip()\n",
    "            array = np.array(ast.literal_eval(array))\n",
    "\n",
    "            \n",
    "            if array_type == \"Combinations\":\n",
    "                            \n",
    "                dataset_types.extend(np.repeat(dataset, len(array)))\n",
    "                loss_types.extend(np.repeat(loss_type, len(array)))\n",
    "                \n",
    "                comb_lists.extend(array)\n",
    "                \n",
    "            elif array_type == \"Model Losses\":\n",
    "                model_losses.extend(array)\n",
    "                \n",
    "            elif array_type == \"BL zero Losses\":\n",
    "                zero_baselines.extend(array)\n",
    "                \n",
    "            elif array_type == \"BL naive Losses\":\n",
    "                naive_baselines.extend(array)\n",
    "\n",
    "            elif array_type == \"BL avg Losses\":\n",
    "                avg_baselines.extend(array)\n",
    "\n",
    "            else:\n",
    "                print(array_type, array)\n",
    "                raise\n",
    "      \n",
    "    run_df = pd.DataFrame({\n",
    "        \"run_id\": run_id,\n",
    "        \"dataset\": dataset_types,\n",
    "        \"loss_type\": loss_types,\n",
    "        \"combinations\": comb_lists,\n",
    "        \"model_losses\": model_losses,\n",
    "        \"zero_baselines\": zero_baselines,\n",
    "        \"naive_baselines\": naive_baselines,\n",
    "        \"avg_baselines\": avg_baselines\n",
    "    })\n",
    "    \n",
    "    list_of_dfs.append(run_df)\n",
    "    \n",
    "results_df = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss type = MAE\n",
    "#results_filt = filter_dataframe_by_column_value(results_df, \"loss_type\", \"MAE\")\n",
    "## model class = ed_lstm\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"model_class\", \"ed_lstm\")\n",
    "## split_by = time\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"split_by\", \"time\")\n",
    "## frequency = 5min\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"frequency\", \"15min\")\n",
    "## lr = 0.001\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"lr\", \"0.001\")\n",
    "## batch_size = \"32\"\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"batch_size\", \"32\")\n",
    "## with_examweek = False\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"with_examweek\", \"False\")\n",
    "## course_encoding_dim = 3\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"course_encoding_dim\", \"3\")\n",
    "## room_id = 0\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"room_ids\", \"[0]\")\n",
    "\n",
    "\n",
    "## num_layers = 3\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"num_layers\", \"3\")\n",
    "\n",
    "## hidden_size = \"[32, 32]\"\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"hidden_size\", \"[32, 32]\")\n",
    "\n",
    "### x_horizon = 36\n",
    "#results_filt = filter_dataframe_by_column_value(results_filt, \"y_horizon\", \"36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-04-09 07:00:00\n",
    "start = datetime.datetime(2024, 4, 16, 7, 0, 0)\n",
    "# 2024-04-09 21:00:00\n",
    "stop = datetime.datetime(2024, 4, 16, 21, 0, 0)\n",
    "\n",
    "plot_data = dfg.filter_by_timestamp(data, \"datetime\", start, stop) \n",
    "\n",
    "plot_data[\"tl\"] = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\n",
    "plot_data[\"registered\"] = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\n",
    "\n",
    "plotter = DataPlotter(\n",
    "    save_path=\"\",\n",
    "    dataframe_guru=dfg\n",
    ")\n",
    "\n",
    "#plotter.plot_some_features(plot_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'avgocc', 'occrate', 'occcount', 'occcountdiff',\n",
       "       'occratediff', 'studyarea', 'registered', 'maxocccount', 'ects',\n",
       "       'maxoccrate', 'lecturerampbefore', 'lecture', 'type',\n",
       "       'maxoccrateestimate', 'lecturerampafter', 'coursenumber', 'cancelled',\n",
       "       'exam', 'test', 'offsite', 'tutorium', 'level', 'maxocccountestimate',\n",
       "       'VL', 'UE', 'KS', 'Informatik', 'None_sa', 'Volkswirtschaftslehre',\n",
       "       'Chemie', 'Wirtschaftsinformatik', 'Maschinenbau',\n",
       "       'Betriebswirtschaftslehre', 'Rechtswissenschaften', 'Mathematik',\n",
       "       'Mechatronik', 'Informationselektronik', 'Biologische Chemie',\n",
       "       'Sozialwissenschaften', 'Artificial Intelligence', 'Kunststofftechnik',\n",
       "       'Statistik', 'Pdagogik', 'Medical Engineering',\n",
       "       'B1 - Bachelor 1. Jahr', 'None_level', 'B2 - Bachelor 2. Jahr',\n",
       "       'M1 - Master 1. Jahr', 'B3 - Bachelor 3. Jahr', 'D - Diplom',\n",
       "       'M2 - Master 2. Jahr', 'hod1', 'hod2', 'dow1', 'dow2', 'week1', 'week2',\n",
       "       'holiday', 'zwickltag', 'occcount1week', 'occrate1day', 'occrate1week',\n",
       "       'occcount1day', 'occcountdiff1week', 'occcountdiff1day',\n",
       "       'occratediff1week', 'occratediff1day', 'tl', 'p', 'ff', 'ffx', 'rf',\n",
       "       'rr', 'so'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_features = {\"maxocccount\", \"maxoccrate\" ,\"maxoccrateestimate\", \"maxocccountestimate\",\n",
    "                \"coursenumber\", \"exam\",  \"test\", \"tutorium\", \"cancelled\",\"offsite\", \n",
    "                \"lecture\", \"lecturerampbefore\", \"lecturerampafter\",\n",
    "                \"registered\", \"type\", \"studyarea\", \"ects\", \"level\"}\n",
    "datetime_features = {\"dow\", \"hod\", \"week\", \"holiday\", \"zwickltag\"}\n",
    "general_features = {\"occcount\", \"occrate\", \"avgocc\"}\n",
    "weather_features = {\"weather\"}\n",
    "shift_features = {\"occcount1week\", \"occrate1week\", \"occcount1day\", \"occrate1day\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'avgocc', 'occrate', 'occcount', 'occcountdiff',\n",
       "       'occratediff', 'studyarea', 'registered', 'maxocccount', 'ects',\n",
       "       'maxoccrate', 'lecturerampbefore', 'lecture', 'type',\n",
       "       'maxoccrateestimate', 'lecturerampafter', 'coursenumber', 'cancelled',\n",
       "       'exam', 'test', 'offsite', 'tutorium', 'level', 'maxocccountestimate',\n",
       "       'VL', 'UE', 'KS', 'Informatik', 'None_sa', 'Volkswirtschaftslehre',\n",
       "       'Chemie', 'Wirtschaftsinformatik', 'Maschinenbau',\n",
       "       'Betriebswirtschaftslehre', 'Rechtswissenschaften', 'Mathematik',\n",
       "       'Mechatronik', 'Informationselektronik', 'Biologische Chemie',\n",
       "       'Sozialwissenschaften', 'Artificial Intelligence', 'Kunststofftechnik',\n",
       "       'Statistik', 'Pdagogik', 'Medical Engineering',\n",
       "       'B1 - Bachelor 1. Jahr', 'None_level', 'B2 - Bachelor 2. Jahr',\n",
       "       'M1 - Master 1. Jahr', 'B3 - Bachelor 3. Jahr', 'D - Diplom',\n",
       "       'M2 - Master 2. Jahr', 'hod1', 'hod2', 'dow1', 'dow2', 'week1', 'week2',\n",
       "       'holiday', 'zwickltag', 'occcount1week', 'occrate1day', 'occrate1week',\n",
       "       'occcount1day', 'occcountdiff1week', 'occcountdiff1day',\n",
       "       'occratediff1week', 'occratediff1day', 'tl', 'p', 'ff', 'ffx', 'rf',\n",
       "       'rr', 'so'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Columns\n",
    "\n",
    "Essential Features:\n",
    "* Occupancy information: number of occupancts absolute or relative (divided by room capacity)\n",
    "* Time stamp: Temporal resolution of t minutes\n",
    "\n",
    "Course Features:\n",
    "* Lecture: If a lecture takes place or not\n",
    "* Date Specific Features: Exam, Test, Tutorium, Cancelled\n",
    "* Course Specific Features: Registered students, Type (VL,UE,KS), Study area, Level, Course number\n",
    "\n",
    "Time-related Features:\n",
    "* Time, Weekday, (Calendarweek)\n",
    "* Holiday, Zwickltag\n",
    "\n",
    "Weather Features:\n",
    "* Temperature, Air pressure, Precipation (sum over time interval), Wind speed, Air humidity, Sunshine duration\n",
    "\n",
    "Additional Features:\n",
    "* Average occupancy information of last k weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'VL', 'UE', 'KS', \n",
    "\n",
    "Study area: Maybe try with learnable parameter\n",
    "'Informatik', 'None_sa',\n",
    "'Volkswirtschaftslehre', 'Chemie', 'Wirtschaftsinformatik',\n",
    "'Maschinenbau', 'Betriebswirtschaftslehre', 'Rechtswissenschaften',\n",
    "'Mathematik', 'Mechatronik', 'Informationselektronik',\n",
    "'Biologische Chemie', 'Sozialwissenschaften', 'Artificial Intelligence',\n",
    "'Kunststofftechnik', 'Statistik', 'Pdagogik', 'Medical Engineering',\n",
    "\n",
    "Level: Maybe try with learnable parameter\n",
    "'B1 - Bachelor 1. Jahr', 'None_level', 'B2 - Bachelor 2. Jahr',\n",
    "'M1 - Master 1. Jahr', 'B3 - Bachelor 3. Jahr', 'D - Diplom',\n",
    "'M2 - Master 2. Jahr', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lecture'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General Columns\n",
    "# datetime, occupancy information (occcount, occrate=occcount/room_capacity)\n",
    "# lecture ?\n",
    "\n",
    "\"lecture\"\n",
    "# Columns Concerning Specific Course Dates\n",
    "# [\"lecture\", \"exam\", \"test\", \"tutorium\", \"cancelled\"]\n",
    "# Course Specific Columns\n",
    "# [\"coursenumber\", \"type\", \"studyarea\", \"ects\", \"level\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Feature Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avgocc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add always\n",
    "[\"occrate\"]\n",
    "\n",
    "# add once \n",
    "[\"lecture\"]\n",
    "\n",
    "# lecture\n",
    "[\"lecture\"]\n",
    "\n",
    "# Columns Concerning Specific Course Dates\n",
    "[\"exam\", \"test\", \"tutorium\", \"cancelled\"]\n",
    "\n",
    "# Course Specific Features: Registered students, Type (VL,UE,KS), Study area, Level, Course number\n",
    "[\"registered\", \"type\", \"studyarea\", \"level\", \"coursenumber\"]\n",
    "\n",
    "# Time Related\n",
    "[\"dow\", \"hod\"]\n",
    "\n",
    "# Weather, in first phase add all weather variables\n",
    "[\"weather\"]\n",
    "\n",
    "# additional\n",
    "[\"avgocc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['occrate_avgocc_coursenumber', 'occrate_coursenumber',\n",
       "       'occrate_avgocc', 'occrate'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_features = [\"exam\"] +  [\"tutorium_test_cancelled\"] + [\"registered\", \"type\", \"studyarea\", \"coursenumber\"] + [\"dow\", \"hod\"]\n",
    "\n",
    "results_out.features.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avgocc',\n",
       " 'coursenumber',\n",
       " 'exam',\n",
       " 'weather',\n",
       " 'dow',\n",
       " 'hod',\n",
       " 'tutorium_test_cancelled',\n",
       " 'type',\n",
       " 'registered']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = [\"avgocc\", \"coursenumber\", \"exam\", \"weather\", \"dow\", \"hod\", \"tutorium_test_cancelled\", \"type\", \"registered\"]\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['occrate_avgocc',\n",
       " 'occrate_coursenumber',\n",
       " 'occrate_exam',\n",
       " 'occrate_weather',\n",
       " 'occrate_dow',\n",
       " 'occrate_hod',\n",
       " 'occrate_tutorium_test_cancelled',\n",
       " 'occrate_type',\n",
       " 'occrate_registered',\n",
       " 'occrate_avgocc_coursenumber',\n",
       " 'occrate_avgocc_exam',\n",
       " 'occrate_avgocc_weather',\n",
       " 'occrate_avgocc_dow',\n",
       " 'occrate_avgocc_hod',\n",
       " 'occrate_avgocc_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_type',\n",
       " 'occrate_avgocc_registered',\n",
       " 'occrate_coursenumber_exam',\n",
       " 'occrate_coursenumber_weather',\n",
       " 'occrate_coursenumber_dow',\n",
       " 'occrate_coursenumber_hod',\n",
       " 'occrate_coursenumber_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_type',\n",
       " 'occrate_coursenumber_registered',\n",
       " 'occrate_exam_weather',\n",
       " 'occrate_exam_dow',\n",
       " 'occrate_exam_hod',\n",
       " 'occrate_exam_tutorium_test_cancelled',\n",
       " 'occrate_exam_type',\n",
       " 'occrate_exam_registered',\n",
       " 'occrate_weather_dow',\n",
       " 'occrate_weather_hod',\n",
       " 'occrate_weather_tutorium_test_cancelled',\n",
       " 'occrate_weather_type',\n",
       " 'occrate_weather_registered',\n",
       " 'occrate_dow_hod',\n",
       " 'occrate_dow_tutorium_test_cancelled',\n",
       " 'occrate_dow_type',\n",
       " 'occrate_dow_registered',\n",
       " 'occrate_hod_tutorium_test_cancelled',\n",
       " 'occrate_hod_type',\n",
       " 'occrate_hod_registered',\n",
       " 'occrate_tutorium_test_cancelled_type',\n",
       " 'occrate_tutorium_test_cancelled_registered',\n",
       " 'occrate_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam',\n",
       " 'occrate_avgocc_coursenumber_weather',\n",
       " 'occrate_avgocc_coursenumber_dow',\n",
       " 'occrate_avgocc_coursenumber_hod',\n",
       " 'occrate_avgocc_coursenumber_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_type',\n",
       " 'occrate_avgocc_coursenumber_registered',\n",
       " 'occrate_avgocc_exam_weather',\n",
       " 'occrate_avgocc_exam_dow',\n",
       " 'occrate_avgocc_exam_hod',\n",
       " 'occrate_avgocc_exam_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_type',\n",
       " 'occrate_avgocc_exam_registered',\n",
       " 'occrate_avgocc_weather_dow',\n",
       " 'occrate_avgocc_weather_hod',\n",
       " 'occrate_avgocc_weather_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_weather_type',\n",
       " 'occrate_avgocc_weather_registered',\n",
       " 'occrate_avgocc_dow_hod',\n",
       " 'occrate_avgocc_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_dow_type',\n",
       " 'occrate_avgocc_dow_registered',\n",
       " 'occrate_avgocc_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_hod_type',\n",
       " 'occrate_avgocc_hod_registered',\n",
       " 'occrate_avgocc_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_type_registered',\n",
       " 'occrate_coursenumber_exam_weather',\n",
       " 'occrate_coursenumber_exam_dow',\n",
       " 'occrate_coursenumber_exam_hod',\n",
       " 'occrate_coursenumber_exam_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_type',\n",
       " 'occrate_coursenumber_exam_registered',\n",
       " 'occrate_coursenumber_weather_dow',\n",
       " 'occrate_coursenumber_weather_hod',\n",
       " 'occrate_coursenumber_weather_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_weather_type',\n",
       " 'occrate_coursenumber_weather_registered',\n",
       " 'occrate_coursenumber_dow_hod',\n",
       " 'occrate_coursenumber_dow_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_dow_type',\n",
       " 'occrate_coursenumber_dow_registered',\n",
       " 'occrate_coursenumber_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_hod_type',\n",
       " 'occrate_coursenumber_hod_registered',\n",
       " 'occrate_coursenumber_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_type_registered',\n",
       " 'occrate_exam_weather_dow',\n",
       " 'occrate_exam_weather_hod',\n",
       " 'occrate_exam_weather_tutorium_test_cancelled',\n",
       " 'occrate_exam_weather_type',\n",
       " 'occrate_exam_weather_registered',\n",
       " 'occrate_exam_dow_hod',\n",
       " 'occrate_exam_dow_tutorium_test_cancelled',\n",
       " 'occrate_exam_dow_type',\n",
       " 'occrate_exam_dow_registered',\n",
       " 'occrate_exam_hod_tutorium_test_cancelled',\n",
       " 'occrate_exam_hod_type',\n",
       " 'occrate_exam_hod_registered',\n",
       " 'occrate_exam_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_type_registered',\n",
       " 'occrate_weather_dow_hod',\n",
       " 'occrate_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_weather_dow_type',\n",
       " 'occrate_weather_dow_registered',\n",
       " 'occrate_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_weather_hod_type',\n",
       " 'occrate_weather_hod_registered',\n",
       " 'occrate_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_weather_type_registered',\n",
       " 'occrate_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_dow_hod_type',\n",
       " 'occrate_dow_hod_registered',\n",
       " 'occrate_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_dow_type_registered',\n",
       " 'occrate_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_hod_type_registered',\n",
       " 'occrate_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather',\n",
       " 'occrate_avgocc_coursenumber_exam_dow',\n",
       " 'occrate_avgocc_coursenumber_exam_hod',\n",
       " 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_type',\n",
       " 'occrate_avgocc_coursenumber_exam_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow',\n",
       " 'occrate_avgocc_coursenumber_weather_hod',\n",
       " 'occrate_avgocc_coursenumber_weather_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_weather_type',\n",
       " 'occrate_avgocc_coursenumber_weather_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_hod',\n",
       " 'occrate_avgocc_coursenumber_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_dow_type',\n",
       " 'occrate_avgocc_coursenumber_dow_registered',\n",
       " 'occrate_avgocc_coursenumber_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_hod_type',\n",
       " 'occrate_avgocc_coursenumber_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_type_registered',\n",
       " 'occrate_avgocc_exam_weather_dow',\n",
       " 'occrate_avgocc_exam_weather_hod',\n",
       " 'occrate_avgocc_exam_weather_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_weather_type',\n",
       " 'occrate_avgocc_exam_weather_registered',\n",
       " 'occrate_avgocc_exam_dow_hod',\n",
       " 'occrate_avgocc_exam_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_dow_type',\n",
       " 'occrate_avgocc_exam_dow_registered',\n",
       " 'occrate_avgocc_exam_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_hod_type',\n",
       " 'occrate_avgocc_exam_hod_registered',\n",
       " 'occrate_avgocc_exam_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_type_registered',\n",
       " 'occrate_avgocc_weather_dow_hod',\n",
       " 'occrate_avgocc_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_weather_dow_type',\n",
       " 'occrate_avgocc_weather_dow_registered',\n",
       " 'occrate_avgocc_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_weather_hod_type',\n",
       " 'occrate_avgocc_weather_hod_registered',\n",
       " 'occrate_avgocc_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_weather_type_registered',\n",
       " 'occrate_avgocc_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_dow_hod_type',\n",
       " 'occrate_avgocc_dow_hod_registered',\n",
       " 'occrate_avgocc_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_dow_type_registered',\n",
       " 'occrate_avgocc_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_hod_type_registered',\n",
       " 'occrate_avgocc_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow',\n",
       " 'occrate_coursenumber_exam_weather_hod',\n",
       " 'occrate_coursenumber_exam_weather_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_weather_type',\n",
       " 'occrate_coursenumber_exam_weather_registered',\n",
       " 'occrate_coursenumber_exam_dow_hod',\n",
       " 'occrate_coursenumber_exam_dow_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_dow_type',\n",
       " 'occrate_coursenumber_exam_dow_registered',\n",
       " 'occrate_coursenumber_exam_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_hod_type',\n",
       " 'occrate_coursenumber_exam_hod_registered',\n",
       " 'occrate_coursenumber_exam_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_type_registered',\n",
       " 'occrate_coursenumber_weather_dow_hod',\n",
       " 'occrate_coursenumber_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_weather_dow_type',\n",
       " 'occrate_coursenumber_weather_dow_registered',\n",
       " 'occrate_coursenumber_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_weather_hod_type',\n",
       " 'occrate_coursenumber_weather_hod_registered',\n",
       " 'occrate_coursenumber_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_weather_type_registered',\n",
       " 'occrate_coursenumber_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_dow_hod_type',\n",
       " 'occrate_coursenumber_dow_hod_registered',\n",
       " 'occrate_coursenumber_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_dow_type_registered',\n",
       " 'occrate_coursenumber_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_hod_type_registered',\n",
       " 'occrate_coursenumber_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_weather_dow_hod',\n",
       " 'occrate_exam_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_exam_weather_dow_type',\n",
       " 'occrate_exam_weather_dow_registered',\n",
       " 'occrate_exam_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_exam_weather_hod_type',\n",
       " 'occrate_exam_weather_hod_registered',\n",
       " 'occrate_exam_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_weather_type_registered',\n",
       " 'occrate_exam_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_exam_dow_hod_type',\n",
       " 'occrate_exam_dow_hod_registered',\n",
       " 'occrate_exam_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_dow_type_registered',\n",
       " 'occrate_exam_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_hod_type_registered',\n",
       " 'occrate_exam_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_weather_dow_hod_type',\n",
       " 'occrate_weather_dow_hod_registered',\n",
       " 'occrate_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_weather_dow_type_registered',\n",
       " 'occrate_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_weather_hod_type_registered',\n",
       " 'occrate_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_dow_hod_type_registered',\n",
       " 'occrate_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_type',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_type',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_type',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_type',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_type_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_type',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_type_registered',\n",
       " 'occrate_avgocc_coursenumber_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_hod',\n",
       " 'occrate_avgocc_exam_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_weather_dow_type',\n",
       " 'occrate_avgocc_exam_weather_dow_registered',\n",
       " 'occrate_avgocc_exam_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_weather_hod_type',\n",
       " 'occrate_avgocc_exam_weather_hod_registered',\n",
       " 'occrate_avgocc_exam_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_weather_type_registered',\n",
       " 'occrate_avgocc_exam_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_dow_hod_type',\n",
       " 'occrate_avgocc_exam_dow_hod_registered',\n",
       " 'occrate_avgocc_exam_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_dow_type_registered',\n",
       " 'occrate_avgocc_exam_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_hod_type_registered',\n",
       " 'occrate_avgocc_exam_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_weather_dow_hod_type',\n",
       " 'occrate_avgocc_weather_dow_hod_registered',\n",
       " 'occrate_avgocc_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_weather_dow_type_registered',\n",
       " 'occrate_avgocc_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_weather_hod_type_registered',\n",
       " 'occrate_avgocc_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_dow_hod_type_registered',\n",
       " 'occrate_avgocc_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod',\n",
       " 'occrate_coursenumber_exam_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_weather_dow_type',\n",
       " 'occrate_coursenumber_exam_weather_dow_registered',\n",
       " 'occrate_coursenumber_exam_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_weather_hod_type',\n",
       " 'occrate_coursenumber_exam_weather_hod_registered',\n",
       " 'occrate_coursenumber_exam_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_weather_type_registered',\n",
       " 'occrate_coursenumber_exam_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_dow_hod_type',\n",
       " 'occrate_coursenumber_exam_dow_hod_registered',\n",
       " 'occrate_coursenumber_exam_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_dow_type_registered',\n",
       " 'occrate_coursenumber_exam_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_hod_type_registered',\n",
       " 'occrate_coursenumber_exam_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_weather_dow_hod_type',\n",
       " 'occrate_coursenumber_weather_dow_hod_registered',\n",
       " 'occrate_coursenumber_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_weather_dow_type_registered',\n",
       " 'occrate_coursenumber_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_weather_hod_type_registered',\n",
       " 'occrate_coursenumber_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_dow_hod_type_registered',\n",
       " 'occrate_coursenumber_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_exam_weather_dow_hod_type',\n",
       " 'occrate_exam_weather_dow_hod_registered',\n",
       " 'occrate_exam_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_weather_dow_type_registered',\n",
       " 'occrate_exam_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_weather_hod_type_registered',\n",
       " 'occrate_exam_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_dow_hod_type_registered',\n",
       " 'occrate_exam_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_weather_dow_hod_type_registered',\n",
       " 'occrate_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_type',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_type',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_type',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_type_registered',\n",
       " 'occrate_avgocc_exam_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_weather_hod_type_registered',\n",
       " 'occrate_avgocc_exam_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_dow_hod_type_registered',\n",
       " 'occrate_avgocc_exam_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_weather_dow_hod_type_registered',\n",
       " 'occrate_avgocc_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_type',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_weather_hod_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_dow_hod_type_registered',\n",
       " 'occrate_coursenumber_exam_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_weather_dow_hod_type_registered',\n",
       " 'occrate_coursenumber_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_exam_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_exam_weather_dow_hod_type_registered',\n",
       " 'occrate_exam_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_type_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_exam_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled_type',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_exam_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate_avgocc_coursenumber_exam_weather_dow_hod_tutorium_test_cancelled_type_registered',\n",
       " 'occrate']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all 14*14 combinations of features\n",
    "import itertools\n",
    "all_combinations = []\n",
    "for i in range(1, len(all_features)+1):\n",
    "    \n",
    "    combs = [\"_\".join(list(x)) for x in itertools.combinations(all_features, i)]\n",
    "    all_combinations.extend(combs)\n",
    "\n",
    "# add occrate to all combinations\n",
    "all_combinations = [\"occrate_\" + comb for comb in all_combinations]\n",
    "all_combinations.append(\"occrate\")\n",
    "\n",
    "\n",
    "print(len(all_combinations))\n",
    "# save list as json file\n",
    "import json\n",
    "with open(\"all_combinations.json\", \"w\") as f:\n",
    "    json.dump(all_combinations, f)\n",
    "\n",
    "all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read out results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file with training results\n",
    "\n",
    "with open(\"results_wrapup_normal.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    line_str = \"\".join(lines)\n",
    "    \n",
    "    \n",
    "list_of_runs = line_str.split(\"\\n\\n\\n\")\n",
    "# remove empty strings\n",
    "list_of_runs = [run for run in list_of_runs if run != \"\"][:-1]\n",
    "list_of_runs\n",
    "\n",
    "runs_of_interest = list_of_runs[:]\n",
    "\n",
    "runs_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "list_of_dfs = []\n",
    "for run in runs_of_interest:\n",
    "    \n",
    "    splitted_run = run.split(\"\\n\")\n",
    "    # filter out empty strings\n",
    "    splitted_run = [elem for elem in splitted_run if elem != \"\"]\n",
    "\n",
    "    run_id = int(splitted_run[0].split(\" \")[2])\n",
    "    if (run_id < 0) or (run_id > 15):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    comb_lists = []\n",
    "    model_losses = []\n",
    "    zero_baselines = []\n",
    "    naive_baselines = []\n",
    "    avg_baselines = []\n",
    "    dataset_types = []\n",
    "    loss_types = []\n",
    "    \n",
    "    for elem in splitted_run[2:]:\n",
    "\n",
    "        by_bar = elem.split(\"|\")\n",
    "        \n",
    "        if len(by_bar) == 2:\n",
    "            dataset = by_bar[0].split(\":\")[1].strip()\n",
    "            loss_type = by_bar[1].split(\":\")[1].strip()\n",
    "\n",
    "            \n",
    "        elif len(by_bar) == 1:\n",
    "            \n",
    "            if by_bar[0] == \"\":\n",
    "                continue\n",
    "            \n",
    "            array_type, array = by_bar[0].split(\":\")\n",
    "            array_type = array_type.strip()\n",
    "            \n",
    "            if array_type == \"Hyperparameters\":\n",
    "                continue\n",
    "            \n",
    "            array = array.strip()\n",
    "            array = np.array(ast.literal_eval(array))\n",
    "\n",
    "            \n",
    "            if array_type == \"Combinations\":\n",
    "                            \n",
    "                dataset_types.extend(np.repeat(dataset, len(array)))\n",
    "                loss_types.extend(np.repeat(loss_type, len(array)))\n",
    "                \n",
    "                comb_lists.extend(array)\n",
    "                \n",
    "            elif array_type == \"Model Losses\":\n",
    "                model_losses.extend(array)\n",
    "                \n",
    "            elif array_type == \"BL zero Losses\":\n",
    "                zero_baselines.extend(array)\n",
    "                \n",
    "            elif array_type == \"BL naive Losses\":\n",
    "                naive_baselines.extend(array)\n",
    "\n",
    "            elif array_type == \"BL avg Losses\":\n",
    "                avg_baselines.extend(array)\n",
    "\n",
    "            else:\n",
    "                print(array_type, array)\n",
    "                raise\n",
    "      \n",
    "    run_df = pd.DataFrame({\n",
    "        \"run_id\": run_id,\n",
    "        \"dataset\": dataset_types,\n",
    "        \"loss_type\": loss_types,\n",
    "        \"combinations\": comb_lists,\n",
    "        \"model_losses\": model_losses,\n",
    "        \"zero_baselines\": zero_baselines,\n",
    "        \"naive_baselines\": naive_baselines,\n",
    "        \"avg_baselines\": avg_baselines\n",
    "    })\n",
    "    \n",
    "    list_of_dfs.append(run_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(list_of_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate through all combinations and load hyperparameters\n",
    "import json\n",
    "path_to_checkpoints = \"_occupancy_forecasting/checkpoints/wrap_up\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    comb = row[\"combinations\"]\n",
    "    \n",
    "    comb_path = os.path.join(path_to_checkpoints, f\"run_{comb[0]}/comb_{comb[1]}\")\n",
    "    \n",
    "    hyperparameters_path = os.path.join(comb_path, \"hyperparameters.json\")\n",
    "\n",
    "    \n",
    "    hyperparameters = json.load(open(hyperparameters_path, \"r\"))\n",
    "    \n",
    "    # overwrite combinations with tuple of run_id and comb_id\n",
    "    results_df.at[idx, \"combinations\"] = (row[\"run_id\"], comb[1])\n",
    "    \n",
    "    # add all hyperparameters to the dataframe\n",
    "    for key, value in hyperparameters.items():\n",
    "        results_df.at[idx, key] = str(value)\n",
    "\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>combinations</th>\n",
       "      <th>model_losses</th>\n",
       "      <th>zero_baselines</th>\n",
       "      <th>naive_baselines</th>\n",
       "      <th>avg_baselines</th>\n",
       "      <th>info</th>\n",
       "      <th>model_class</th>\n",
       "      <th>split_by</th>\n",
       "      <th>room_ids</th>\n",
       "      <th>with_examweek</th>\n",
       "      <th>prelayer</th>\n",
       "      <th>dataset_mode</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>additive_noise</th>\n",
       "      <th>course_encoding_dim</th>\n",
       "      <th>dropout</th>\n",
       "      <th>x_horizon</th>\n",
       "      <th>y_horizon</th>\n",
       "      <th>features</th>\n",
       "      <th>frequency</th>\n",
       "      <th>max_n_updates</th>\n",
       "      <th>----------------------------</th>\n",
       "      <th>permissible_features</th>\n",
       "      <th>optimizer_class</th>\n",
       "      <th>differencing</th>\n",
       "      <th>criterion</th>\n",
       "      <th>layer_norm</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>forget_gate</th>\n",
       "      <th>include_x_features</th>\n",
       "      <th>zero_sample_drop_rate</th>\n",
       "      <th>x_size</th>\n",
       "      <th>y_features_size</th>\n",
       "      <th>y_size</th>\n",
       "      <th>occcount</th>\n",
       "      <th>feature_store</th>\n",
       "      <th>more_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 5)</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber</td>\n",
       "      <td>5min</td>\n",
       "      <td>100000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 6)</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_hod</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 7)</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_dow_hod_exam_test_tutorium_registered</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 5)</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_dow</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 2)</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_coursenumber_type_studyarea_level_registered</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 7)</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week</td>\n",
       "      <td>5min</td>\n",
       "      <td>100000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(10, 3)</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 9: weather</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_weather</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 0)</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_type_studyarea_level</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 1)</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_coursenumber_type_studyarea_level</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 3)</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_type_studyarea_level_registered</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(11, 4)</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 11: more feature combinations</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 2)</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_exam_tutorium_test_cancelled</td>\n",
       "      <td>5min</td>\n",
       "      <td>50000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(9, 0)</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 8: ed lstm - longer forecasting horizon</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate</td>\n",
       "      <td>5min</td>\n",
       "      <td>50000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>MAE</td>\n",
       "      <td>(10, 0)</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>Run 9: weather</td>\n",
       "      <td>ed_lstm</td>\n",
       "      <td>time</td>\n",
       "      <td>[0]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>occrate_avgocc_coursenumber_tl</td>\n",
       "      <td>5min</td>\n",
       "      <td>25000</td>\n",
       "      <td>--------------------------- [128, 32]</td>\n",
       "      <td>['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']</td>\n",
       "      <td>Adam</td>\n",
       "      <td>none</td>\n",
       "      <td>MAE</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id dataset loss_type combinations  model_losses  zero_baselines  \\\n",
       "0        9    test       MAE       (9, 5)      0.008764        0.017787   \n",
       "15      11    test       MAE      (11, 6)      0.009253        0.017787   \n",
       "16      11    test       MAE      (11, 7)      0.009334        0.017787   \n",
       "17      11    test       MAE      (11, 5)      0.009434        0.017787   \n",
       "18      11    test       MAE      (11, 2)      0.009765        0.017787   \n",
       "1        9    test       MAE       (9, 7)      0.009796        0.017787   \n",
       "8       10    test       MAE      (10, 3)      0.009796        0.017787   \n",
       "19      11    test       MAE      (11, 0)      0.010129        0.017787   \n",
       "13      11    test       MAE      (11, 1)      0.010192        0.017787   \n",
       "21      11    test       MAE      (11, 3)      0.010507        0.017787   \n",
       "22      11    test       MAE      (11, 4)      0.010559        0.017787   \n",
       "3        9    test       MAE       (9, 2)      0.010636        0.017787   \n",
       "5        9    test       MAE       (9, 0)      0.013729        0.017787   \n",
       "9       10    test       MAE      (10, 0)      0.014079        0.017787   \n",
       "\n",
       "    naive_baselines  avg_baselines  \\\n",
       "0          0.016627       0.011299   \n",
       "15         0.016627       0.011299   \n",
       "16         0.016627       0.011299   \n",
       "17         0.016627       0.011299   \n",
       "18         0.016627       0.011299   \n",
       "1          0.016627       0.011299   \n",
       "8          0.016627       0.011299   \n",
       "19         0.016627       0.011299   \n",
       "13         0.016627       0.011299   \n",
       "21         0.016627       0.011299   \n",
       "22         0.016627       0.011299   \n",
       "3          0.016627       0.011299   \n",
       "5          0.016627       0.011299   \n",
       "9          0.016627       0.011299   \n",
       "\n",
       "                                           info model_class split_by room_ids  \\\n",
       "0   Run 8: ed lstm - longer forecasting horizon     ed_lstm     time      [0]   \n",
       "15            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "16            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "17            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "18            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "1   Run 8: ed lstm - longer forecasting horizon     ed_lstm     time      [0]   \n",
       "8                                Run 9: weather     ed_lstm     time      [0]   \n",
       "19            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "13            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "21            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "22            Run 11: more feature combinations     ed_lstm     time      [0]   \n",
       "3   Run 8: ed lstm - longer forecasting horizon     ed_lstm     time      [0]   \n",
       "5   Run 8: ed lstm - longer forecasting horizon     ed_lstm     time      [0]   \n",
       "9                                Run 9: weather     ed_lstm     time      [0]   \n",
       "\n",
       "   with_examweek prelayer dataset_mode     lr batch_size hidden_size  \\\n",
       "0          False     True       normal  0.001         32    [32, 32]   \n",
       "15         False     True       normal  0.001         32    [32, 32]   \n",
       "16         False     True       normal  0.001         32    [32, 32]   \n",
       "17         False     True       normal  0.001         32    [32, 32]   \n",
       "18         False     True       normal  0.001         32    [32, 32]   \n",
       "1          False     True       normal  0.001         32    [32, 32]   \n",
       "8          False     True       normal  0.001         32    [32, 32]   \n",
       "19         False     True       normal  0.001         32    [32, 32]   \n",
       "13         False     True       normal  0.001         32    [32, 32]   \n",
       "21         False     True       normal  0.001         32    [32, 32]   \n",
       "22         False     True       normal  0.001         32    [32, 32]   \n",
       "3          False     True       normal  0.001         32    [32, 32]   \n",
       "5          False     True       normal  0.001         32    [32, 32]   \n",
       "9          False     True       normal  0.001         32    [32, 32]   \n",
       "\n",
       "   num_layers bidirectional additive_noise course_encoding_dim dropout  \\\n",
       "0           3          True              0                   3       0   \n",
       "15          3          True              0                   3       0   \n",
       "16          3          True              0                   3       0   \n",
       "17          3          True              0                   3       0   \n",
       "18          3          True              0                   3       0   \n",
       "1           3          True              0                   3       0   \n",
       "8           3          True              0                   3       0   \n",
       "19          3          True              0                   3       0   \n",
       "13          3          True              0                   3       0   \n",
       "21          3          True              0                   3       0   \n",
       "22          3          True              0                   3       0   \n",
       "3           3          True              0                   3       0   \n",
       "5           3          True              0                   3       0   \n",
       "9           3          True              0                   3       0   \n",
       "\n",
       "   x_horizon y_horizon  \\\n",
       "0         36        36   \n",
       "15        36        36   \n",
       "16        36        36   \n",
       "17        36        36   \n",
       "18        36        36   \n",
       "1         36        36   \n",
       "8         36        36   \n",
       "19        36        36   \n",
       "13        36        36   \n",
       "21        36        36   \n",
       "22        36        36   \n",
       "3         36        36   \n",
       "5         36        36   \n",
       "9         36        36   \n",
       "\n",
       "                                                                 features  \\\n",
       "0                                             occrate_avgocc_coursenumber   \n",
       "15                                        occrate_avgocc_coursenumber_hod   \n",
       "16      occrate_avgocc_coursenumber_dow_hod_exam_test_tutorium_registered   \n",
       "17                                        occrate_avgocc_coursenumber_dow   \n",
       "18                   occrate_coursenumber_type_studyarea_level_registered   \n",
       "1   occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week   \n",
       "8                                     occrate_avgocc_coursenumber_weather   \n",
       "19                       occrate_avgocc_coursenumber_type_studyarea_level   \n",
       "13                              occrate_coursenumber_type_studyarea_level   \n",
       "21            occrate_avgocc_coursenumber_type_studyarea_level_registered   \n",
       "22    occrate_avgocc_coursenumber_type_studyarea_level_exam_test_tutorium   \n",
       "3                occrate_avgocc_coursenumber_exam_tutorium_test_cancelled   \n",
       "5                                                                 occrate   \n",
       "9                                          occrate_avgocc_coursenumber_tl   \n",
       "\n",
       "   frequency max_n_updates           ----------------------------  \\\n",
       "0       5min        100000  --------------------------- [128, 32]   \n",
       "15      5min         25000  --------------------------- [128, 32]   \n",
       "16      5min         25000  --------------------------- [128, 32]   \n",
       "17      5min         25000  --------------------------- [128, 32]   \n",
       "18      5min         25000  --------------------------- [128, 32]   \n",
       "1       5min        100000  --------------------------- [128, 32]   \n",
       "8       5min         25000  --------------------------- [128, 32]   \n",
       "19      5min         25000  --------------------------- [128, 32]   \n",
       "13      5min         25000  --------------------------- [128, 32]   \n",
       "21      5min         25000  --------------------------- [128, 32]   \n",
       "22      5min         25000  --------------------------- [128, 32]   \n",
       "3       5min         50000  --------------------------- [128, 32]   \n",
       "5       5min         50000  --------------------------- [128, 32]   \n",
       "9       5min         25000  --------------------------- [128, 32]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         permissible_features  \\\n",
       "0                                                                                                                      ['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "15  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "16  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "17  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "18  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "1                                                                                                                      ['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "8   ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "19  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "13  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "21  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "22  ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "3                                                                                                                      ['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "5                                                                                                                      ['occcount', 'occrate', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "9   ['occcount', 'occrate', 'occrate_avgocc_coursenumber_exam_tutorium_test_cancelled_dow_hod_week', 'lecture', 'lecturerampbefore', 'lecturerampafter', 'exam', 'test', 'tutorium', 'cancelled', 'offsite', 'coursenumber', 'registered', 'type', 'studyarea', 'ects', 'level', 'dow', 'hod', 'week', 'holiday', 'zwickltag', 'weather', 'so', 'rr', 'rf', 'ffx', 'p', 'ff', 'tl', 'occcount1week', 'occrate1week', 'occcount1day', 'occrate1day', 'maxocccount', 'maxoccrate', 'maxoccrateestimate', 'maxocccountestimate']   \n",
       "\n",
       "   optimizer_class differencing criterion layer_norm weight_decay forget_gate  \\\n",
       "0             Adam         none       MAE      False            0        True   \n",
       "15            Adam         none       MAE      False            0        True   \n",
       "16            Adam         none       MAE      False            0        True   \n",
       "17            Adam         none       MAE      False            0        True   \n",
       "18            Adam         none       MAE      False            0        True   \n",
       "1             Adam         none       MAE      False            0        True   \n",
       "8             Adam         none       MAE      False            0        True   \n",
       "19            Adam         none       MAE      False            0        True   \n",
       "13            Adam         none       MAE      False            0        True   \n",
       "21            Adam         none       MAE      False            0        True   \n",
       "22            Adam         none       MAE      False            0        True   \n",
       "3             Adam         none       MAE      False            0        True   \n",
       "5             Adam         none       MAE      False            0        True   \n",
       "9             Adam         none       MAE      False            0        True   \n",
       "\n",
       "   include_x_features zero_sample_drop_rate x_size y_features_size y_size  \\\n",
       "0                True                   0.1      2               1      1   \n",
       "15               True                   0.1      4               3      1   \n",
       "16               True                   0.1     10               9      1   \n",
       "17               True                   0.1      4               3      1   \n",
       "18               True                   0.1     30              29      1   \n",
       "1                True                   0.1     12              11      1   \n",
       "8                True                   0.1      9               8      1   \n",
       "19               True                   0.1     30              29      1   \n",
       "13               True                   0.1     29              28      1   \n",
       "21               True                   0.1     31              30      1   \n",
       "22               True                   0.1     33              32      1   \n",
       "3                True                   0.1      6               5      1   \n",
       "5                True                   0.1      1               0      1   \n",
       "9                True                   0.1      3               2      1   \n",
       "\n",
       "   occcount  \\\n",
       "0     False   \n",
       "15    False   \n",
       "16    False   \n",
       "17    False   \n",
       "18    False   \n",
       "1     False   \n",
       "8     False   \n",
       "19    False   \n",
       "13    False   \n",
       "21    False   \n",
       "22    False   \n",
       "3     False   \n",
       "5     False   \n",
       "9     False   \n",
       "\n",
       "                                                                               feature_store  \\\n",
       "0   occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "15  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "16  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "17  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "18  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "1   occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "8   occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "19  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "13  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "21  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "22  occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "3   occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "5   occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "9   occrate_coursenumber_exam_test_tutorium_cancelled_offsite_hod_dow_week_holiday_zwickltag   \n",
       "\n",
       "   more_embeddings  \n",
       "0              NaN  \n",
       "15           False  \n",
       "16           False  \n",
       "17           False  \n",
       "18           False  \n",
       "1              NaN  \n",
       "8              NaN  \n",
       "19           False  \n",
       "13           False  \n",
       "21           False  \n",
       "22           False  \n",
       "3              NaN  \n",
       "5              NaN  \n",
       "9              NaN  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through all combinations and load hyperparameters\n",
    "import json\n",
    "path_to_checkpoints = \"_occupancy_forecasting/checkpoints/wrap_up\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    comb = row[\"combinations\"]\n",
    "    \n",
    "    comb_path = os.path.join(path_to_checkpoints, f\"run_{comb[0]}/comb_{comb[1]}\")\n",
    "    \n",
    "    hyperparameters_path = os.path.join(comb_path, \"hyperparameters.json\")\n",
    "\n",
    "    \n",
    "    hyperparameters = json.load(open(hyperparameters_path, \"r\"))\n",
    "    \n",
    "    # overwrite combinations with tuple of run_id and comb_id\n",
    "    results_df.at[idx, \"combinations\"] = (row[\"run_id\"], comb[1])\n",
    "    \n",
    "    # add all hyperparameters to the dataframe\n",
    "    for key, value in hyperparameters.items():\n",
    "        results_df.at[idx, key] = str(value)\n",
    "\n",
    "print(len(results_df))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_dataframe_by_column_value(df, column, value):\n",
    "    return df[df[column] == value].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# loss type = MAE\n",
    "results_filt = filter_dataframe_by_column_value(results_df, \"loss_type\", \"MAE\")\n",
    "# model class = ed_lstm\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"model_class\", \"ed_lstm\")\n",
    "# split_by = time\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"split_by\", \"time\")\n",
    "# frequency = 5min\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"frequency\", \"5min\")\n",
    "# lr = 0.001\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"lr\", \"0.001\")\n",
    "# batch_size = \"32\"\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"batch_size\", \"32\")\n",
    "# with_examweek = False\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"with_examweek\", \"False\")\n",
    "# course_encoding_dim = 3\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"course_encoding_dim\", \"3\")\n",
    "# room_id = 0\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"room_ids\", \"[0]\")\n",
    "\n",
    "\n",
    "# num_layers = 3\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"num_layers\", \"3\")\n",
    "\n",
    "# hidden_size = \"[32, 32]\"\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"hidden_size\", \"[32, 32]\")\n",
    "\n",
    "## x_horizon = 36\n",
    "results_filt = filter_dataframe_by_column_value(results_filt, \"y_horizon\", \"36\")\n",
    "\n",
    "# finalize filtering\n",
    "results_out = filter_dataframe_by_column_value(results_filt, \"dataset\", \"test\")\n",
    "results_out = results_out.sort_values(by=\"model_losses\")\n",
    "\n",
    "results_out.drop_duplicates(subset=[\"features\"], keep=\"first\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pretty_results = results_out[[\"features\", \"model_losses\", \"avg_baselines\", \"naive_baselines\", \"zero_baselines\"]]\n",
    "\n",
    "# split features by \"_\"\n",
    "pretty_results[\"features\"] = pretty_results[\"features\"].apply(lambda x: x.split(\"_\"))\n",
    "\n",
    "# do not cut off columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pretty_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pretty_results.to_csv(\"pretty_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 2024-04-09 07:00:00\\nstart = datetime.datetime(2024, 4, 9, 7, 0, 0)\\n# 2024-04-09 21:00:00\\nstop = datetime.datetime(2024, 4, 9, 21, 0, 0)\\n\\nplot_data = dfg.filter_by_timestamp(data, \"datetime\", start, stop) \\n\\n# 3 subplots in 3 rows\\nfig, axs = plt.subplots(3, 1, figsize=(15, 10))\\n# plot occrate\\naxs[0].plot(plot_data[\"datetime\"], plot_data[\"occrate\"], label=\"ocrate\")\\n# plot registered\\nregistered = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\\naxs[1].plot(plot_data[\"datetime\"], registered, label=\"registered\")\\n# temperature\\ntemperature = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\\naxs[2].plot(plot_data[\"datetime\"], temperature, label=\"temperature\")\\nplt.show()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# 2024-04-09 07:00:00\n",
    "start = datetime.datetime(2024, 4, 9, 7, 0, 0)\n",
    "# 2024-04-09 21:00:00\n",
    "stop = datetime.datetime(2024, 4, 9, 21, 0, 0)\n",
    "\n",
    "plot_data = dfg.filter_by_timestamp(data, \"datetime\", start, stop) \n",
    "\n",
    "# 3 subplots in 3 rows\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10))\n",
    "# plot occrate\n",
    "axs[0].plot(plot_data[\"datetime\"], plot_data[\"occrate\"], label=\"ocrate\")\n",
    "# plot registered\n",
    "registered = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\n",
    "axs[1].plot(plot_data[\"datetime\"], registered, label=\"registered\")\n",
    "# temperature\n",
    "temperature = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\n",
    "axs[2].plot(plot_data[\"datetime\"], temperature, label=\"temperature\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig = make_subplots(\n",
    "#    rows=3, \n",
    "#    cols=1, \n",
    "#    subplot_titles=(\"Occupancy Rate\", \"Registered Students\", \"Temperature in Linz\")\n",
    "#    )\n",
    "#x_col = \"datetime\"\n",
    "\n",
    "## occupancy rate\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=plot_data[x_col], \n",
    "#        y=plot_data[\"occrate\"],\n",
    "#        mode='lines', \n",
    "#        name='Occupancy Rate'\n",
    "#        ),\n",
    "#    row=1, col=1\n",
    "#    )\n",
    "## registered students\n",
    "#registered = (plot_data[\"registered\"] - norm_registered[\"min\"]) / (norm_registered[\"max\"] - norm_registered[\"min\"])\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=plot_data[x_col], \n",
    "#        y=registered,\n",
    "#        mode='lines', \n",
    "#        name='Registered Students'\n",
    "#        ),\n",
    "#    row=2, col=1\n",
    "#    )\n",
    "\n",
    "## temperature\n",
    "#temperature = (plot_data[\"tl\"] - norm_temperature[\"min\"]) / (norm_temperature[\"max\"] - norm_temperature[\"min\"])\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=plot_data[x_col], \n",
    "#        y=temperature,\n",
    "#        mode='lines', \n",
    "#        name='Temperature in Linz'\n",
    "#        ),\n",
    "#    row=3, col=1\n",
    "#    )\n",
    "\n",
    "## set y axis between 0 and 1\n",
    "#fig.update_yaxes(range=[-0.1, 1], row=1, col=1)\n",
    "#fig.update_yaxes(range=[-0.1, 1], row=2, col=1)\n",
    "#fig.update_yaxes(range=[-0.1, 1], row=3, col=1)\n",
    "#fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
