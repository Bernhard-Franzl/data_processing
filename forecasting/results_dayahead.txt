################# Run: 0 #################
Time: 2024-11-13 12:48:50
Dataset: train | Loss: MAE
Combinations: [[0, 5], [0, 18], [0, 8], [0, 15], [0, 2], [0, 17], [0, 19], [0, 1], [0, 16], [0, 4], [0, 13], [0, 3], [0, 6], [0, 12], [0, 11], [0, 9], [0, 0], [0, 10], [0, 7], [0, 14]]
Model Losses: [0.001453, 0.001845, 0.002742, 0.003071, 0.003321, 0.003806, 0.004867, 0.005609, 0.006042, 0.006314, 0.00637 , 0.006479, 0.00659 , 0.006635, 0.006841, 0.006858, 0.007457, 0.007528, 0.007981, 0.008628]
BL zero Losses: [0.024914, 0.024914, 0.024914, 0.024914, 0.024575, 0.024575, 0.024575, 0.024575, 0.024882, 0.024882, 0.024831, 0.024831, 0.025728, 0.025728, 0.026157, 0.026157, 0.024914, 0.024575, 0.024831, 0.026111]
BL naive Losses: [0.022541, 0.022541, 0.022541, 0.022541, 0.022394, 0.022394, 0.022394, 0.022394, 0.022512, 0.022512, 0.022492, 0.022492, 0.022145, 0.022145, 0.022514, 0.022514, 0.022541, 0.022394, 0.022492, 0.022474]
BL avg Losses: [0.021261, 0.021261, 0.021261, 0.021261, 0.021423, 0.021423, 0.021423, 0.021423, 0.021305, 0.021305, 0.021304, 0.021304, 0.020673, 0.020673, 0.021018, 0.021018, 0.021261, 0.021423, 0.021304, 0.021113]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('random-train-val'), np.int64(3)), (np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2)), (np.str_('True'), np.int64(3))]), ('x_horizon', [(np.str_('144'), np.int64(1)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(1))])]

Dataset: train | Loss: R2
Combinations: [[0, 5], [0, 8], [0, 15], [0, 2], [0, 18], [0, 6], [0, 14], [0, 10], [0, 3], [0, 12], [0, 4], [0, 17], [0, 13], [0, 11], [0, 1], [0, 19], [0, 9], [0, 16], [0, 7], [0, 0]]
Model Losses: [0.954686, 0.94537 , 0.938033, 0.931506, 0.922131, 0.853465, 0.819836, 0.819642, 0.780494, 0.773763, 0.764359, 0.748141, 0.680236, 0.674386, 0.660479, 0.60736 , 0.589236, 0.525478, 0.468434, 0.117151]
BL zero Losses: [0.165125, 0.165125, 0.165125, 0.165125, 0.175458, 0.175458, 0.175458, 0.175458, 0.157326, 0.157326, 0.160901, 0.160901, 0.144826, 0.144826, 0.130573, 0.130573, 0.165125, 0.175458, 0.160901, 0.133681]
BL naive Losses: [0.140251, 0.140251, 0.140251, 0.140251, 0.125659, 0.125659, 0.125659, 0.125659, 0.143909, 0.143909, 0.143109, 0.143109, 0.147092, 0.147092, 0.132877, 0.132877, 0.140251, 0.125659, 0.143109, 0.133208]
BL avg Losses: [-2.748371, -2.748371, -2.748371, -2.748371, -2.972162, -2.972162, -2.972162, -2.972162, -0.03227 , -0.03227 , -0.036061, -0.036061, -0.047412, -0.047412, -0.064869, -0.064869, -2.748371, -2.972162, -0.036061, -0.073204]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('random-train-val'), np.int64(3)), (np.str_('time'), np.int64(2))]), ('with_examweek', [(np.str_('False'), np.int64(2)), (np.str_('True'), np.int64(3))]), ('x_horizon', [(np.str_('144'), np.int64(1)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(1))])]

Dataset: val | Loss: MAE
Combinations: [[0, 15], [0, 14], [0, 12], [0, 13], [0, 19], [0, 9], [0, 18], [0, 10], [0, 11], [0, 8], [0, 7], [0, 5], [0, 4], [0, 17], [0, 6], [0, 2], [0, 16], [0, 3], [0, 1], [0, 0]]
Model Losses: [0.003067, 0.003669, 0.003947, 0.004024, 0.004557, 0.006844, 0.007788, 0.007886, 0.008031, 0.008305, 0.008997, 0.009272, 0.010325, 0.01035 , 0.010708, 0.011423, 0.011522, 0.01233 , 0.012544, 0.01333 ]
BL zero Losses: [0.021693, 0.021693, 0.021693, 0.021693, 0.020007, 0.020007, 0.020007, 0.020007, 0.016677, 0.016677, 0.017788, 0.017788, 0.009231, 0.009231, 0.009941, 0.009941, 0.020211, 0.022866, 0.018178, 0.009941]
BL naive Losses: [0.016682, 0.016682, 0.016682, 0.016682, 0.015138, 0.015138, 0.015138, 0.015138, 0.010935, 0.010935, 0.011664, 0.011664, 0.015536, 0.015536, 0.014429, 0.014429, 0.016962, 0.0173  , 0.010958, 0.014429]
BL avg Losses: [0.013028, 0.013028, 0.013028, 0.013028, 0.013463, 0.013463, 0.013463, 0.013463, 0.008252, 0.008252, 0.008222, 0.008222, 0.01894 , 0.01894 , 0.016839, 0.016839, 0.012244, 0.015387, 0.007791, 0.016839]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('random-train-val'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('144'), np.int64(1)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(1))])]

Dataset: val | Loss: R2
Combinations: [[0, 15], [0, 13], [0, 14], [0, 12], [0, 5], [0, 17], [0, 4], [0, 10], [0, 6], [0, 18], [0, 11], [0, 3], [0, 7], [0, 8], [0, 2], [0, 9], [0, 1], [0, 0], [0, 19], [0, 16]]
Model Losses: [0.953251, 0.860773, 0.858789, 0.85021 , 0.84681 , 0.794218, 0.789702, 0.759555, 0.743233, 0.734303, 0.630952, 0.603873, 0.602206, 0.56991 , 0.568978, 0.506385, 0.489536, 0.471407, 0.391672, 0.35996 ]
BL zero Losses: [0.026971, 0.026971, 0.026971, 0.026971, 0.211707, 0.211707, 0.211707, 0.211707, 0.197776, 0.197776, 0.144295, 0.144295, 0.556946, 0.556946, 0.522865, 0.522865, 0.066053, 0.099094, 0.163049, 0.522865]
BL naive Losses: [0.203455, 0.203455, 0.203455, 0.203455, 0.535873, 0.535873, 0.535873, 0.535873, 0.428694, 0.428694, 0.390607, 0.390607, 0.474835, 0.474835, 0.511361, 0.511361, 0.129573, 0.469569, 0.514298, 0.511361]
BL avg Losses: [  0.628557,   0.628557,   0.628557,   0.628557,   0.661205,   0.661205,   0.661205,   0.661205,   0.746294,   0.746294,   0.796047,   0.796047, -36.67634 , -36.67634 , -39.497597, -39.497597,   0.623619,   0.612805,   0.816497, -39.497597]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('random-train-val'), np.int64(4)), (np.str_('time'), np.int64(1))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(3)), (np.str_('72'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2)), (np.str_('36'), np.int64(3))])]

Dataset: test | Loss: MAE
Combinations: [[0, 17], [0, 4], [0, 7], [0, 6], [0, 5], [0, 13], [0, 19], [0, 15], [0, 12], [0, 14], [0, 8], [0, 1], [0, 11], [0, 3], [0, 10], [0, 9], [0, 0], [0, 2], [0, 16], [0, 18]]
Model Losses: [0.008599, 0.00931 , 0.009731, 0.009933, 0.010442, 0.010968, 0.012186, 0.013027, 0.013332, 0.014089, 0.01844 , 0.01879 , 0.01885 , 0.019012, 0.020053, 0.020073, 0.0213  , 0.021567, 0.022384, 0.023422]
BL zero Losses: [0.02424 , 0.02424 , 0.02424 , 0.02424 , 0.016723, 0.016723, 0.016723, 0.016723, 0.02424 , 0.02424 , 0.02424 , 0.02424 , 0.016723, 0.016723, 0.016723, 0.016723, 0.0277  , 0.016723, 0.0277  , 0.016723]
BL naive Losses: [0.021012, 0.021012, 0.021012, 0.021012, 0.016583, 0.016583, 0.016583, 0.016583, 0.021012, 0.021012, 0.021012, 0.021012, 0.016583, 0.016583, 0.016583, 0.016583, 0.022054, 0.016583, 0.022054, 0.016583]
BL avg Losses: [0.021348, 0.021348, 0.021348, 0.021348, 0.011044, 0.011044, 0.011044, 0.011044, 0.021348, 0.021348, 0.021348, 0.021348, 0.011044, 0.011044, 0.011044, 0.011044, 0.023145, 0.011044, 0.023145, 0.011044]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('144'), np.int64(1)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(2))]), ('y_horizon', [(np.str_('12'), np.int64(2)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(1))])]

Dataset: test | Loss: R2
Combinations: [[0, 17], [0, 4], [0, 6], [0, 8], [0, 18], [0, 10], [0, 3], [0, 14], [0, 5], [0, 2], [0, 12], [0, 0], [0, 1], [0, 7], [0, 15], [0, 13], [0, 11], [0, 16], [0, 9], [0, 19]]
Model Losses: [0.617747, 0.606232, 0.561641, 0.484871, 0.441975, 0.440155, 0.435968, 0.40678 , 0.392018, 0.382429, 0.372511, 0.346175, 0.308792, 0.29847 , 0.290941, 0.260707, 0.248007, 0.207595, 0.170824, 0.154504]
BL zero Losses: [0.22151 , 0.22151 , 0.22151 , 0.22151 , 0.245666, 0.245666, 0.245666, 0.245666, 0.22151 , 0.22151 , 0.22151 , 0.22151 , 0.245666, 0.245666, 0.245666, 0.245666, 0.110297, 0.245666, 0.110297, 0.245666]
BL naive Losses: [0.276434, 0.276434, 0.276434, 0.276434, 0.093605, 0.093605, 0.093605, 0.093605, 0.276434, 0.276434, 0.276434, 0.276434, 0.093605, 0.093605, 0.093605, 0.093605, 0.315924, 0.093605, 0.315924, 0.093605]
BL avg Losses: [0.266701, 0.266701, 0.266701, 0.266701, 0.609603, 0.609603, 0.609603, 0.609603, 0.266701, 0.266701, 0.266701, 0.266701, 0.609603, 0.609603, 0.609603, 0.609603, 0.304801, 0.609603, 0.304801, 0.609603]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('random-train-val'), np.int64(2)), (np.str_('time'), np.int64(3))]), ('with_examweek', [(np.str_('False'), np.int64(3)), (np.str_('True'), np.int64(2))]), ('x_horizon', [(np.str_('144'), np.int64(2)), (np.str_('36'), np.int64(2)), (np.str_('72'), np.int64(1))]), ('y_horizon', [(np.str_('12'), np.int64(3)), (np.str_('72'), np.int64(2))])]



################# Run: 3 #################
Time: 2024-11-13 12:53:03
Dataset: train | Loss: MAE
Combinations: [[3, 12], [3, 28], [3, 32], [3, 24], [3, 21], [3, 8], [3, 0], [3, 44], [3, 16], [3, 20], [3, 4], [3, 40], [3, 6], [3, 36], [3, 13], [3, 29], [3, 25], [3, 2], [3, 30], [3, 17], [3, 33], [3, 10], [3, 1], [3, 9], [3, 5], [3, 26], [3, 39], [3, 23], [3, 22], [3, 31], [3, 3], [3, 45], [3, 27], [3, 37], [3, 41], [3, 42], [3, 34], [3, 18], [3, 38], [3, 46], [3, 14], [3, 7], [3, 15], [3, 47], [3, 43], [3, 35], [3, 11], [3, 19]]
Model Losses: [0.00362 , 0.004585, 0.004961, 0.005015, 0.005065, 0.005077, 0.005121, 0.005236, 0.005319, 0.005399, 0.005534, 0.00588 , 0.006199, 0.006375, 0.00643 , 0.00664 , 0.006741, 0.007052, 0.007097, 0.007154, 0.007273, 0.007359, 0.00741 , 0.007763, 0.007952,
 0.007954, 0.008592, 0.008612, 0.008623, 0.008772, 0.008879, 0.008923, 0.008939, 0.009001, 0.009024, 0.009042, 0.009052, 0.009068, 0.009244, 0.009362, 0.009409, 0.009514, 0.009541, 0.009576, 0.009759, 0.010182, 0.010251, 0.01167 ]
BL zero Losses: [0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575,
 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575]
BL naive Losses: [0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394,
 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394]
BL avg Losses: [0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423,
 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.1'), np.int64(2)), (np.str_('0.2'), np.int64(1)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered'), np.int64(4))]), ('hidden_size', [(np.str_('[128]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(3))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('72'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]

Dataset: train | Loss: R2
Combinations: [[3, 12], [3, 28], [3, 21], [3, 44], [3, 8], [3, 32], [3, 40], [3, 24], [3, 16], [3, 33], [3, 29], [3, 25], [3, 6], [3, 20], [3, 39], [3, 23], [3, 13], [3, 31], [3, 27], [3, 30], [3, 26], [3, 34], [3, 47], [3, 43], [3, 36], [3, 3], [3, 45], [3, 11], [3, 4], [3, 35], [3, 41], [3, 42], [3, 46], [3, 37], [3, 2], [3, 17], [3, 19], [3, 5], [3, 0], [3, 10], [3, 1], [3, 18], [3, 22], [3, 15], [3, 9], [3, 7], [3, 38], [3, 14]]
Model Losses: [0.910472, 0.907222, 0.884741, 0.882612, 0.880217, 0.876574, 0.861617, 0.854201, 0.848729, 0.842628, 0.840448, 0.834332, 0.833283, 0.829083, 0.828907, 0.828255, 0.822486, 0.821047, 0.81918 , 0.814901, 0.812238, 0.808855, 0.807425, 0.799205, 0.793493,
 0.792882, 0.783195, 0.782748, 0.782152, 0.778293, 0.778242, 0.766424, 0.756593, 0.737316, 0.695788, 0.694079, 0.686896, 0.681259, 0.670026, 0.646762, 0.613893, 0.606631, 0.520642, 0.51375 , 0.475202, 0.461754, 0.427096, 0.407625]
BL zero Losses: [0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458,
 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458]
BL naive Losses: [0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659,
 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659]
BL avg Losses: [-2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162,
 -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162,
 -2.972162, -2.972162, -2.972162, -2.972162]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.1'), np.int64(1)), (np.str_('0.2'), np.int64(1)), (np.str_('0.5'), np.int64(3))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered'), np.int64(4))]), ('hidden_size', [(np.str_('[128, 32]'), np.int64(1)), (np.str_('[128]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(1)), (np.str_('[32]'), np.int64(1))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('72'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]

Dataset: val | Loss: MAE
Combinations: [[3, 44], [3, 36], [3, 8], [3, 24], [3, 4], [3, 40], [3, 0], [3, 20], [3, 16], [3, 12], [3, 28], [3, 45], [3, 33], [3, 32], [3, 37], [3, 5], [3, 34], [3, 41], [3, 25], [3, 42], [3, 18], [3, 46], [3, 1], [3, 22], [3, 38], [3, 26], [3, 17], [3, 10], [3, 9], [3, 35], [3, 29], [3, 13], [3, 39], [3, 2], [3, 14], [3, 3], [3, 27], [3, 11], [3, 30], [3, 15], [3, 21], [3, 47], [3, 6], [3, 31], [3, 7], [3, 23], [3, 19], [3, 43]]
Model Losses: [0.007504, 0.00786 , 0.007922, 0.008099, 0.008203, 0.008224, 0.008246, 0.00852 , 0.008584, 0.008588, 0.008593, 0.008697, 0.008759, 0.008784, 0.00888 , 0.009036, 0.009095, 0.009148, 0.009149, 0.009237, 0.009334, 0.009398, 0.009543, 0.00955 , 0.009568,
 0.00966 , 0.009664, 0.009674, 0.009703, 0.009742, 0.009774, 0.00978 , 0.00979 , 0.009909, 0.009916, 0.00993 , 0.009986, 0.010074, 0.010145, 0.010203, 0.010227, 0.010365, 0.010855, 0.010891, 0.010976, 0.01128 , 0.011297, 0.011711]
BL zero Losses: [0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007,
 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007]
BL naive Losses: [0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138,
 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138]
BL avg Losses: [0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463,
 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.1'), np.int64(2)), (np.str_('0.2'), np.int64(1)), (np.str_('0.5'), np.int64(2))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[128, 32]'), np.int64(2)), (np.str_('[32, 32]'), np.int64(1)), (np.str_('[32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('72'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]

Dataset: val | Loss: R2
Combinations: [[3, 44], [3, 36], [3, 4], [3, 40], [3, 24], [3, 0], [3, 12], [3, 8], [3, 20], [3, 32], [3, 45], [3, 33], [3, 16], [3, 37], [3, 42], [3, 28], [3, 34], [3, 41], [3, 10], [3, 46], [3, 25], [3, 29], [3, 3], [3, 30], [3, 26], [3, 35], [3, 11], [3, 27], [3, 2], [3, 39], [3, 47], [3, 15], [3, 6], [3, 31], [3, 19], [3, 23], [3, 43], [3, 22], [3, 5], [3, 18], [3, 13], [3, 21], [3, 1], [3, 38], [3, 17], [3, 9], [3, 14], [3, 7]]
Model Losses: [0.885414, 0.88143 , 0.873813, 0.873293, 0.867089, 0.865122, 0.860387, 0.859687, 0.848861, 0.848478, 0.843507, 0.842607, 0.841818, 0.839018, 0.838659, 0.838217, 0.830792, 0.827548, 0.827289, 0.825424, 0.824758, 0.809752, 0.808862, 0.803174, 0.803085,
 0.802258, 0.797748, 0.797205, 0.795589, 0.795379, 0.791507, 0.786989, 0.769623, 0.768141, 0.75889 , 0.756635, 0.754874, 0.704178, 0.701821, 0.697269, 0.692343, 0.657812, 0.582828, 0.575704, 0.567861, 0.567517, 0.561072, 0.511864]
BL zero Losses: [0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707,
 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707]
BL naive Losses: [0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873,
 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873]
BL avg Losses: [0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205,
 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.1'), np.int64(2)), (np.str_('0.2'), np.int64(2)), (np.str_('0.5'), np.int64(1))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[128, 32]'), np.int64(3)), (np.str_('[32, 32]'), np.int64(1)), (np.str_('[32]'), np.int64(1))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('72'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]

Dataset: test | Loss: MAE
Combinations: [[3, 4], [3, 16], [3, 40], [3, 28], [3, 32], [3, 44], [3, 36], [3, 33], [3, 8], [3, 25], [3, 34], [3, 12], [3, 20], [3, 30], [3, 29], [3, 9], [3, 0], [3, 6], [3, 13], [3, 46], [3, 26], [3, 24], [3, 5], [3, 1], [3, 19], [3, 7], [3, 38], [3, 2], [3, 10], [3, 17], [3, 3], [3, 35], [3, 41], [3, 37], [3, 14], [3, 42], [3, 22], [3, 45], [3, 11], [3, 27], [3, 18], [3, 47], [3, 31], [3, 21], [3, 15], [3, 43], [3, 23], [3, 39]]
Model Losses: [0.008572, 0.008855, 0.008877, 0.009117, 0.009172, 0.009208, 0.009312, 0.009391, 0.009506, 0.009546, 0.009632, 0.009795, 0.009826, 0.009908, 0.010014, 0.01002 , 0.010037, 0.010075, 0.010133, 0.010191, 0.010213, 0.010237, 0.010361, 0.010371, 0.010407,
 0.010517, 0.010553, 0.010582, 0.010688, 0.010715, 0.010837, 0.010858, 0.010863, 0.010869, 0.010873, 0.010933, 0.010957, 0.010977, 0.011002, 0.011052, 0.011388, 0.011529, 0.011539, 0.011546, 0.011744, 0.011804, 0.011819, 0.012267]
BL zero Losses: [0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723,
 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723]
BL naive Losses: [0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583,
 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583]
BL avg Losses: [0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044,
 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.2'), np.int64(4)), (np.str_('0.5'), np.int64(1))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered'), np.int64(5))]), ('hidden_size', [(np.str_('[128, 32]'), np.int64(1)), (np.str_('[128]'), np.int64(1)), (np.str_('[32, 32]'), np.int64(2)), (np.str_('[32]'), np.int64(1))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('72'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]

Dataset: test | Loss: R2
Combinations: [[3, 35], [3, 29], [3, 11], [3, 46], [3, 4], [3, 45], [3, 16], [3, 19], [3, 28], [3, 33], [3, 36], [3, 12], [3, 40], [3, 34], [3, 3], [3, 32], [3, 44], [3, 42], [3, 41], [3, 6], [3, 25], [3, 27], [3, 43], [3, 30], [3, 26], [3, 20], [3, 10], [3, 8], [3, 0], [3, 47], [3, 22], [3, 37], [3, 24], [3, 31], [3, 15], [3, 21], [3, 23], [3, 39], [3, 13], [3, 2], [3, 9], [3, 38], [3, 1], [3, 17], [3, 18], [3, 14], [3, 7], [3, 5]]
Model Losses: [0.664892, 0.664568, 0.636012, 0.633633, 0.628794, 0.620839, 0.61756 , 0.61228 , 0.61218 , 0.586854, 0.581967, 0.576425, 0.575523, 0.569263, 0.56915 , 0.568574, 0.56637 , 0.564608, 0.561247, 0.561154, 0.559623, 0.545972, 0.545544, 0.544151, 0.529088,
 0.517864, 0.516123, 0.514956, 0.514155, 0.511488, 0.492828, 0.48404 , 0.481489, 0.454235, 0.453528, 0.418149, 0.411446, 0.407842, 0.388089, 0.344487, 0.300783, 0.275263, 0.264199, 0.262768, 0.257363, 0.248336, 0.225149, 0.224328]
BL zero Losses: [0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666,
 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666]
BL naive Losses: [0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605,
 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605]
BL avg Losses: [0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603,
 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603]
Hyperparameters: [('course_encoding_dim', [(np.str_('0'), np.int64(5))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0.2'), np.int64(2)), (np.str_('0.5'), np.int64(3))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_week_zwickltag'), np.int64(2))]), ('hidden_size', [(np.str_('[128, 32]'), np.int64(1)), (np.str_('[32, 32]'), np.int64(2)), (np.str_('[32]'), np.int64(2))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('72'), np.int64(5))]), ('y_horizon', [(np.str_('36'), np.int64(5))])]



################# Run: 4 #################
Time: 2024-11-13 12:53:51
Dataset: train | Loss: MAE
Combinations: [[4, 1], [4, 6], [4, 7], [4, 2], [4, 3], [4, 5], [4, 4], [4, 0]]
Model Losses: [0.004683, 0.004828, 0.005258, 0.005847, 0.006739, 0.007827, 0.008216, 0.0091  ]
BL zero Losses: [0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575, 0.024575]
BL naive Losses: [0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394, 0.022394]
BL avg Losses: [0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423, 0.021423]
Hyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered_coursenumber'), np.int64(2)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber_dow_hod_week_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_coursenumber'), np.int64(2))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]

Dataset: train | Loss: R2
Combinations: [[4, 7], [4, 6], [4, 4], [4, 1], [4, 2], [4, 0], [4, 5], [4, 3]]
Model Losses: [ 0.889427,  0.887772,  0.848575,  0.836274,  0.830005,  0.816977,  0.59163 , -1.633017]
BL zero Losses: [0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458, 0.175458]
BL naive Losses: [0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659, 0.125659]
BL avg Losses: [-2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162, -2.972162]
Hyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered_coursenumber'), np.int64(2)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber_dow_hod_week_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]

Dataset: val | Loss: MAE
Combinations: [[4, 2], [4, 5], [4, 6], [4, 3], [4, 1], [4, 7], [4, 4], [4, 0]]
Model Losses: [0.008933, 0.00894 , 0.009245, 0.009734, 0.009834, 0.00997 , 0.010347, 0.011983]
BL zero Losses: [0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007, 0.020007]
BL naive Losses: [0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138, 0.015138]
BL avg Losses: [0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463, 0.013463]
Hyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(3)), (np.str_('3'), np.int64(2))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered_coursenumber'), np.int64(2)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber_dow_hod_week_zwickltag'), np.int64(2)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]

Dataset: val | Loss: R2
Combinations: [[4, 6], [4, 3], [4, 1], [4, 7], [4, 4], [4, 0], [4, 2], [4, 5]]
Model Losses: [0.849614, 0.83243 , 0.81935 , 0.81319 , 0.753664, 0.688348, 0.610552, 0.601726]
BL zero Losses: [0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707, 0.211707]
BL naive Losses: [0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873, 0.535873]
BL avg Losses: [0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205, 0.661205]
Hyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered_coursenumber'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber_dow_hod_week_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_coursenumber'), np.int64(2))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]

Dataset: test | Loss: MAE
Combinations: [[4, 2], [4, 7], [4, 5], [4, 6], [4, 4], [4, 3], [4, 1], [4, 0]]
Model Losses: [0.009333, 0.009366, 0.009581, 0.009868, 0.010144, 0.010385, 0.011131, 0.011886]
BL zero Losses: [0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723, 0.016723]
BL naive Losses: [0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583, 0.016583]
BL avg Losses: [0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044, 0.011044]
Hyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(1)), (np.str_('3'), np.int64(4))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered_coursenumber'), np.int64(2)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber_dow_hod_week_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]

Dataset: test | Loss: R2
Combinations: [[4, 7], [4, 6], [4, 4], [4, 1], [4, 0], [4, 3], [4, 5], [4, 2]]
Model Losses: [0.613427, 0.584617, 0.54225 , 0.471169, 0.43909 , 0.40658 , 0.30541 , 0.273945]
BL zero Losses: [0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666, 0.245666]
BL naive Losses: [0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605, 0.093605]
BL avg Losses: [0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603, 0.609603]
Hyperparameters: [('course_encoding_dim', [(np.str_('1'), np.int64(2)), (np.str_('3'), np.int64(3))]), ('dataset_mode', [(np.str_('dayahead'), np.int64(5))]), ('dropout', [(np.str_('0'), np.int64(5))]), ('features', [(np.str_('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered_coursenumber'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber'), np.int64(2)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_coursenumber_dow_hod_week_zwickltag'), np.int64(1)), (np.str_('occrate_lecture_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_coursenumber'), np.int64(1))]), ('hidden_size', [(np.str_('[32]'), np.int64(5))]), ('num_layers', [(np.str_('3'), np.int64(5))]), ('split_by', [(np.str_('time'), np.int64(5))]), ('with_examweek', [(np.str_('False'), np.int64(5))]), ('x_horizon', [(np.str_('36'), np.int64(5))]), ('y_horizon', [(np.str_('12'), np.int64(5))])]

























################# Run: 6 #################
Time: 2024-11-14 12:46:17
Dataset: train | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.007772]
BL zero Losses: [0.024575]
BL naive Losses: [0.022394]
BL avg Losses: [0.021423]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: train | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.499385]
BL zero Losses: [0.175458]
BL naive Losses: [0.125659]
BL avg Losses: [-2.972162]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: val | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.010086]
BL zero Losses: [0.022866]
BL naive Losses: [0.0173]
BL avg Losses: [0.015387]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: val | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.712782]
BL zero Losses: [0.099094]
BL naive Losses: [0.469569]
BL avg Losses: [0.612805]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: test | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.010006]
BL zero Losses: [0.016723]
BL naive Losses: [0.016583]
BL avg Losses: [0.011044]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: test | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.420726]
BL zero Losses: [0.245666]
BL naive Losses: [0.093605]
BL avg Losses: [0.609603]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]



################# Run: 6 #################
Time: 2024-11-14 13:05:53
Dataset: train | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.006472]
BL zero Losses: [0.024575]
BL naive Losses: [0.022394]
BL avg Losses: [0.021423]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: train | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.792147]
BL zero Losses: [0.175458]
BL naive Losses: [0.125659]
BL avg Losses: [-2.972162]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: val | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.010388]
BL zero Losses: [0.022866]
BL naive Losses: [0.0173]
BL avg Losses: [0.015387]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: val | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.835825]
BL zero Losses: [0.099094]
BL naive Losses: [0.469569]
BL avg Losses: [0.612805]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: test | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.009221]
BL zero Losses: [0.016723]
BL naive Losses: [0.016583]
BL avg Losses: [0.011044]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: test | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.472429]
BL zero Losses: [0.245666]
BL naive Losses: [0.093605]
BL avg Losses: [0.609603]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]



################# Run: 6 #################
Time: 2024-11-14 13:06:41
Dataset: train | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.006472]
BL zero Losses: [0.024575]
BL naive Losses: [0.022394]
BL avg Losses: [0.021423]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: train | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.792147]
BL zero Losses: [0.175458]
BL naive Losses: [0.125659]
BL avg Losses: [-2.972162]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: val | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.010388]
BL zero Losses: [0.022866]
BL naive Losses: [0.0173]
BL avg Losses: [0.015387]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: val | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.835825]
BL zero Losses: [0.099094]
BL naive Losses: [0.469569]
BL avg Losses: [0.612805]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: test | Loss: MAE
Combinations: [[6, 0]]
Model Losses: [0.009221]
BL zero Losses: [0.016723]
BL naive Losses: [0.016583]
BL avg Losses: [0.011044]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]

Dataset: test | Loss: R2
Combinations: [[6, 0]]
Model Losses: [0.472429]
BL zero Losses: [0.245666]
BL naive Losses: [0.093605]
BL avg Losses: [0.609603]
Hyperparameters: [('course_encoding_dim', [('0', 1)]), ('dataset_mode', [('dayahead', 1)]), ('dropout', [('0', 1)]), ('features', [('occrate_lecture_lecturerampbefore_test_exam_tutorium_cancelled_type_dow_hod_week_holiday_zwickltag_studyarea_level_registered', 1)]), ('hidden_size', [('[16, 256]', 1)]), ('num_layers', [('3', 1)]), ('split_by', [('time', 1)]), ('with_examweek', [('False', 1)]), ('x_horizon', [('144', 1)]), ('y_horizon', [('72', 1)])]



